{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "The notebook takes all the images in a Map & gis data, creates word variations, \n",
    "runs phoc and gets the closest match to every clip in the map. \n",
    "Based on the matched word variation we get the direction the clip should \n",
    "be extended in and store it in a separate file. Below cells also contain\n",
    "some analysis on how phoc performs using gis data, the top 10 neighbors etc\n",
    "'''\n",
    "\n",
    "import argparse\n",
    "import logging\n",
    "\n",
    "import numpy as np\n",
    "import torch.autograd\n",
    "import torch.cuda\n",
    "import torch.nn as nn\n",
    "import torch.optim\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import random\n",
    "\n",
    "import copy\n",
    "from datasets.maps_alt import MAPSDataset\n",
    "\n",
    "#from cnn_ws.transformations.homography_augmentation import HomographyAugmentation\n",
    "from cnn_ws.losses.cosine_loss import CosineLoss\n",
    "\n",
    "from cnn_ws.models.myphocnet import PHOCNet\n",
    "from cnn_ws.evaluation.retrieval import map_from_feature_matrix, map_from_query_test_feature_matrices\n",
    "from torch.utils.data.dataloader import _DataLoaderIter as DataLoaderIter\n",
    "from torch.utils.data.sampler import WeightedRandomSampler\n",
    "\n",
    "from cnn_ws.utils.save_load import my_torch_save, my_torch_load\n",
    "\n",
    "#import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_filter_len = 1 # only words above this length are considered valid\n",
    "max_var_len = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not torch.cuda.is_available():\n",
    "    logger.warning('Could not find CUDA environment, using CPU mode')\n",
    "    gpu_id = None\n",
    "else:\n",
    "    gpu_id = [0]\n",
    "#torch.cuda.get_device_name(gpu_id[0])\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ = torch.load('models/PHOCNet_Nov13.pt')\n",
    "cnn = model_.module#list(model_.named_parameters())\n",
    "if gpu_id is not None:\n",
    "        if len(gpu_id) > 1:\n",
    "            cnn = nn.DataParallel(cnn, device_ids=gpu_id)\n",
    "            cnn.cuda()\n",
    "        else:\n",
    "            cnn.cuda(gpu_id[0])\n",
    "cnn.training = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from strlocale import BasicLocale\n",
    "\n",
    "def clean_words(words):\n",
    "    lc = BasicLocale()\n",
    "    for i, w in enumerate(words):\n",
    "        try:\n",
    "            words[i] = lc.represent(w).encode('ascii',errors='ignore')\n",
    "        except:\n",
    "            words[i] = w\n",
    "    return words\n",
    "\n",
    "def load_and_transform(map_name):\n",
    "    images = np.load('/mnt/nfs/work1/696ds-s18/mbhargava/detection_outputs_ready_for_test/ray_regions/'+map_name+'.npy')\n",
    "    words = np.load('/mnt/nfs/work1/696ds-s18/mbhargava/detection_outputs_ready_for_test/ray_labels/'+map_name+'.npy')\n",
    "    images = np.transpose(images, (0,3,1,2))\n",
    "    words = clean_words(words)\n",
    "    print 'Images Shape ', images.shape\n",
    "    print 'Words Shape ', words.shape\n",
    "    return images, words\n",
    "\n",
    "def load_and_clean_gis_data():\n",
    "    with open('../GIS_data/GIS_combined.txt') as f:\n",
    "        gis_data = np.array(f.read().splitlines())\n",
    "    gis_data = clean_words(gis_data)\n",
    "    print 'GIS Data', gis_data.shape\n",
    "    return gis_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_img_phoc_embs(cnn, images):\n",
    "    outputs = []\n",
    "    for i in tqdm(range(len(images)), ascii=True, desc='Converting Images to Embeddings'):\n",
    "        word_img = images[i]\n",
    "        word_img = 1 - word_img.astype(np.float32) / 255.0\n",
    "        word_img = word_img.reshape((1,) + word_img.shape)\n",
    "        word_img = torch.from_numpy(word_img).float()\n",
    "        word_img = word_img.cuda(gpu_id[0])\n",
    "        word_img = torch.autograd.Variable(word_img)\n",
    "        output = torch.sigmoid(cnn(word_img))\n",
    "        output = output.data.cpu().numpy().flatten()\n",
    "        outputs.append(output)\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cnn_ws.string_embeddings.phoc import build_phoc_descriptor\n",
    "\n",
    "def insert_dict_set(dct, key, val):\n",
    "    if key not in dct:\n",
    "        dct[key] = set()\n",
    "    dct[key].add(val)\n",
    "    \n",
    "# the method defines the rules to handle multiple dir associated with a given word\n",
    "# returns conf_words which is a set of word_var where this confusion exists\n",
    "# word_var: dictionary from word -> chosen_dir. Incase a word has multiple dir\n",
    "# the following preference order is followed 0 > (1,-1) > (2,-2) > (3,-3) ...\n",
    "def handle_word_conf(comp_word_var):\n",
    "    word_var = {}\n",
    "    conf_words = set()\n",
    "    for var in comp_word_var.keys():\n",
    "        dirs = np.array(list(comp_word_var[var]))\n",
    "        if(len(dirs) == 1):\n",
    "            word_var[var] = dirs[0]\n",
    "        else:\n",
    "            conf_words.add(var)\n",
    "            idx = np.argmin(np.abs(dirs))\n",
    "            word_var[var] = dirs[idx]\n",
    "    return word_var, conf_words\n",
    "\n",
    "# function to create word variations\n",
    "# word_var is a dictionary that contains all variations as key and 0,1,-1 as value\n",
    "# 0 denotes the root word, -1 denotes var = root_word[:-1], +1 denotes var = root_word[1:]\n",
    "# root_word_var is a dict that stores original_word => all_variations\n",
    "# enable_conf: boolean flag that controls if the confusion logic should be used.\n",
    "# when enabled if a word is a root word as well as a word variation (happens if root words ar rand and grand)\n",
    "# it marks it as to be extended and also stores it in the confusion list\n",
    "def create_word_variations(words, enable_conf=False):\n",
    "    word_var = {}\n",
    "    root_word_var = {}\n",
    "    # create the root word variation dict and set word_var as -1 or +1\n",
    "    for w in words:\n",
    "        root_var_list = [w, w.lower(), w.upper(), w.capitalize()]\n",
    "        var_set = set()\n",
    "        for var in root_var_list:\n",
    "            for l in range(1,max_var_len+1):\n",
    "                if len(w) <= l:\n",
    "                    continue\n",
    "                insert_dict_set(word_var, var, 0)\n",
    "                insert_dict_set(word_var, var[l:], l)\n",
    "                insert_dict_set(word_var, var[:-l], -l)\n",
    "                var_set.add(var)\n",
    "                var_set.add(var[l:])\n",
    "                var_set.add(var[:-l])\n",
    "        root_word_var[w] = var_set\n",
    "    word_var, conf_words = handle_word_conf(word_var)\n",
    "    return word_var, root_word_var, conf_words\n",
    "\n",
    "def gen_text_phoc_embs(words):\n",
    "    word_strings = words\n",
    "    unigrams = [chr(i) for i in range(ord('&'), ord('&')+1) + range(ord('A'), ord('Z')+1) + \\\n",
    "                    range(ord('a'), ord('z') + 1) + range(ord('0'), ord('9') + 1)]\n",
    "    bigram_levels = None\n",
    "    bigrams = None\n",
    "    phoc_unigram_levels=(1, 2, 4, 8)\n",
    "    \n",
    "    word_var_dir, root_word_var, conf_words = create_word_variations(word_strings, enable_conf=True)\n",
    "    \n",
    "    embedding = build_phoc_descriptor(words=word_strings,\n",
    "                                  phoc_unigrams=unigrams,\n",
    "                                  bigram_levels=bigram_levels,\n",
    "                                  phoc_bigrams=bigrams,\n",
    "                                  unigram_levels=phoc_unigram_levels)\n",
    "\n",
    "    word_var_strings = word_var_dir.keys()\n",
    "    embedding_var = build_phoc_descriptor(words=word_var_strings,\n",
    "                                  phoc_unigrams=unigrams,\n",
    "                                  bigram_levels=bigram_levels,\n",
    "                                  phoc_bigrams=bigrams,\n",
    "                                  unigram_levels=phoc_unigram_levels)\n",
    "    \n",
    "    return (embedding, embedding_var, word_var_strings, word_var_dir, root_word_var, conf_words)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the new report matches method that handles variations\n",
    "from scipy.spatial.distance import cdist, pdist, squareform\n",
    "def report_matches_with_variations(outputs, embedding, matching, ground_truth, \n",
    "                                   words, word_var_dir, root_word_var, k, length):\n",
    "    # length sorting stuff\n",
    "    qualified_ids = [x for x in range(len(ground_truth)) if len(ground_truth[x]) > length]\n",
    "    outputs = np.array(outputs)\n",
    "    ground_truth = np.array(ground_truth)\n",
    "    outputs = list(outputs[qualified_ids])\n",
    "    ground_truth = list(ground_truth[qualified_ids])\n",
    "    \n",
    "    # the real computation\n",
    "    dist_mat = cdist(XA=outputs, XB=embedding, metric=matching)\n",
    "    retrieval_indices = np.argsort(dist_mat, axis=1)\n",
    "    q = retrieval_indices[:,:k]\n",
    "    count = 0\n",
    "    matched_words = []\n",
    "    img_dir = []\n",
    "    words_len = []\n",
    "    min_ext_len = 3\n",
    "    # get all matched words\n",
    "    for i in range(len(q)):\n",
    "        matched = []\n",
    "        for j in q[i]:\n",
    "            matched.append(words[j])\n",
    "            curr_len = len(words[j])\n",
    "            curr_dir = word_var_dir[words[j]]\n",
    "            if len(ground_truth[i]) < min_ext_len:\n",
    "                curr_dir = 0\n",
    "            words_len.append(curr_len + abs(curr_dir))\n",
    "            img_dir.append(curr_dir)\n",
    "        matched_words.append(matched)\n",
    "    \n",
    "    # calculate accuracies\n",
    "    for i in range(len(ground_truth)):\n",
    "        #print word_strings[i]\n",
    "        if ground_truth[i].lower() in [mw.lower() for mw in matched_words[i]]:\n",
    "            count = count+1\n",
    "        else:\n",
    "            for w in matched_words[i]:\n",
    "                if ground_truth[i] in root_word_var and w in root_word_var[ground_truth[i]]:\n",
    "                    count = count+1\n",
    "                    break\n",
    "\n",
    "    return (count, matched_words, qualified_ids, img_dir, words_len, outputs, ground_truth, dist_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the old original report matches method\n",
    "from scipy.spatial.distance import cdist, pdist, squareform\n",
    "def report_matches(outputs, embedding, matching, words, ground_truth, k, length):\n",
    "    # length sorting stuff\n",
    "    qualified_ids = [x for x in range(len(ground_truth)) if len(ground_truth[x]) > length]\n",
    "    outputs = np.array(outputs)\n",
    "    ground_truth = np.array(ground_truth)\n",
    "    outputs = list(outputs[qualified_ids])\n",
    "    ground_truth = list(ground_truth[qualified_ids])\n",
    "    # the real computation\n",
    "    dist_mat = cdist(XA=outputs, XB=embedding, metric=matching)\n",
    "    retrieval_indices = np.argsort(dist_mat, axis=1)\n",
    "    q = retrieval_indices[:,:k]\n",
    "    count = 0\n",
    "    matched_words = []\n",
    "    # get all matched words\n",
    "    for i in range(len(q)):\n",
    "        matched = []\n",
    "        for j in q[i]:\n",
    "            matched.append(words[j])\n",
    "        matched_words.append(matched)\n",
    "    \n",
    "    for i in range(len(ground_truth)):\n",
    "        if ground_truth[i].lower() in [mw.lower() for mw in matched_words[i]]:\n",
    "            count = count+1\n",
    "\n",
    "    return (count, matched_words, outputs, embedding, ground_truth, qualified_ids, dist_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# given the image name, this driver function computes the following\n",
    "# 1. loads the words and images and transforms them based on image name\n",
    "# 2. generates embeddings for images using the cnn model\n",
    "# 3. gets the original and variation embeddings\n",
    "# 4. generate report with word variations (prints accuracy)\n",
    "# 5. generate report original (prints accuracy)\n",
    "# 6. returns the image_dir_info that needs to be saved as numpy files\n",
    "def image_ext_with_word_var(map_name, cnn, gis_data, text_phoc_info, global_stats):\n",
    "    images, words = load_and_transform(map_name)\n",
    "    img_phoc_embs = gen_img_phoc_embs(cnn, images)\n",
    "    embedding, embedding_var, word_var_strings, word_var_dir, root_word_var, conf_set = text_phoc_info\n",
    "    original_report = report_matches(img_phoc_embs, embedding, 'cosine', gis_data, words, 1, word_filter_len)\n",
    "    global_stats['correct_original'] += original_report[0]\n",
    "    print 'Original Accuracy ', str(original_report[0]/float(len(original_report[4])))\n",
    "    word_var_report = report_matches_with_variations(img_phoc_embs, embedding_var,'cosine', words, word_var_strings, word_var_dir, root_word_var, 1, word_filter_len)\n",
    "    global_stats['correct_word_var'] += word_var_report[0]\n",
    "    print 'Accuracy With Word Variations ', str(word_var_report[0]/float(len(word_var_report[4])))\n",
    "    global_stats['total'] += len(word_var_report[4])\n",
    "    img_dir_info = np.array([word_var_report[2], word_var_report[3], word_var_report[4]])\n",
    "    return img_dir_info, word_var_report[6], conf_set, original_report, word_var_report\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GIS Data (477196,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 477196/477196 [01:31<00:00, 5222.71it/s]\n",
      "100%|██████████| 1290899/1290899 [03:52<00:00, 5556.17it/s]\n"
     ]
    }
   ],
   "source": [
    "gis_data = load_and_clean_gis_data()\n",
    "text_phoc_info = gen_text_phoc_embs(gis_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = ['D0042-1070001']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cdad5836ffc5433cb220a61e3ff55073",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description=u'Main Iteration', max=1), HTML(value=u'')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D0042-1070001\n",
      "Images Shape  (1192, 3, 135, 487)\n",
      "Words Shape  (1192,)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75894f1d755d49eba4170fab256155cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "SEJveChjaGlsZHJlbj0oSW50UHJvZ3Jlc3ModmFsdWU9MCwgZGVzY3JpcHRpb249dSdDb252ZXJ0aW5nIEltYWdlcyB0byBFbWJlZGRpbmdzJywgbWF4PTExOTIpLCBIVE1MKHZhbHVlPXUnJynigKY=\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Accuracy  0.287184284378\n",
      "Accuracy With Word Variations  0.357343311506\n",
      "\n",
      "Accuracy Original 0.287184284378\n",
      "Accuracy With Word Variations 0.357343311506\n"
     ]
    }
   ],
   "source": [
    "global_stats = {'correct_original':0, 'correct_word_var':0, 'total':0}\n",
    "\n",
    "original_report = None\n",
    "word_var_report = None\n",
    "for i in tqdm(range(len(A)), ascii=True, desc = 'Main Iteration'):\n",
    "    print A[i]\n",
    "    img_dir_info, words, conf_words, original_report,word_var_report = image_ext_with_word_var(A[i], cnn, gis_data, text_phoc_info, global_stats)\n",
    "    # np.save('../../../images_to_extend/image_dir_'+A[i]+'.npy', img_dir_info)\n",
    "    # np.save('../../../images_to_extend/image_labels_'+A[i]+'.npy', words)\n",
    "print 'Accuracy Original', global_stats['correct_original']/float(global_stats['total'])\n",
    "print 'Accuracy With Word Variations', global_stats['correct_word_var']/float(global_stats['total'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1069\n",
      "52 ['eastern'] eastern\n",
      "85 ['and'] and\n",
      "113 ['and'] and\n",
      "119 ['abound'] abound\n",
      "124 ['and'] and\n",
      "131 ['generally'] generally\n",
      "140 ['beds'] beds\n",
      "141 ['thickness'] thickness\n",
      "160 ['2d'] 2d\n",
      "162 ['frequent'] frequent\n",
      "166 ['the'] the\n",
      "172 ['of'] of\n",
      "179 ['and'] and\n",
      "188 ['abound'] abound\n",
      "219 ['in'] in\n",
      "232 ['the'] the\n",
      "233 ['13'] 13\n",
      "236 ['10'] 10\n",
      "243 ['14'] 14\n",
      "280 ['14'] 14\n",
      "286 ['10'] 10\n",
      "291 ['the'] the\n",
      "308 ['12'] 12\n",
      "315 ['throughout'] throughout\n",
      "330 ['15'] 15\n",
      "331 ['13'] 13\n",
      "334 ['10'] 10\n",
      "338 ['12'] 12\n",
      "474 ['12'] 12\n",
      "487 ['12'] 12\n",
      "488 ['13'] 13\n",
      "506 ['12'] 12\n",
      "507 ['11'] 11\n",
      "525 ['16'] 16\n",
      "547 ['14'] 14\n",
      "691 ['12'] 12\n",
      "694 ['abound'] abound\n",
      "697 ['throughout'] throughout\n",
      "718 ['beds'] beds\n",
      "750 ['and'] and\n",
      "766 ['and'] and\n",
      "773 ['thickness'] thickness\n",
      "777 ['the'] the\n",
      "781 ['frequent'] frequent\n",
      "791 ['and'] and\n",
      "832 ['2d'] 2d\n",
      "873 ['the'] the\n",
      "920 ['14'] 14\n",
      "976 ['12'] 12\n"
     ]
    }
   ],
   "source": [
    "count, matched_words, outputs, embedding, ground_truth, qualified_ids, dist_mat = original_report\n",
    "print(len(matched_words))\n",
    "for i in range(len(matched_words)):\n",
    "    if matched_words[i][0].lower() == ground_truth[i]:\n",
    "        print i, matched_words[i], ground_truth[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_dist = np.argsort(dist_mat, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gis_word_idx(word):\n",
    "    idx = []\n",
    "    for i in range(len(gis_data)):\n",
    "        if word.lower() == gis_data[i].lower():\n",
    "            idx.append(i)\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, words = load_and_transform(A[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# analysis of land image\n",
    "gis_word_idx = set(get_gis_word_idx('land'))\n",
    "img_ids = set([38, 73, 116, 158, 248, 711, 712, 716, 817])\n",
    "for i in range(len(matched_words)):\n",
    "    if i not in img_ids:\n",
    "        continue\n",
    "    print \"************************************************************************\"\n",
    "    print \"************************************************************************\"\n",
    "    print \"Original image:\"\n",
    "    q = np.transpose(images[qualified_ids[i]],(1,2,0))\n",
    "    plt.imshow(q)\n",
    "    plt.show()\n",
    "    print \"the matched words are (inorder): \"+str(matched_words[i])\n",
    "    print \"the gound truth is:\" + str(ground_truth[i])\n",
    "    for p,j in enumerate(sorted_dist[i]):\n",
    "        if j in gis_word_idx:\n",
    "            print \"closest correct match in dist matrix\", p\n",
    "            break\n",
    "    print \"top 10 matches are: \", [gis_data[j] for j in sorted_dist[i][:10]]\n",
    "    print \"------------------------------------------------------------------------\"\n",
    "    print \"------------------------------------------------------------------------\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# analysis of logan image\n",
    "gis_word_idx = set(get_gis_word_idx('logan'))\n",
    "img_ids = set([50,246,695,769])\n",
    "for i in range(len(matched_words)):\n",
    "    if i not in img_ids:\n",
    "        continue\n",
    "    print \"************************************************************************\"\n",
    "    print \"************************************************************************\"\n",
    "    print \"Original image:\"\n",
    "    q = np.transpose(images[qualified_ids[i]],(1,2,0))\n",
    "    plt.imshow(q)\n",
    "    plt.show()\n",
    "    print \"the matched words are (inorder): \"+str(matched_words[i])\n",
    "    print \"the gound truth is:\" + str(ground_truth[i])\n",
    "    for p,j in enumerate(sorted_dist[i]):\n",
    "        if j in gis_word_idx:\n",
    "            print \"closest correct match in dist matrix\", p\n",
    "            break\n",
    "    print \"top 10 matches are: \", [gis_data[j] for j in sorted_dist[i][:10]]\n",
    "    print \"------------------------------------------------------------------------\"\n",
    "    print \"------------------------------------------------------------------------\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# analysis of 1866 image\n",
    "gis_word_idx = set(get_gis_word_idx('1866'))\n",
    "img_ids = set([70, 483, 757])\n",
    "for i in range(len(matched_words)):\n",
    "    if i not in img_ids:\n",
    "        continue\n",
    "    print \"************************************************************************\"\n",
    "    print \"************************************************************************\"\n",
    "    print \"Original image:\"\n",
    "    q = np.transpose(images[qualified_ids[i]],(1,2,0))\n",
    "    plt.imshow(q)\n",
    "    plt.show()\n",
    "    print \"the matched words are (inorder): \"+str(matched_words[i])\n",
    "    print \"the gound truth is:\" + str(ground_truth[i])\n",
    "    for p,j in enumerate(sorted_dist[i]):\n",
    "        if j in gis_word_idx:\n",
    "            print \"closest correct match in dist matrix\", p\n",
    "            break\n",
    "    if p == len(sorted_dist[i])-1:\n",
    "        print \"did not find the word in gis data\"\n",
    "    print \"top 10 matches are: \", [gis_data[j] for j in sorted_dist[i][:10]]\n",
    "    print \"------------------------------------------------------------------------\"\n",
    "    print \"------------------------------------------------------------------------\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# analysis of Crawford image\n",
    "gis_word_idx = set(get_gis_word_idx('CRAWFORD'))\n",
    "img_ids = set([76, 698])\n",
    "for i in range(len(matched_words)):\n",
    "    if i not in img_ids:\n",
    "        continue\n",
    "    print \"************************************************************************\"\n",
    "    print \"************************************************************************\"\n",
    "    print \"Original image:\"\n",
    "    q = np.transpose(images[qualified_ids[i]],(1,2,0))\n",
    "    plt.imshow(q)\n",
    "    plt.show()\n",
    "    print \"the matched words are (inorder): \"+str(matched_words[i])\n",
    "    print \"the gound truth is:\" + str(ground_truth[i])\n",
    "    for p,j in enumerate(sorted_dist[i]):\n",
    "        if j in gis_word_idx:\n",
    "            print \"closest correct match in dist matrix\", p\n",
    "            break\n",
    "    if p == len(sorted_dist[i])-1:\n",
    "        print \"did not find the word in gis data\"\n",
    "    print \"top 10 matches are: \", [gis_data[j] for j in sorted_dist[i][:10]]\n",
    "    print \"------------------------------------------------------------------------\"\n",
    "    print \"------------------------------------------------------------------------\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# analysis of state image\n",
    "gis_word_idx = set(get_gis_word_idx('state'))\n",
    "img_ids = set([99, 120, 225, 741, 799])\n",
    "for i in range(len(matched_words)):\n",
    "    if i not in img_ids:\n",
    "        continue\n",
    "    print \"************************************************************************\"\n",
    "    print \"************************************************************************\"\n",
    "    print \"Original image:\"\n",
    "    q = np.transpose(images[qualified_ids[i]],(1,2,0))\n",
    "    plt.imshow(q)\n",
    "    plt.show()\n",
    "    print \"the matched words are (inorder): \"+str(matched_words[i])\n",
    "    print \"the gound truth is:\" + str(ground_truth[i])\n",
    "    for p,j in enumerate(sorted_dist[i]):\n",
    "        if j in gis_word_idx:\n",
    "            print \"closest correct match in dist matrix\", p\n",
    "            break\n",
    "    if p == len(sorted_dist[i])-1:\n",
    "        print \"did not find the word in gis data\"\n",
    "    print \"top 10 matches are: \", [gis_data[j] for j in sorted_dist[i][:10]]\n",
    "    print \"------------------------------------------------------------------------\"\n",
    "    print \"------------------------------------------------------------------------\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# analysis of FAIRFIELD image\n",
    "gis_word_idx = set(get_gis_word_idx('FAIRFIELD'))\n",
    "img_ids = set([156, 962])\n",
    "for i in range(len(matched_words)):\n",
    "    if i not in img_ids:\n",
    "        continue\n",
    "    print \"************************************************************************\"\n",
    "    print \"************************************************************************\"\n",
    "    print \"Original image:\"\n",
    "    q = np.transpose(images[qualified_ids[i]],(1,2,0))\n",
    "    plt.imshow(q)\n",
    "    plt.show()\n",
    "    print \"the matched words are (inorder): \"+str(matched_words[i])\n",
    "    print \"the gound truth is:\" + str(ground_truth[i])\n",
    "    for p,j in enumerate(sorted_dist[i]):\n",
    "        if j in gis_word_idx:\n",
    "            print \"closest correct match in dist matrix\", p\n",
    "            break\n",
    "    if p == len(sorted_dist[i])-1:\n",
    "        print \"did not find the word in gis data\"\n",
    "    print \"top 10 matches are: \", [gis_data[j] for j in sorted_dist[i][:10]]\n",
    "    print \"------------------------------------------------------------------------\"\n",
    "    print \"------------------------------------------------------------------------\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# analysis of 13 image\n",
    "gis_word_idx = set(get_gis_word_idx('13'))\n",
    "img_ids = set([222, 233, 270, 331, 471, 488, 549, 685, 813, 957])\n",
    "for i in range(len(matched_words)):\n",
    "    if i not in img_ids:\n",
    "        continue\n",
    "    print \"************************************************************************\"\n",
    "    print \"************************************************************************\"\n",
    "    print \"Original image:\"\n",
    "    q = np.transpose(images[qualified_ids[i]],(1,2,0))\n",
    "    plt.imshow(q)\n",
    "    plt.show()\n",
    "    print \"the matched words are (inorder): \"+str(matched_words[i])\n",
    "    print \"the gound truth is:\" + str(ground_truth[i])\n",
    "    for p,j in enumerate(sorted_dist[i]):\n",
    "        if j in gis_word_idx:\n",
    "            print \"closest correct match in dist matrix\", p\n",
    "            break\n",
    "    if p == len(sorted_dist[i])-1:\n",
    "        print \"did not find the word in gis data\"\n",
    "    print \"top 10 matches are: \", [gis_data[j] for j in sorted_dist[i][:10]]\n",
    "    print \"------------------------------------------------------------------------\"\n",
    "    print \"------------------------------------------------------------------------\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# analysis of 13 image\n",
    "gis_word_idx = set(get_gis_word_idx('great'))\n",
    "img_ids = set([355, 561])\n",
    "for i in range(len(matched_words)):\n",
    "    if i not in img_ids:\n",
    "        continue\n",
    "    print \"************************************************************************\"\n",
    "    print \"************************************************************************\"\n",
    "    print \"Original image:\"\n",
    "    q = np.transpose(images[qualified_ids[i]],(1,2,0))\n",
    "    plt.imshow(q)\n",
    "    plt.show()\n",
    "    print \"the matched words are (inorder): \"+str(matched_words[i])\n",
    "    print \"the gound truth is:\" + str(ground_truth[i])\n",
    "    for p,j in enumerate(sorted_dist[i]):\n",
    "        if j in gis_word_idx:\n",
    "            print \"closest correct match in dist matrix\", p\n",
    "            break\n",
    "    if p == len(sorted_dist[i])-1:\n",
    "        print \"did not find the word in gis data\"\n",
    "    print \"top 10 matches are: \", [gis_data[j] for j in sorted_dist[i][:10]]\n",
    "    print \"------------------------------------------------------------------------\"\n",
    "    print \"------------------------------------------------------------------------\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
