{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import logging\n",
    "\n",
    "import numpy as np\n",
    "import torch.autograd\n",
    "import torch.cuda\n",
    "import torch.nn as nn\n",
    "import torch.optim\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import random\n",
    "\n",
    "import copy\n",
    "from datasets.maps_alt import MAPSDataset\n",
    "\n",
    "#from cnn_ws.transformations.homography_augmentation import HomographyAugmentation\n",
    "from cnn_ws.losses.cosine_loss import CosineLoss\n",
    "\n",
    "from cnn_ws.models.myphocnet import PHOCNet\n",
    "from cnn_ws.evaluation.retrieval import map_from_feature_matrix, map_from_query_test_feature_matrices\n",
    "from torch.utils.data.dataloader import _DataLoaderIter as DataLoaderIter\n",
    "from torch.utils.data.sampler import WeightedRandomSampler\n",
    "\n",
    "from cnn_ws.utils.save_load import my_torch_save, my_torch_load\n",
    "\n",
    "#import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_filter_len = 1 # only words above this length are considered valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not torch.cuda.is_available():\n",
    "    logger.warning('Could not find CUDA environment, using CPU mode')\n",
    "    gpu_id = None\n",
    "else:\n",
    "    gpu_id = [0]\n",
    "#torch.cuda.get_device_name(gpu_id[0])\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ = torch.load('models/PHOCNet_SDMD.pt')\n",
    "cnn = model_.module#list(model_.named_parameters())\n",
    "if gpu_id is not None:\n",
    "        if len(gpu_id) > 1:\n",
    "            cnn = nn.DataParallel(cnn, device_ids=gpu_id)\n",
    "            cnn.cuda()\n",
    "        else:\n",
    "            cnn.cuda(gpu_id[0])\n",
    "cnn.training = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the file names\n",
    "f = open('../splits/train_files.txt', 'rb')\n",
    "A = f.readlines()\n",
    "f.close()\n",
    "A = [x.rstrip('\\n') for x in A]\n",
    "# train maps to remove\n",
    "A.remove('D0042-1070013')\n",
    "# test maps to remove\n",
    "# A.remove('D5005-5028102')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from strlocale import BasicLocale\n",
    "\n",
    "def clean_words(words):\n",
    "    lc = BasicLocale()\n",
    "    for i, w in enumerate(words):\n",
    "        try:\n",
    "            words[i] = lc.represent(w).encode('ascii',errors='ignore')\n",
    "        except:\n",
    "            words[i] = w\n",
    "    return words\n",
    "\n",
    "def load_and_transform(map_name):\n",
    "    images = np.load('../../../detection_outputs_ready_for_test/detected_regions/'+map_name+'.npy')\n",
    "    words = np.load('../../../detection_outputs_ready_for_test/detected_labels/'+map_name+'.npy')\n",
    "    images = np.transpose(images, (0,3,1,2))\n",
    "    words = clean_words(words)\n",
    "    print 'Images Shape ', images.shape\n",
    "    print 'Words Shape ', words.shape\n",
    "    return images, words\n",
    "\n",
    "def load_and_clean_gis_data():\n",
    "    with open('../../../GIS_data/GIS_combined.txt') as f:\n",
    "        gis_data = np.array(f.read().splitlines())\n",
    "    gis_data = clean_words(gis_data)\n",
    "    print 'GIS Data', gis_data.shape\n",
    "    return gis_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_img_phoc_embs(cnn, images):\n",
    "    outputs = []\n",
    "    for i in tqdm(range(len(images)), ascii=True, desc='Converting Images to Embeddings'):\n",
    "        word_img = images[i]\n",
    "        word_img = 1 - word_img.astype(np.float32) / 255.0\n",
    "        word_img = word_img.reshape((1,) + word_img.shape)\n",
    "        word_img = torch.from_numpy(word_img).float()\n",
    "        word_img = word_img.cuda(gpu_id[0])\n",
    "        word_img = torch.autograd.Variable(word_img)\n",
    "        output = torch.sigmoid(cnn(word_img))\n",
    "        output = output.data.cpu().numpy().flatten()\n",
    "        outputs.append(output)\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cnn_ws.string_embeddings.phoc import build_phoc_descriptor\n",
    "\n",
    "# function to create word variations\n",
    "# word_var is a dictionary that contains all variations as key and 0,1,-1 as value\n",
    "# 0 denotes the root word, -1 denotes var = root_word[:-1], +1 denotes var = root_word[1:]\n",
    "# root_word_var is a dict that stores original_word => all_variations\n",
    "# enable_conf: boolean flag that controls if the confusion logic should be used.\n",
    "# when enabled if a word is a root word as well as a word variation (happens if root words ar rand and grand)\n",
    "# it marks it as to be extended and also stores it in the confusion list\n",
    "def create_word_variations(words, enable_conf=False):\n",
    "    word_var = {}\n",
    "    root_word_var = {}\n",
    "    # create the root word variation dict and set word_var as -1 or +1\n",
    "    for w in words:\n",
    "        if len(w) <= word_filter_len:\n",
    "            continue\n",
    "        root_var_list = [w, w.lower(), w.upper(), w.capitalize()]\n",
    "        var_set = set()\n",
    "        for var in root_var_list:\n",
    "            word_var[var[1:]] = 1\n",
    "            word_var[var[:-1]] = -1\n",
    "            var_set.add(var)\n",
    "            var_set.add(var[1:])\n",
    "            var_set.add(var[:-1])\n",
    "        root_word_var[w] = var_set\n",
    "    # explicitly set all root words to have direction 0\n",
    "    # mark the words that already have a direction set\n",
    "    conf_words = set()\n",
    "    for w in words:\n",
    "        if len(w) <= word_filter_len:\n",
    "            continue\n",
    "        root_var_list = [w, w.lower(), w.upper(), w.capitalize()]\n",
    "        for var in root_var_list:\n",
    "            if var in word_var and word_var[var] != 0 and enable_conf:\n",
    "                conf_words.add(var)\n",
    "            else:\n",
    "                word_var[var] = 0\n",
    "    return word_var, root_word_var, conf_words\n",
    "\n",
    "def gen_text_phoc_embs(words):\n",
    "    word_strings = words\n",
    "    unigrams = [chr(i) for i in range(ord('&'), ord('&')+1) + range(ord('A'), ord('Z')+1) + \\\n",
    "                    range(ord('a'), ord('z') + 1) + range(ord('0'), ord('9') + 1)]\n",
    "    bigram_levels = None\n",
    "    bigrams = None\n",
    "    phoc_unigram_levels=(1, 2, 4, 8)\n",
    "    \n",
    "    word_var_dir, root_word_var, conf_words = create_word_variations(word_strings, enable_conf=True)\n",
    "    \n",
    "    embedding = build_phoc_descriptor(words=word_strings,\n",
    "                                  phoc_unigrams=unigrams,\n",
    "                                  bigram_levels=bigram_levels,\n",
    "                                  phoc_bigrams=bigrams,\n",
    "                                  unigram_levels=phoc_unigram_levels)\n",
    "\n",
    "    word_var_strings = word_var_dir.keys()\n",
    "    embedding_var = build_phoc_descriptor(words=word_var_strings,\n",
    "                                  phoc_unigrams=unigrams,\n",
    "                                  bigram_levels=bigram_levels,\n",
    "                                  phoc_bigrams=bigrams,\n",
    "                                  unigram_levels=phoc_unigram_levels)\n",
    "    \n",
    "    return (embedding, embedding_var, word_var_strings, word_var_dir, root_word_var, conf_words)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the new report matches method that handles variations\n",
    "from scipy.spatial.distance import cdist, pdist, squareform\n",
    "def report_matches_with_variations(outputs, embedding, matching, ground_truth, \n",
    "                                   words, word_var_dir, root_word_var, k, length):\n",
    "    # length sorting stuff\n",
    "    qualified_ids = [x for x in range(len(ground_truth)) if len(ground_truth[x]) > length]\n",
    "    outputs = np.array(outputs)\n",
    "    ground_truth = np.array(ground_truth)\n",
    "    outputs = list(outputs[qualified_ids])\n",
    "    ground_truth = list(ground_truth[qualified_ids])\n",
    "    \n",
    "    # the real computation\n",
    "    dist_mat = cdist(XA=outputs, XB=embedding, metric=matching)\n",
    "    retrieval_indices = np.argsort(dist_mat, axis=1)\n",
    "    q = retrieval_indices[:,:k]\n",
    "    count = 0\n",
    "    matched_words = []\n",
    "    img_dir = []\n",
    "    words_len = []\n",
    "    # get all matched words\n",
    "    for i in range(len(q)):\n",
    "        matched = []\n",
    "        for j in q[i]:\n",
    "            matched.append(words[j])\n",
    "            curr_len = len(words[j])\n",
    "            curr_dir = word_var_dir[words[j]]\n",
    "            words_len.append(curr_len + abs(curr_dir))\n",
    "            img_dir.append(curr_dir)\n",
    "        matched_words.append(matched)\n",
    "    \n",
    "    # calculate accuracies\n",
    "    for i in range(len(ground_truth)):\n",
    "        #print word_strings[i]\n",
    "        if ground_truth[i].lower() in [mw.lower() for mw in matched_words[i]]:\n",
    "            count = count+1\n",
    "        else:\n",
    "            for w in matched_words[i]:\n",
    "                if ground_truth[i] in root_word_var and w in root_word_var[ground_truth[i]]:\n",
    "                    count = count+1\n",
    "                    break\n",
    "\n",
    "    return (count, matched_words, qualified_ids, img_dir, words_len, outputs, ground_truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the old original report matches method\n",
    "from scipy.spatial.distance import cdist, pdist, squareform\n",
    "def report_matches(outputs, embedding, matching, words, ground_truth, k, length):\n",
    "    # length sorting stuff\n",
    "    qualified_ids = [x for x in range(len(ground_truth)) if len(ground_truth[x]) > length]\n",
    "    outputs = np.array(outputs)\n",
    "    ground_truth = np.array(ground_truth)\n",
    "    outputs = list(outputs[qualified_ids])\n",
    "    ground_truth = list(ground_truth[qualified_ids])\n",
    "    # the real computation\n",
    "    dist_mat = cdist(XA=outputs, XB=embedding, metric=matching)\n",
    "    retrieval_indices = np.argsort(dist_mat, axis=1)\n",
    "    q = retrieval_indices[:,:k]\n",
    "    count = 0\n",
    "    matched_words = []\n",
    "    # get all matched words\n",
    "    for i in range(len(q)):\n",
    "        matched = []\n",
    "        for j in q[i]:\n",
    "            matched.append(words[j])\n",
    "        matched_words.append(matched)\n",
    "    \n",
    "    for i in range(len(ground_truth)):\n",
    "        if ground_truth[i].lower() in [mw.lower() for mw in matched_words[i]]:\n",
    "            count = count+1\n",
    "\n",
    "    return (count, matched_words, outputs, embedding, ground_truth, qualified_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# given the image name, this driver function computes the following\n",
    "# 1. loads the words and images and transforms them based on image name\n",
    "# 2. generates embeddings for images using the cnn model\n",
    "# 3. gets the original and variation embeddings\n",
    "# 4. generate report with word variations (prints accuracy)\n",
    "# 5. generate report original (prints accuracy)\n",
    "# 6. returns the image_dir_info that needs to be saved as numpy files\n",
    "def image_ext_with_word_var(map_name, cnn, gis_data, text_phoc_info, global_stats):\n",
    "    images, words = load_and_transform(map_name)\n",
    "    img_phoc_embs = gen_img_phoc_embs(cnn, images)\n",
    "    embedding, embedding_var, word_var_strings, word_var_dir, root_word_var, conf_set = text_phoc_info\n",
    "    original_report = report_matches(img_phoc_embs, embedding, 'cosine', gis_data, words, 1, word_filter_len)\n",
    "    global_stats['correct_original'] += original_report[0]\n",
    "    print 'Original Accuracy ', str(original_report[0]/float(len(original_report[4])))\n",
    "    word_var_report = report_matches_with_variations(img_phoc_embs, embedding_var,'cosine', words, \\\n",
    "                                                     word_var_strings, word_var_dir, root_word_var, 1, word_filter_len)\n",
    "    global_stats['correct_word_var'] += word_var_report[0]\n",
    "    print 'Accuracy With Word Variations ', str(word_var_report[0]/float(len(word_var_report[4])))\n",
    "    global_stats['total'] += len(word_var_report[4])\n",
    "    img_dir_info = np.array([word_var_report[2], word_var_report[3], word_var_report[4]])\n",
    "    return img_dir_info, word_var_report[6], conf_set\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GIS Data (477196,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 477196/477196 [01:47<00:00, 4445.50it/s]\n",
      "100%|██████████| 1290899/1290899 [04:41<00:00, 4582.73it/s]\n"
     ]
    }
   ],
   "source": [
    "gis_data = load_and_clean_gis_data()\n",
    "text_phoc_info = gen_text_phoc_embs(gis_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting Images to Embeddings:   1%|1         | 5/371 [00:00<00:07, 49.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D0006-0285025\n",
      "Images Shape  (371, 3, 135, 487)\n",
      "Words Shape  (371,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting Images to Embeddings: 100%|##########| 371/371 [00:06<00:00, 61.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "328\n",
      "Original Accuracy  0.19512195122\n",
      "Accuracy With Word Variations  0.216463414634\n",
      "D0017-1592006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting Images to Embeddings:   1%|          | 6/716 [00:00<00:12, 55.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images Shape  (716, 3, 135, 487)\n",
      "Words Shape  (716,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting Images to Embeddings: 100%|##########| 716/716 [00:11<00:00, 63.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "705\n",
      "Original Accuracy  0.222695035461\n",
      "Accuracy With Word Variations  0.258156028369\n",
      "D0041-5370006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "strlocale.py:137: UnicodeWarning: Unicode equal comparison failed to convert both arguments to Unicode - interpreting them as being unequal\n",
      "  if c in self._diacrit_dict: # Replace simple diacritic\n",
      "strlocale.py:152: UnicodeWarning: Unicode equal comparison failed to convert both arguments to Unicode - interpreting them as being unequal\n",
      "  return [c if (c not in self.__filtered) else u'' for c in chars]\n",
      "Converting Images to Embeddings:   1%|1         | 6/514 [00:00<00:09, 54.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images Shape  (514, 3, 135, 487)\n",
      "Words Shape  (514,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting Images to Embeddings: 100%|##########| 514/514 [00:08<00:00, 63.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "492\n",
      "Original Accuracy  0.115853658537\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting Images to Embeddings:   2%|1         | 6/398 [00:00<00:07, 55.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy With Word Variations  0.123983739837\n",
      "D0041-5370026\n",
      "Images Shape  (398, 3, 135, 487)\n",
      "Words Shape  (398,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting Images to Embeddings: 100%|##########| 398/398 [00:06<00:00, 63.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "365\n",
      "Original Accuracy  0.13698630137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Converting Images to Embeddings:   0%|          | 0/1188 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy With Word Variations  0.205479452055\n",
      "D0042-1070001\n",
      "Images Shape  (1188, 3, 135, 487)\n",
      "Words Shape  (1188,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting Images to Embeddings: 100%|##########| 1188/1188 [00:18<00:00, 63.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "875\n",
      "Original Accuracy  0.225142857143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Converting Images to Embeddings:   0%|          | 0/692 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy With Word Variations  0.269714285714\n",
      "D0042-1070002\n",
      "Images Shape  (692, 3, 135, 487)\n",
      "Words Shape  (692,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting Images to Embeddings: 100%|##########| 692/692 [00:10<00:00, 63.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "631\n",
      "Original Accuracy  0.198098256735\n",
      "Accuracy With Word Variations  0.234548335975\n",
      "D0042-1070003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting Images to Embeddings:   1%|          | 6/1090 [00:00<00:20, 54.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images Shape  (1090, 3, 135, 487)\n",
      "Words Shape  (1090,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting Images to Embeddings: 100%|##########| 1090/1090 [00:17<00:00, 63.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "869\n",
      "Original Accuracy  0.262370540852\n",
      "Accuracy With Word Variations  0.26582278481\n",
      "D0042-1070004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting Images to Embeddings:   0%|          | 5/1189 [00:00<00:25, 46.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images Shape  (1189, 3, 135, 487)\n",
      "Words Shape  (1189,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting Images to Embeddings: 100%|##########| 1189/1189 [00:18<00:00, 64.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1001\n",
      "Original Accuracy  0.20979020979\n"
     ]
    }
   ],
   "source": [
    "global_stats = {'correct_original':0, 'correct_word_var':0, 'total':0}\n",
    "\n",
    "for i in tqdm(range(len(A)), ascii=True, desc = 'Main Iteration'):\n",
    "    print A[i]\n",
    "    img_dir_info, words, conf_words = image_ext_with_word_var(A[i], cnn, gis_data, text_phoc_info, global_stats)\n",
    "    # np.save('../../../images_to_extend/image_dir_'+A[i]+'.npy', img_dir_info)\n",
    "    # np.save('../../../images_to_extend/image_labels_'+A[i]+'.npy', words)\n",
    "print 'Accuracy Original', global_stats['correct_original']/float(global_stats['total'])\n",
    "print 'Accuracy With Word Variations', global_stats['correct_word_var']/float(global_stats['total'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # image plot using the variations\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# count, matched_words, qualified_ids, img_dirs, words_len, new_outputs, new_word_strings, \\\n",
    "# = report_matches_with_variations(outputs, embedding_var,'cosine', word_strings,word_var_strings,1, 2)\n",
    "\n",
    "# img_dir_info = np.array([qualified_ids, img_dirs, words_len, new_word_strings])\n",
    "\n",
    "# print \"the accuracy is: \"+str(count/float(len(new_word_strings)))\n",
    "\n",
    "# _len = min(100, len(matched_words))\n",
    "# new_images = images[qualified_ids]\n",
    "# for i in range(_len):\n",
    "#     print \"************************************************************************\"\n",
    "#     print \"************************************************************************\"\n",
    "#     print \"Original image:\"\n",
    "#     q = np.transpose(new_images[i],(1,2,0))\n",
    "#     plt.imshow(q)\n",
    "#     plt.show()\n",
    "#     print \"the matched words are (inorder): \"+str(matched_words[i])\n",
    "#     print \"the gound truth is:\" + str(new_word_strings[i])\n",
    "#     print \"------------------------------------------------------------------------\"\n",
    "#     print \"------------------------------------------------------------------------\"\n",
    "# pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # image plots using original without variation method for comparisons\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# count, matched_words, new_outputs, new_embedding, new_word_strings, \\\n",
    "#     qualified_ids = report_matches(outputs, embedding, 'cosine', word_strings, 1, 2)\n",
    "\n",
    "# print \"the accuracy is: \"+str(count/float(len(new_word_strings)))\n",
    "\n",
    "# _len = min(100, len(matched_words))\n",
    "# new_images = images[qualified_ids]\n",
    "# for i in range(_len):\n",
    "#     print \"************************************************************************\"\n",
    "#     print \"************************************************************************\"\n",
    "#     print \"Original image:\"\n",
    "#     q = np.transpose(new_images[i],(1,2,0))\n",
    "#     plt.imshow(q)\n",
    "#     plt.show()\n",
    "#     print \"the matched words are (inorder): \"+str(matched_words[i])\n",
    "#     print \"the gound truth is:\" + str(new_word_strings[i])\n",
    "#     print \"------------------------------------------------------------------------\"\n",
    "#     print \"------------------------------------------------------------------------\"\n",
    "# pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
