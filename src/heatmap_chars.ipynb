{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def int_coords(coord_old,coord_new,direction):\n",
    "#     coords = coord_old\n",
    "#     coords=np.vstack((coords,coord_new))\n",
    "#     print(coords.shape,'coordsshape',coord_old.shape,coord_new.shape)\n",
    "#     s = [(coor[0],coor[1]) for coor in coord_old]\n",
    "#     s.extend([(coor[0],coor[1]) for coor in coord_new])\n",
    "#     c = collections.Counter(s)\n",
    "# #     s.extend([(coor[0],coor[1]) for coor in coords])\n",
    "# #     for coord in coord_old:\n",
    "# #         print(coord,'coord old')\n",
    "# #         s.add((coord[0],coord[1]))\n",
    "# #     for coord in coord_new:\n",
    "# #         print(coord,'coord new')\n",
    "# #         s.add((coord[0],coord[1]))\n",
    "#     points = []\n",
    "#     for key in c:\n",
    "#         if c[key]==1:\n",
    "#             if \n",
    "#             points.append(key)\n",
    "#     print(points)\n",
    "    if direction==-1:\n",
    "        points = [list(coord_old[1]),list(coord_new[1]),list(coord_new[2]),list(coord_old[2])]\n",
    "    elif direction==(1):\n",
    "        points = [list(coord_new[0]),list(coord_old[0]),list(coord_old[3]),list(coord_new[3])]\n",
    "    else:\n",
    "        points = [list(coord_new[0]),list(coord_new[1]),list(coord_new[2]),list(coord_new[3])]\n",
    "    return list(points)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"def int_coords(coord_old,coord_new):\\n    \\n    if np.sum(coord_old == coord_new)==coord_old.size:\\n        return [(0,0),(0,0)]\\n    else:\\n        print('Coords old:',np.sum(coord_old==coord_new),len(coord_old),coord_old)\\n    height_old = coord_old[1][1]-coord_old[0][1]\\n    width_old = coord_old[1][0]-coord_old[0][0]\\n    height_new = coord_new[1][1]-coord_new[0][1]\\n    width_new = coord_new[1][0]-coord_new[0][0]\\n    if width_new>width_old:\\n        if (coord_new[1][0])>(coord_old[1][0]):\\n            new_left_x = coord_old[1][0]\\n            new_right_x = coord_new[1][0]\\n            new_left_y = coord_new[0][1]\\n            new_right_y = coord_new[1][1]\\n#             print('old',coord_old,'new',coord_new,'right',[(new_left_x,new_left_y),(new_right_x,new_right_y)])\\n            \\n        else:\\n            new_left_x = coord_old[0][0]\\n            new_right_x = coord_new[0][0]\\n            new_left_y = coord_new[0][1]\\n            new_right_y = coord_new[0][1]+height_new\\n#             print('old',coord_old,'new',coord_new,'left',[(new_left_x,new_left_y),(new_right_x,new_right_y)])\\n#     elif height_new>height_old:\\n#         if (coord_new[1][1])>(coord_old[1][1]):\\n#             new_left_x = coord_old[1][0]\\n#             new_right_x = coord_new[1][0]\\n#             new_left_y = coord_old[1][1]-width_old\\n#             new_right_y = coord_new[1][1]\\n#         else:\\n#             new_left_x = coord_new[0][0]\\n#             new_right_x = coord_old[0][0]+width_old\\n#             new_left_y = coord_new[0][1]\\n#             new_right_y = coord_old[0][1]\\n    else:\\n        new_left_x = coord_old[0][0]\\n        new_right_x = coord_old[1][0]\\n        new_left_y = coord_old[0][1]\\n        new_right_y = coord_old[1][1]\\n    return [(new_left_x,new_left_y),(new_right_x,new_right_y)]\\n    \""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''def int_coords(coord_old,coord_new):\n",
    "    \n",
    "    if np.sum(coord_old == coord_new)==coord_old.size:\n",
    "        return [(0,0),(0,0)]\n",
    "    else:\n",
    "        print('Coords old:',np.sum(coord_old==coord_new),len(coord_old),coord_old)\n",
    "    height_old = coord_old[1][1]-coord_old[0][1]\n",
    "    width_old = coord_old[1][0]-coord_old[0][0]\n",
    "    height_new = coord_new[1][1]-coord_new[0][1]\n",
    "    width_new = coord_new[1][0]-coord_new[0][0]\n",
    "    if width_new>width_old:\n",
    "        if (coord_new[1][0])>(coord_old[1][0]):\n",
    "            new_left_x = coord_old[1][0]\n",
    "            new_right_x = coord_new[1][0]\n",
    "            new_left_y = coord_new[0][1]\n",
    "            new_right_y = coord_new[1][1]\n",
    "#             print('old',coord_old,'new',coord_new,'right',[(new_left_x,new_left_y),(new_right_x,new_right_y)])\n",
    "            \n",
    "        else:\n",
    "            new_left_x = coord_old[0][0]\n",
    "            new_right_x = coord_new[0][0]\n",
    "            new_left_y = coord_new[0][1]\n",
    "            new_right_y = coord_new[0][1]+height_new\n",
    "#             print('old',coord_old,'new',coord_new,'left',[(new_left_x,new_left_y),(new_right_x,new_right_y)])\n",
    "#     elif height_new>height_old:\n",
    "#         if (coord_new[1][1])>(coord_old[1][1]):\n",
    "#             new_left_x = coord_old[1][0]\n",
    "#             new_right_x = coord_new[1][0]\n",
    "#             new_left_y = coord_old[1][1]-width_old\n",
    "#             new_right_y = coord_new[1][1]\n",
    "#         else:\n",
    "#             new_left_x = coord_new[0][0]\n",
    "#             new_right_x = coord_old[0][0]+width_old\n",
    "#             new_left_y = coord_new[0][1]\n",
    "#             new_right_y = coord_old[0][1]\n",
    "    else:\n",
    "        new_left_x = coord_old[0][0]\n",
    "        new_right_x = coord_old[1][0]\n",
    "        new_left_y = coord_old[0][1]\n",
    "        new_right_y = coord_old[1][1]\n",
    "    return [(new_left_x,new_left_y),(new_right_x,new_right_y)]\n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import string\n",
    "# For one char\n",
    "def maps(words_old,words_new,coords_old,coords_new,dir,gt,id):\n",
    "    '''\n",
    "    words_old = list of words matched which are the variations of original word\n",
    "    words_new = list of words matched after extending the region to include 1 more char\n",
    "    coords_old = region coordinates in a list of list of tuples of (top left, bottom right) before extending the region\n",
    "    coords_new = region after extending to include one char\n",
    "    returns:\n",
    "    c_map = dictionary of characters to coordinates\n",
    "    '''\n",
    "    c_map = {}\n",
    "    g_map = {}\n",
    "    for a in string.ascii_lowercase:\n",
    "        c_map[a] = []\n",
    "#     for A in string.ascii_uppercase:\n",
    "#         c_map[A] = []\n",
    "    for i in range(len(id)):  \n",
    "        word = words_old[i].lower()\n",
    "#         if(words_new[i].lower()!=gt[i].lower() and word.lower()!=gt[i].lower()):\n",
    "#             print(word,words_new[i],gt[i],gt[i]==words_new[i])\n",
    "        if dir[i]:\n",
    "            if word.lower() == words_new[i][1:].lower():\n",
    "                char_coords = int_coords(coords_old[id[i]],coords_new[i],dir[i])\n",
    "                l = c_map.get(words_new[i][0].lower(),[])\n",
    "                l.append(char_coords)\n",
    "                print('left',word.lower(),words_new[i].lower(),dir[i])\n",
    "# #                 print('left',char_coords,'old',coords_all[i],'new',coords_new_all[i],words_new[i][0],'gt',gt[i],'old',words_old[i],'new',words_new[i],'id',id[i],'dir',dir[i])\n",
    "                c_map[words_new[i][0].lower()] = l\n",
    "            elif word.lower() == words_new[i][:-1].lower():\n",
    "                char_coords = int_coords(coords_old[id[i]],coords_new[i],dir[i])\n",
    "                l = c_map.get(words_new[i][-1].lower(),[])\n",
    "                l.append(char_coords)\n",
    "                print('right',word.lower(),words_new[i].lower(),dir[i])\n",
    "#                 print('left',char_coords,'old',coords_all[i],'new',coords_new_all[i],words_new[i][-1],'gt',gt[i],'old',words_old[i],'new',words_new[i],'id',id[i],'dir',dir[i])\n",
    "                c_map[words_new[i][-1].lower()] = l\n",
    "    return c_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['D0006-0285025.npy', 'D0017-1592006.npy', 'D0041-5370006.npy', 'D0041-5370026.npy', 'D0042-1070001.npy', 'D0042-1070002.npy', 'D0042-1070003.npy', 'D0042-1070004.npy', 'D0042-1070005.npy', 'D0042-1070006.npy', 'D0042-1070007.npy', 'D0042-1070009.npy', 'D0042-1070010.npy', 'D0042-1070012.npy', 'D0042-1070015.npy', 'D0079-0019007.npy', 'D0089-5235001.npy', 'D0090-5242001.npy', 'D0117-5755018.npy', 'D0117-5755024.npy', 'D0117-5755025.npy', 'D0117-5755033.npy']\n",
      "(22, 'D0089-5235001.npy')\n",
      "D0089-5235001\n",
      "(439, 4, 2)\n",
      "5278\n",
      "(331, 4, 2)\n",
      "images to extend\n",
      "(3, 331)\n",
      "((331,), 'ids')\n",
      "('dirs', (331,))\n"
     ]
    }
   ],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "mypath = '../../training_mudit/'\n",
    "fNs = [f for f in listdir('../../training_mudit/') if isfile(join(mypath, f))]\n",
    "print(fNs)\n",
    "i = 16\n",
    "print(len(fNs),fNs[16])\n",
    "fN = fNs[i][:-4]\n",
    "print(fN)\n",
    "coords_old = np.load('../../training_old/'+fN+'.npy')\n",
    "print(coords_old.shape)\n",
    "print((coords_old[:][0][0][0]))\n",
    "#D0117-5755018.npy\n",
    "# coords_old_all = np.load('../detection_outputs/D0090-5242001.npy')\n",
    "# print(coords_new_all.shape)\n",
    "coords_new = np.load('../../training_new/'+fN+'.npy')\n",
    "# coords_new = np.array([[coords_new_all[i][3],coords_new_all[i][1]] for i in range(coords_new_all.shape[0])])\n",
    "print(coords_new.shape)\n",
    "extend = np.load('../../training_images/image_dir_'+fN+'.npy')\n",
    "print('images to extend')\n",
    "print(extend.shape)\n",
    "#extend : 0-ids, 1-dirs, 2-word lengths\n",
    "# coords_new_all = np.load('../detection_outputs_new/D0090-5242001.npy')\n",
    "# coords_new = np.array([[coords_new_all[i][3],coords_new_all[i][1]] for i in range(coords_new_all.shape[0])])\n",
    "ids = extend[0]\n",
    "# coords_old = np.array([[coords_old_all[i][3],coords_old_all[i][1]] for i in ids[0]])\n",
    "# print(coords_old.shape,coords_new.shape,ids.shape)\n",
    "print(ids.shape,'ids')\n",
    "dir = extend[1]\n",
    "print('dirs',dir.shape)\n",
    "# print(zip(coords_old[ids],coords_new,dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('no.of.keys', 671)\n",
      "('minmax', array([0.]), array([631.]))\n",
      "331\n"
     ]
    }
   ],
   "source": [
    "# fN = 'D0090-5242001'\n",
    "align_fN='../../detection_alignment/'+fN+'.npy' #90 has 536 entries\n",
    "annot_fN='../../jerods_annotations/'+fN+'.npy' #90 has 604 keys in the dictionary\n",
    "aligns=np.load(align_fN)\n",
    "annots=np.load(annot_fN).item()\n",
    "print('no.of.keys',len(annots.keys()))\n",
    "gt = []\n",
    "import collections\n",
    "print('minmax',min(aligns),max(aligns))\n",
    "for i in range(0,len(ids)):\n",
    "    if aligns[ids[i]]==0:\n",
    "        gt.append('no label')\n",
    "        continue\n",
    "#     print('i,ids[i]',i,ids[i],'aligns[ids[i]]',int(aligns[ids[i]][0]))\n",
    "#           annots[int(aligns[ids[i]][0])]\n",
    "    gt.append(annots[int(aligns[ids[i]][0])-1]['name'])\n",
    "#     print(annots[aligns[ids[i]][0]-1]['name'])\n",
    "    \n",
    "print(len(gt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['CONNECTIONS' 'AND' 'ed' 'line' 'CIT' \"G'\" 'Collection' 'NORTHERN'\n",
      "  'REGON' 'RAILROAD' 'TS.' '.P.' 'David' 'HOR' '.p.' \"G'\" 'IG' 'forks'\n",
      "  'PACIFIC' 'TS.' 'LAKE.' 'Cartography' 'ORT' 'Re' 'mouse' 'ST.' 'AN'\n",
      "  'MA' 'Miles' 'ashington' 'TS.' \"G'\" 'Mous' 'T.' 'FORT' 'norther'\n",
      "  'CARTOGRAPH' 'MINN.' \"'D\" 'T.' 'S.C' 'BLACK' 'TS.' 'ENNETT' 'MTS'\n",
      "  'ST.P.' 'DAVI' \"G'\" 'TANDING' 'Ill' '.p.' 'ARTOGRAPHY' 'WALSH'\n",
      "  'NATIONA' 'nternational' 'IG' 's.c.' 'ill.' 'WINNEPE' 'PAC.' 'HELENA'\n",
      "  'ELL' 'DIVID' 'st' 'SNAKE' 'ort' 'snake' 'LAKE.' 'City' 's.c' '00'\n",
      "  'Mil' 'lympia' 'AUL' 'Devil' 'Associates' '.P.' 'CARTOGRAPH' 'S.C'\n",
      "  'BOUNDARY' 'RE' 'FOR' 'Mcleo' 'ENNETT' 'river' 'wals' 'ouse' 'ITY'\n",
      "  'st.' 'LL.' 'railroa' 'PAU' 'ST.' 'TS.' 'hel' 'ST' 'AKE' 'BIG' 'LAKE'\n",
      "  '.p.' 'centra' 're' 'ED' 'OUNDARY' 'RIVE' 'FOR' \"G'\" 'TENIN'\n",
      "  'ASHINGTON' 'ig' 'RAILROA' 'lin' 'CENTRA' 'LAKE' 'st' 'SNAKE' 'custe'\n",
      "  'teto' 'crystal' 'ouse' 'DIV' 'aul' 'IG' 'Carroll' '16th' 'PACIFI'\n",
      "  'div' 'INE' 'll.' 'yellowston' 'KENZIES' 's.c' 'ap' 'S.c.' 'ST' 'lake'\n",
      "  'river' 'ashlan' 'ig' 'ORT' 'iles' 'RIVERS' 'ivers.' 'Oregon' 'RANG'\n",
      "  'ort' 'Saskatchewa' 'AP' 'no label attached' 'HELENA' 'FT.' 'Mts.' 'ST'\n",
      "  'golden' 'PORTLAND' 'RED' 'LAKE' 'Pacifi' 'S.C' 'ELENA' 'FT.' 'div'\n",
      "  'S.C' 'RYSTAL' 'ts.' 'NAKE' \"g'\" 'city' 'PACIFI' 'ED' 's.c' 'st' 'ND'\n",
      "  'T.' 'IOW' 'cit' 'NORTHERN' 'ITY' 's.c.' 'ashlan' 'CRYSTA' 'bi' 'T.'\n",
      "  'yellowston' 'Railroa' 'olympia' 'ft' 'YELLOWSTON' '.C.' 'KENZIE'\n",
      "  'Orego' 'PAC' 'T.' 'ILL' 'ND' 'st.' 'Pac' 'ORN' '00' 'TS.' 'TS.' \"G'\"\n",
      "  'IV.' 'pac.' 'LAK' 'TS.' 'RE' 'FOR' 'ts.' 'DIVID' 'ERMILLION' 'ort'\n",
      "  'CONNECTIONS' 's.c' 'wyoming' 'CITY' 'ED' \"G'\" 'rive' 'orks' 'T.'\n",
      "  'crystal' 'LL.' 'Branc' 'ig' 'st' \"g'\" 'ig' 'rang' 'ST' 'ST' 'ouse'\n",
      "  'SNAKE' 'ouse' 'Forks' 'hor' 'RIVE' 'OCKY' 'DIVID' 'RIVER' 'S.C.'\n",
      "  'golde' 'St.p' \"g'\" 'Helena' 'british' 'ts.' 'St.p' 'Pau' 'Oregon'\n",
      "  'ity' 'SSOCIATES,' 'devils' 'MILES' 'ST.' \"G'\" 'S.C' 'PORTLAND'\n",
      "  'WYOMIN' 'AINY' 'st.' 'MTS' 'AINY' 'ITY' 'STANDIN' 'ivide' 'Kenzies'\n",
      "  'SUPERIO' 'ac.' 'ap' 'BOUNDARY' 'BOUNDARY' 'BOUNDARY' 'BOUNDARY'\n",
      "  'BOUNDARY' 'BOUNDARY' 'BOUNDARY' 'BOUNDARY' 'BOUNDARY' 'BOUNDARY'\n",
      "  'BOUNDARY' 'BOUNDARY' 'BOUNDARY' 'BOUNDARY' 'BOUNDARY' 'BOUNDARY'\n",
      "  'BOUNDARY' 'BOUNDARY' 'BOUNDARY' 'BOUNDARY' 'BOUNDARY' 'BOUNDARY'\n",
      "  'BOUNDARY' 'BOUNDARY' 'BOUNDARY' 'BOUNDARY' 'BOUNDARY' 'BOUNDARY'\n",
      "  'BOUNDARY' 'BOUNDARY' 'BOUNDARY' 'BOUNDARY' 'BOUNDARY' 'BOUNDARY'\n",
      "  'BOUNDARY' 'BOUNDARY' 'BOUNDARY' 'BOUNDARY' 'BOUNDARY' 'BOUNDARY'\n",
      "  'popla' 'cit' 'OLDEN' 'St.p.' 'ainy' 'CAM' 'RAILROA' 'TS.' 'OREGON'\n",
      "  'AKE' 'Associates' 'st' 'ASSOCIATES' 'SUPERIO' 'COLLECTION' 'RAILROA'\n",
      "  'ts.' 'IG' 'MILES' 'T.' 'and']\n",
      " ['CONNECTIONS.' 'AND' 're' 'line' 'FORKS' 'll.' 'Collection' 'NORTHERN'\n",
      "  'teton' 'RAILROAD' 'ST' 'amp' 'David' 'Horn' '.P.' 'RED' 'REILLE'\n",
      "  'forks' 'PACIFIC' 'TS.' 'LAKE.' 'Cartography' 'ENTRAL' 'ma' 'mouse'\n",
      "  'ST.' 'MINN.' 'SSOCIATES,' 'Miles' 'city' 's.c.' 'Golde' 'Mouse'\n",
      "  'MILES' 'FORT' 'FOR' 'BI' 'MINN.' 'MA' 'MILE' 'COLUMBI' 'BLACK' 'LAK'\n",
      "  'ST' 'st' 'ST.P.' 'DAVI' \"G'\" 'rain' 'associates' 'CAM' 'RED' 'WALSH'\n",
      "  'NATIONAL' 'nternational' 'EVILS' 's.c.' 'ill.' 'WINNEPEG' 'PAC.'\n",
      "  'HELENA' 'helen' 'DEVIL' 'uster' 'SNAKE' 'eton' 'snake' 'LAKE.' 'City'\n",
      "  'cam' 'IOW' 'MILK' 'popla' 'BI' 'divid' 'Associates,' '.P.' 'TS.'\n",
      "  'COLLECTION' 'BOUNDARY' 'BRECKENRIDGE' 'MOUSE' 'OREGO' 'cit' 'river'\n",
      "  'wals' 'custe' 'ITY' 'st.' 'LL.' 'ASSOCIATES' 'LYMPIA' 'ST.' '.P.'\n",
      "  'WALS' 'BLACK' 'ILK' 'BIG' 'LAKE' 'IVERS.' 'Crysta' 'orego' 'red'\n",
      "  'IVER' 'River' 'AUL' \"G'\" 'TENIN' 'ST' 'st.p.' 'Rain' 'CONNECTIONS'\n",
      "  'T.' 'LAKE' 'ap' 'SNAKE' 'custer' 'ft' 'crystal' 'S.C.' 'DAVI' 'FT.'\n",
      "  'll.' 'Carroll' '16th' 'FT' 'div' 'ELL' 'ILL.' 'yellowston' 'KENZIES'\n",
      "  's.c.' \"g'\" 'S.c.' '.c.' 'lake' 'river' 'Crystal' 'ig' 'ATIONAL'\n",
      "  'ritish' 'RIVERS' 'st.p.' 'Oregon' 'TACOM' 're' 'Rive' '.C.'\n",
      "  'no label attached' 'HELENA' 'FT.' 'Mts.' 'st' 'golden' 'PORTLAND'\n",
      "  'RED' 'LAKE' 'IG' \"g'\" 'Popla' 'FT.' \"'d\" 'st.' 'IOWA' 'associates,'\n",
      "  'T.' 'ED' 'city' 'PACIFIC' 'ivers.' 'ST' 'ity' 'ND' 'SUPERIOR' 'DAVID'\n",
      "  'ac.' 'NORTHERN' 'cartography' 's.c.' 'Ashlan' 'BRANC' 'superior' 'aul'\n",
      "  'yellowstone' 'LL.' 'olympia' 't.' 'ENINO' 'miles' 'AKE' 'ORT' 'DIV'\n",
      "  'T.' 'aul' 'IV.' 'st.' 'wals' 'ETON' '00' 'ts.' 'ITY' 'll.' 'DAVID'\n",
      "  'pac.' 'LAK' 'CITY' 'RAINY' 'ig' 'ts.' 'DIVID' 'BI' 'ORT' 'ONNECTIONS.'\n",
      "  'WINNIPE' 'wyoming' 'CITY' 'red' \"G'\" 'river' 'MTS' 'MTS' 'crystal'\n",
      "  'LAK' 'Branc' 'Rang' 'St.' 'snak' 'mile' 'For' 'St.' 'ENINO' 'Custe'\n",
      "  'SNAKE' 'mts.' 'Forks' 'Devils' 'iver' 'OCKY' 'IVIDE' 'RIVER' 'S.C.'\n",
      "  'll.' 'St.p.' \"g'd\" 'Helena' 'british' 'OLUMBIA' 'St.p' 'ma' 'Oregon'\n",
      "  'city' 'IOW' 'devils' 'MILES' 'ST.' 'Golde' 'St.p.' 'PORTLAND' 'IOWA'\n",
      "  'ITY' 'st.' \"G'\" 'MINN' 'teto' 'TS.' 'ivide' 'Kenzies' 'PAC' 'T.'\n",
      "  'COLUMBI' 'BOUNDARY' 'BOUNDARY' 'BOUNDARY' 'BOUNDARY' 'BOUNDARY'\n",
      "  'BOUNDARY' 'BOUNDARY' 'BOUNDARY' 'BOUNDARY' 'BOUNDARY' 'BOUNDARY'\n",
      "  'BOUNDARY' 'BOUNDARY' 'BOUNDARY' 'BOUNDARY' 'BOUNDARY' 'BOUNDARY'\n",
      "  'BOUNDARY' 'BOUNDARY' 'BOUNDARY' 'BOUNDARY' 'BOUNDARY' 'BOUNDARY'\n",
      "  'BOUNDARY' 'BOUNDARY' 'BOUNDARY' 'BOUNDARY' 'BOUNDARY' 'BOUNDARY'\n",
      "  'BOUNDARY' 'BOUNDARY' 'BOUNDARY' 'BOUNDARY' 'BOUNDARY' 'BOUNDARY'\n",
      "  'BOUNDARY' 'BOUNDARY' 'BOUNDARY' 'BOUNDARY' 'BOUNDARY' 'hell' 't.'\n",
      "  'DIVIDE' 'St.p.' 'Rang' 'AC.' 'ST.' 'crysta' 'OREGON' 'ST' 'Associates'\n",
      "  'aul' \"G'\" \"'D\" 'COLLECTION' 'PAC.' 'ap' 'wals' 'MILES' 'CIT' 'and']\n",
      " ['AND' 'AND' 'COLUMBIA' '114' 'WINNEPEG' '110' 'Collection' 'NORTHERN'\n",
      "  '110' 'RAILROAD,' 'WYOMING' 'MAP' 'David' '102' 'SASKATCHEWAN'\n",
      "  'WASHINGTON' '114' '104' 'PACIFIC' 'WYOMING' 'BLACK' 'Cartography'\n",
      "  'RAINY' 'David' '104' 'SASKATCHEWAN' 'OREGON' 'Custer' '118' 'Golden'\n",
      "  'SASKATCHEWAN' '106' '108' '120' 'NORTHERN' 'Fort' 'SASKATCHEWAN'\n",
      "  'MANITOBA' 'SASKATCHEWAN' 'BOUNDARY' 'RAINY' 'NATIONAL' 'SASKATCHEWAN'\n",
      "  'SASKATCHEWAN' 'no label attached' 'COLUMBIA' 'BOUNDARY' 'OREGON' 'Ft.'\n",
      "  'Ft.' 'MANITOBA' 'OREGON' 'Walsh' 'INTERNATIONAL' 'Kenzies' '116'\n",
      "  'SASKATCHEWAN' 'BIG' 'WINNIPEG' 'PACIFIC' 'HELENA' 'RAINY' 'DIV.' 'Ft.'\n",
      "  'INTERNATIONAL' 'Fort' 'Lake' 'LAKE.' 'City' 'RANGE' 'OREGON' 'Milk'\n",
      "  'Ft.' 'MANITOBA' 'MANITOBA' 'Associates,' 'N.P.' 'MANITOBA'\n",
      "  'no label attached' 'AND' 'no label attached' '106' '116' 'S.C.'\n",
      "  'River' 'BRITISH' 'no label attached' 'WYOMING' 'SASKATCHEWAN'\n",
      "  'SUPERIOR' '128' 'WASHINGTON' 'YELLOWSTONE' 'WINNEPEG' 'SASKATCHEWAN'\n",
      "  'MANITOBA' 'LAKE' '124' 'LAKE' 'Snake' 'no label attached' 'Sulphur'\n",
      "  'SASKATCHEWAN' 'NORTHERN' 'Poplar' 'no label attached' \"G'd\"\n",
      "  'INTERNATIONAL' 'Ft.' 'no label attached' 'RAILROAD' 'WINNEPEG'\n",
      "  'Rivers.' 'VERMILLION' 'no label attached' 'LAKE' 'Fort' 'Ft.'\n",
      "  'COLUMBIA' 'Fort' 'MANITOBA' 'OREGON' 'WINNIPEG' 'Carroll' 'Ft.'\n",
      "  'DEADWOOD' 'SASKATCHEWAN' 'COLUMBIA' 'ILL.' 'MANITOBA' 'WASHINGTON'\n",
      "  'no label attached' 'WASHINGTON' '120' 'PAUL' 'Red' 'River' 'Camp'\n",
      "  'Kampeska' 'Horn' 'ST.' 'RIVER' 'Fork' 'MTS.' '126' 'Ft.' 'MTS.'\n",
      "  'CENTRAL' 'Ft.' 'HELENA' 'OREGON' '114' 'WYOMING' 'IOWA' 'PORTLAND'\n",
      "  'WASHINGTON' 'LAKE.' '116' 'WINNEPEG' 'N.P.' 'OREGON' 'OREGON'\n",
      "  'SASKATCHEWAN' 'SASKATCHEWAN' '118' 'WASHINGTON' 'OREGON' 'Ft.'\n",
      "  'PACIFIC' 'SUPERIOR' 'no label attached' 'Golden' 'AND' 'WASHINGTON'\n",
      "  'WYOMING' 'COLUMBIA' 'NORTHERN' 'COLUMBIA' 'WASHINGTON' 'Ashland'\n",
      "  'S.C.' 'RANGE' 'WASHINGTON' 'Milk' '110' 'Olympia' 'Ft.' 'Tenino'\n",
      "  'WASHINGTON' 'SASKATCHEWAN' 'OREILLE' 'BRITISH' 'BOUNDARY' '114'\n",
      "  'SASKATCHEWAN' 'SASKATCHEWAN' 'BRITISH' 'CONNECTIONS.' 'OREGON'\n",
      "  'no label attached' 'MANITOBA' 'Custer' 'SASKATCHEWAN' 'McLeod'\n",
      "  'SASKATCHEWAN' 'WASHINGTON' 'no label attached' 'BRITISH'\n",
      "  'no label attached' 'DIV.' 'Ft.' 'Ft.' 'RAILROAD,' 'COLUMBIA' 'Miles'\n",
      "  'City' 'SASKATCHEWAN' \"G'd\" 'River' 'Crystal' 'INTERNATIONAL' 'Ft.'\n",
      "  'SUPERIOR' 'Branch' 'Camp' 'Ft.' 'Ft.' 'Kampeska' 'MANITOBA' 'Fort'\n",
      "  \"G'd\" 'Ft.' 'RANGE' 'Ft.' 'SASKATCHEWAN' 'BOUNDARY' 'River' 'ROCKY'\n",
      "  '116' 'RIVER' 'MTS.' 'Mouse' 'ST.P.' 'Ft.' 'Hell' 'Ft.' 'LINE' 'ST.P.'\n",
      "  'N.P.' 'Oregon' 'City' 'IOWA' 'Ft.' 'City' 'OREGON' 'WASHINGTON'\n",
      "  'SASKATCHEWAN' 'PORTLAND' 'WASHINGTON' 'WYOMING' 'WINNEPEG' 'COLUMBIA'\n",
      "  'MINN.' 'OREGON' 'ST.' 'Miles' 'WASHINGTON' 'PAC.' 'WASHINGTON'\n",
      "  'BRITISH' 'INTERNATIONAL' 'SASKATCHEWAN' '104' 'Breckenridge' 'Ft.'\n",
      "  'MANITOBA' 'Fort' 'Ft.' 'BOUNDARY' 'Carroll' 'Ft.' \"G'd\" 'Ft.'\n",
      "  'SASKATCHEWAN' 'YELLOWSTONE' 'Camp' 'WYOMING' '100' 'Sulphur'\n",
      "  'WINNEPEG' 'MANITOBA' 'Standing' 'PACIFIC' 'Kampeska' 'Fort' 'DEVILS'\n",
      "  'Big' 'Ft.' 'Ft.' '100' 'Ft.' 'NATIONAL' 'ST.' 'Miles' 'Teton' 'Fort'\n",
      "  'BOUNDARY' 'Ft.' 'Fort' '102' 'Hell' 'Ft.' 'DIVIDE' 'ST.P.' 'Bennett'\n",
      "  'Mouse' 'N.P.' 'Fork' 'Tacoma' 'WASHINGTON' 'Ft.' 'Ft.' 'COLUMBIA'\n",
      "  'SASKATCHEWAN' 'Forks' 'PAC.' '16th' 'no label attached' 'MINN.' 'ST.'\n",
      "  'Ft.']]\n",
      "[('CONNECTIONS', 'CONNECTIONS.'), ('AND', 'AND'), ('ed', 're'), ('line', 'line'), ('CIT', 'FORKS'), (\"G'\", 'll.'), ('Collection', 'Collection'), ('NORTHERN', 'NORTHERN'), ('REGON', 'teton'), ('RAILROAD', 'RAILROAD'), ('TS.', 'ST'), ('.P.', 'amp'), ('David', 'David'), ('HOR', 'Horn'), ('.p.', '.P.'), (\"G'\", 'RED'), ('IG', 'REILLE'), ('forks', 'forks'), ('PACIFIC', 'PACIFIC'), ('TS.', 'TS.'), ('LAKE.', 'LAKE.'), ('Cartography', 'Cartography'), ('ORT', 'ENTRAL'), ('Re', 'ma'), ('mouse', 'mouse'), ('ST.', 'ST.'), ('AN', 'MINN.'), ('MA', 'SSOCIATES,'), ('Miles', 'Miles'), ('ashington', 'city'), ('TS.', 's.c.'), (\"G'\", 'Golde'), ('Mous', 'Mouse'), ('T.', 'MILES'), ('FORT', 'FORT'), ('norther', 'FOR'), ('CARTOGRAPH', 'BI'), ('MINN.', 'MINN.'), (\"'D\", 'MA'), ('T.', 'MILE'), ('S.C', 'COLUMBI'), ('BLACK', 'BLACK'), ('TS.', 'LAK'), ('ENNETT', 'ST'), ('MTS', 'st'), ('ST.P.', 'ST.P.'), ('DAVI', 'DAVI'), (\"G'\", \"G'\"), ('TANDING', 'rain'), ('Ill', 'associates'), ('.p.', 'CAM'), ('ARTOGRAPHY', 'RED'), ('WALSH', 'WALSH'), ('NATIONA', 'NATIONAL'), ('nternational', 'nternational'), ('IG', 'EVILS'), ('s.c.', 's.c.'), ('ill.', 'ill.'), ('WINNEPE', 'WINNEPEG'), ('PAC.', 'PAC.'), ('HELENA', 'HELENA'), ('ELL', 'helen'), ('DIVID', 'DEVIL'), ('st', 'uster'), ('SNAKE', 'SNAKE'), ('ort', 'eton'), ('snake', 'snake'), ('LAKE.', 'LAKE.'), ('City', 'City'), ('s.c', 'cam'), ('00', 'IOW'), ('Mil', 'MILK'), ('lympia', 'popla'), ('AUL', 'BI'), ('Devil', 'divid'), ('Associates', 'Associates,'), ('.P.', '.P.'), ('CARTOGRAPH', 'TS.'), ('S.C', 'COLLECTION'), ('BOUNDARY', 'BOUNDARY'), ('RE', 'BRECKENRIDGE'), ('FOR', 'MOUSE'), ('Mcleo', 'OREGO'), ('ENNETT', 'cit'), ('river', 'river'), ('wals', 'wals'), ('ouse', 'custe'), ('ITY', 'ITY'), ('st.', 'st.'), ('LL.', 'LL.'), ('railroa', 'ASSOCIATES'), ('PAU', 'LYMPIA'), ('ST.', 'ST.'), ('TS.', '.P.'), ('hel', 'WALS'), ('ST', 'BLACK'), ('AKE', 'ILK'), ('BIG', 'BIG'), ('LAKE', 'LAKE'), ('.p.', 'IVERS.'), ('centra', 'Crysta'), ('re', 'orego'), ('ED', 'red'), ('OUNDARY', 'IVER'), ('RIVE', 'River'), ('FOR', 'AUL'), (\"G'\", \"G'\"), ('TENIN', 'TENIN'), ('ASHINGTON', 'ST'), ('ig', 'st.p.'), ('RAILROA', 'Rain'), ('lin', 'CONNECTIONS'), ('CENTRA', 'T.'), ('LAKE', 'LAKE'), ('st', 'ap'), ('SNAKE', 'SNAKE'), ('custe', 'custer'), ('teto', 'ft'), ('crystal', 'crystal'), ('ouse', 'S.C.'), ('DIV', 'DAVI'), ('aul', 'FT.'), ('IG', 'll.'), ('Carroll', 'Carroll'), ('16th', '16th'), ('PACIFI', 'FT'), ('div', 'div'), ('INE', 'ELL'), ('ll.', 'ILL.'), ('yellowston', 'yellowston'), ('KENZIES', 'KENZIES'), ('s.c', 's.c.'), ('ap', \"g'\"), ('S.c.', 'S.c.'), ('ST', '.c.'), ('lake', 'lake'), ('river', 'river'), ('ashlan', 'Crystal'), ('ig', 'ig'), ('ORT', 'ATIONAL'), ('iles', 'ritish'), ('RIVERS', 'RIVERS'), ('ivers.', 'st.p.'), ('Oregon', 'Oregon'), ('RANG', 'TACOM'), ('ort', 're'), ('Saskatchewa', 'Rive'), ('AP', '.C.'), ('no label attached', 'no label attached'), ('HELENA', 'HELENA'), ('FT.', 'FT.'), ('Mts.', 'Mts.'), ('ST', 'st'), ('golden', 'golden'), ('PORTLAND', 'PORTLAND'), ('RED', 'RED'), ('LAKE', 'LAKE'), ('Pacifi', 'IG'), ('S.C', \"g'\"), ('ELENA', 'Popla'), ('FT.', 'FT.'), ('div', \"'d\"), ('S.C', 'st.'), ('RYSTAL', 'IOWA'), ('ts.', 'associates,'), ('NAKE', 'T.'), (\"g'\", 'ED'), ('city', 'city'), ('PACIFI', 'PACIFIC'), ('ED', 'ivers.'), ('s.c', 'ST'), ('st', 'ity'), ('ND', 'ND'), ('T.', 'SUPERIOR'), ('IOW', 'DAVID'), ('cit', 'ac.'), ('NORTHERN', 'NORTHERN'), ('ITY', 'cartography'), ('s.c.', 's.c.'), ('ashlan', 'Ashlan'), ('CRYSTA', 'BRANC'), ('bi', 'superior'), ('T.', 'aul'), ('yellowston', 'yellowstone'), ('Railroa', 'LL.'), ('olympia', 'olympia'), ('ft', 't.'), ('YELLOWSTON', 'ENINO'), ('.C.', 'miles'), ('KENZIE', 'AKE'), ('Orego', 'ORT'), ('PAC', 'DIV'), ('T.', 'T.'), ('ILL', 'aul'), ('ND', 'IV.'), ('st.', 'st.'), ('Pac', 'wals'), ('ORN', 'ETON'), ('00', '00'), ('TS.', 'ts.'), ('TS.', 'ITY'), (\"G'\", 'll.'), ('IV.', 'DAVID'), ('pac.', 'pac.'), ('LAK', 'LAK'), ('TS.', 'CITY'), ('RE', 'RAINY'), ('FOR', 'ig'), ('ts.', 'ts.'), ('DIVID', 'DIVID'), ('ERMILLION', 'BI'), ('ort', 'ORT'), ('CONNECTIONS', 'ONNECTIONS.'), ('s.c', 'WINNIPE'), ('wyoming', 'wyoming'), ('CITY', 'CITY'), ('ED', 'red'), (\"G'\", \"G'\"), ('rive', 'river'), ('orks', 'MTS'), ('T.', 'MTS'), ('crystal', 'crystal'), ('LL.', 'LAK'), ('Branc', 'Branc'), ('ig', 'Rang'), ('st', 'St.'), (\"g'\", 'snak'), ('ig', 'mile'), ('rang', 'For'), ('ST', 'St.'), ('ST', 'ENINO'), ('ouse', 'Custe'), ('SNAKE', 'SNAKE'), ('ouse', 'mts.'), ('Forks', 'Forks'), ('hor', 'Devils'), ('RIVE', 'iver'), ('OCKY', 'OCKY'), ('DIVID', 'IVIDE'), ('RIVER', 'RIVER'), ('S.C.', 'S.C.'), ('golde', 'll.'), ('St.p', 'St.p.'), (\"g'\", \"g'd\"), ('Helena', 'Helena'), ('british', 'british'), ('ts.', 'OLUMBIA'), ('St.p', 'St.p'), ('Pau', 'ma'), ('Oregon', 'Oregon'), ('ity', 'city'), ('SSOCIATES,', 'IOW'), ('devils', 'devils'), ('MILES', 'MILES'), ('ST.', 'ST.'), (\"G'\", 'Golde'), ('S.C', 'St.p.'), ('PORTLAND', 'PORTLAND'), ('WYOMIN', 'IOWA'), ('AINY', 'ITY'), ('st.', 'st.'), ('MTS', \"G'\"), ('AINY', 'MINN'), ('ITY', 'teto'), ('STANDIN', 'TS.'), ('ivide', 'ivide'), ('Kenzies', 'Kenzies'), ('SUPERIO', 'PAC'), ('ac.', 'T.'), ('ap', 'COLUMBI'), ('BOUNDARY', 'BOUNDARY'), ('BOUNDARY', 'BOUNDARY'), ('BOUNDARY', 'BOUNDARY'), ('BOUNDARY', 'BOUNDARY'), ('BOUNDARY', 'BOUNDARY'), ('BOUNDARY', 'BOUNDARY'), ('BOUNDARY', 'BOUNDARY'), ('BOUNDARY', 'BOUNDARY'), ('BOUNDARY', 'BOUNDARY'), ('BOUNDARY', 'BOUNDARY'), ('BOUNDARY', 'BOUNDARY'), ('BOUNDARY', 'BOUNDARY'), ('BOUNDARY', 'BOUNDARY'), ('BOUNDARY', 'BOUNDARY'), ('BOUNDARY', 'BOUNDARY'), ('BOUNDARY', 'BOUNDARY'), ('BOUNDARY', 'BOUNDARY'), ('BOUNDARY', 'BOUNDARY'), ('BOUNDARY', 'BOUNDARY'), ('BOUNDARY', 'BOUNDARY'), ('BOUNDARY', 'BOUNDARY'), ('BOUNDARY', 'BOUNDARY'), ('BOUNDARY', 'BOUNDARY'), ('BOUNDARY', 'BOUNDARY'), ('BOUNDARY', 'BOUNDARY'), ('BOUNDARY', 'BOUNDARY'), ('BOUNDARY', 'BOUNDARY'), ('BOUNDARY', 'BOUNDARY'), ('BOUNDARY', 'BOUNDARY'), ('BOUNDARY', 'BOUNDARY'), ('BOUNDARY', 'BOUNDARY'), ('BOUNDARY', 'BOUNDARY'), ('BOUNDARY', 'BOUNDARY'), ('BOUNDARY', 'BOUNDARY'), ('BOUNDARY', 'BOUNDARY'), ('BOUNDARY', 'BOUNDARY'), ('BOUNDARY', 'BOUNDARY'), ('BOUNDARY', 'BOUNDARY'), ('BOUNDARY', 'BOUNDARY'), ('BOUNDARY', 'BOUNDARY'), ('popla', 'hell'), ('cit', 't.'), ('OLDEN', 'DIVIDE'), ('St.p.', 'St.p.'), ('ainy', 'Rang'), ('CAM', 'AC.'), ('RAILROA', 'ST.'), ('TS.', 'crysta'), ('OREGON', 'OREGON'), ('AKE', 'ST'), ('Associates', 'Associates'), ('st', 'aul'), ('ASSOCIATES', \"G'\"), ('SUPERIO', \"'D\"), ('COLLECTION', 'COLLECTION'), ('RAILROA', 'PAC.'), ('ts.', 'ap'), ('IG', 'wals'), ('MILES', 'MILES'), ('T.', 'CIT'), ('and', 'and')]\n"
     ]
    }
   ],
   "source": [
    "words_all = np.load('../../training_mudit/'+fN+'.npy')\n",
    "words_all = words_all.T\n",
    "print(words_all)\n",
    "words_old = words_all[0]\n",
    "words_new = words_all[1]\n",
    "gt = words_all[2]\n",
    "print(zip(words_old,words_new))\n",
    "# words_new = np.load('../../new_labels/'+fN+'.npy')\n",
    "# print(zip(words_old[ids],words_new,gt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import ast\n",
    "# csv = pd.read_csv('../data/D0090-5242001.csv',names=['ids','dir','old','new','gt'])\n",
    "# csv = pd.read_csv('/media/d/DATA/NN/torch-phoc/mudit/torch-phoc/extension_info/D0090-5242001.csv',names=['ids','dir','old','new','gt'])\n",
    "# words_old = [ast.literal_eval(word)[0] for word in csv['old']]\n",
    "# words_new = [ast.literal_eval(word)[0] for word in csv['new']]\n",
    "# dir = list(csv['dir'])\n",
    "# gt = list(csv['gt'])\n",
    "# gt = [ast.literal_eval(word)[0] for word in csv['gt']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('right', 'connections', 'connections.', -1)\n",
      "('right', 'hor', 'horn', -1)\n",
      "('right', 'mous', 'mouse', -1)\n",
      "('right', 'nationa', 'national', -1)\n",
      "('right', 'winnepe', 'winnepeg', -1)\n",
      "('right', 'mil', 'milk', -1)\n",
      "('right', 'associates', 'associates,', -1)\n",
      "('left', 'ed', 'red', 1)\n",
      "('right', 'rive', 'river', -1)\n",
      "('right', 'custe', 'custer', -1)\n",
      "('left', 'll.', 'ill.', 1)\n",
      "('right', 's.c', 's.c.', -1)\n",
      "('right', 'pacifi', 'pacific', -1)\n",
      "('right', 'yellowston', 'yellowstone', -1)\n",
      "('left', 'ed', 'red', 1)\n",
      "('right', 'rive', 'river', -1)\n",
      "('right', 'st', 'st.', -1)\n",
      "('right', 'st', 'st.', -1)\n",
      "('right', 'st.p', 'st.p.', -1)\n",
      "('right', \"g'\", \"g'd\", -1)\n",
      "('left', 'ity', 'city', 1)\n"
     ]
    }
   ],
   "source": [
    "# Sample data\n",
    "# words_old = ['wor','ord']\n",
    "# words_new = ['word','word']\n",
    "# coords_old = [[(1000,2000),(2000,3000)],[(2000,2400),(2400,2500)]]\n",
    "# coords_new = [[(1000,2000),(2500,3000)],[(2000,2000),(2400,2500)]]\n",
    "d = maps(words_old,words_new,coords_old,coords_new,dir,gt,ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{',': [[[482, 2269], [491, 2269], [491, 2248], [482, 2248]]], '.': [[[5687, 689], [5721, 689], [5721, 627], [5687, 627]], [[2205, 1712], [2205, 1723], [2205, 1665], [2205, 1665]], [[3615, 1156], [3615, 1169], [3653, 1149], [3653, 1149]], [[3870, 1314], [3870, 1327], [3904, 1308], [3904, 1308]], [[4411, 1393], [4411, 1403], [4431, 1377], [4431, 1377]]], 'a': [], 'c': [[[5670, 573], [5695, 573], [5707, 509], [5682, 509]], [[1111, 1345], [1121, 1345], [1129, 1325], [1119, 1325]]], 'b': [], 'e': [[[2987, 412], [2995, 412], [2995, 384], [2987, 384]], [[2834, 954], [2838, 954], [2843, 927], [2839, 927]]], 'd': [[[3437, 1013], [3437, 1029], [3461, 992], [3461, 992]]], 'g': [[[4362, 469], [4387, 469], [4387, 437], [4362, 437]]], 'f': [], 'i': [[[4739, 1898], [4750, 1898], [4750, 1872], [4739, 1872]]], 'h': [], 'k': [[[2840, 939], [2856, 939], [2856, 911], [2840, 911]]], 'j': [], 'm': [], 'l': [[[2751, 831], [2782, 831], [2782, 798], [2751, 798]]], 'o': [], 'n': [[[3663, 411], [3673, 411], [3673, 379], [3663, 379]]], 'q': [], 'p': [], 's': [], 'r': [[[2580, 564], [2594, 564], [2594, 525], [2580, 525]], [[3332, 1063], [3350, 1063], [3350, 1040], [3332, 1040]], [[2980, 1463], [3001, 1463], [3001, 1431], [2980, 1431]], [[2499, 557], [2499, 557], [2507, 513], [2507, 495]], [[3038, 1078], [3055, 1078], [3060, 1048], [3043, 1048]]], 'u': [], 't': [], 'w': [], 'v': [], 'y': [], 'x': [], 'z': []}\n"
     ]
    }
   ],
   "source": [
    "# print(sorted(d,key=lambda len()))\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ndef plot_char(char,c_map,map_name,img=None):\\n    if type(img)!=np.ndarray:\\n        im = Image.open(map_name)\\n        img = np.array(im)\\n    coords = c_map[char]\\n    for coord in coords:\\n#             print(coords)\\n#             print(coord[0],'0',coord[1])\\n            cv2.rectangle(img,coord[0],coord[1],(255,0,0),5)\\n#     If each character has to be saved:\\n#     im = Image.fromarray(img)\\n#     im.save('h_'+'D0090-5242001.tiff')\\n    return img\\n    \""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "def plot_char(char,c_map,map_name,img=None):\n",
    "    if type(img)!=np.ndarray:\n",
    "        im = Image.open(map_name)\n",
    "        img = np.array(im)\n",
    "    coords = c_map[char]\n",
    "    for coord in coords:\n",
    "#             print(coords)\n",
    "#             print(coord[0],'0',coord[1])\n",
    "            cv2.rectangle(img,coord[0],coord[1],(255,0,0),5)\n",
    "#     If each character has to be saved:\n",
    "#     im = Image.fromarray(img)\n",
    "#     im.save('h_'+'D0090-5242001.tiff')\n",
    "    return img\n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"print(d)\\nmap_name = '../data/maps/D0090-5242001.tiff'\\nim = Image.open(map_name)\\nimg = np.array(im)\\nprint(type(img))\\nfor c in d.keys():\\n    img =  plot_char(c,d,'../data/maps/D0090-5242001.tiff',img)\\nim = Image.fromarray(img)\\nim.save('chars_'+'D0090-5242001.tiff')\\n\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''print(d)\n",
    "map_name = '../data/maps/D0090-5242001.tiff'\n",
    "im = Image.open(map_name)\n",
    "img = np.array(im)\n",
    "print(type(img))\n",
    "for c in d.keys():\n",
    "    img =  plot_char(c,d,'../data/maps/D0090-5242001.tiff',img)\n",
    "im = Image.fromarray(img)\n",
    "im.save('chars_'+'D0090-5242001.tiff')\n",
    "'''\n",
    "# f = plt.figure()\n",
    "# f.savefig('d_'+'D0090-5242001.eps',format='eps',dpi=300)\n",
    "# f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nfor i in range(coords_old.shape[0]):\\n    d[words_old[i]]=[[(coords_old[i][0][0],coords_old[i][0][1]),(coords_old[i][1][0],coords_old[i][1][1])]]\\nfor c in d.keys():\\n    img =  plot_char(c,d,'../data/maps/D0090-5242001.tiff',img)\\nim = Image.fromarray(img)\\nim.save('all_'+'D0090-5242001.tiff')\\n\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "for i in range(coords_old.shape[0]):\n",
    "    d[words_old[i]]=[[(coords_old[i][0][0],coords_old[i][0][1]),(coords_old[i][1][0],coords_old[i][1][1])]]\n",
    "for c in d.keys():\n",
    "    img =  plot_char(c,d,'../data/maps/D0090-5242001.tiff',img)\n",
    "im = Image.fromarray(img)\n",
    "im.save('all_'+'D0090-5242001.tiff')\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = np.array(d)\n",
    "np.save('dicts_new/'+fN+'.npy',d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
