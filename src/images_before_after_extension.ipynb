{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import argparse\n",
    "import logging\n",
    "\n",
    "import numpy as np\n",
    "import torch.autograd\n",
    "import torch.cuda\n",
    "import torch.nn as nn\n",
    "import torch.optim\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "\n",
    "import copy\n",
    "from datasets.maps_alt import MAPSDataset\n",
    "\n",
    "#from cnn_ws.transformations.homography_augmentation import HomographyAugmentation\n",
    "from cnn_ws.losses.cosine_loss import CosineLoss\n",
    "\n",
    "from cnn_ws.models.myphocnet import PHOCNet\n",
    "from cnn_ws.evaluation.retrieval import map_from_feature_matrix, map_from_query_test_feature_matrices\n",
    "from torch.utils.data.dataloader import _DataLoaderIter as DataLoaderIter\n",
    "from torch.utils.data.sampler import WeightedRandomSampler\n",
    "\n",
    "from cnn_ws.utils.save_load import my_torch_save, my_torch_load\n",
    "\n",
    "#import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not torch.cuda.is_available():\n",
    "    logger.warning('Could not find CUDA environment, using CPU mode')\n",
    "    gpu_id = None\n",
    "else:\n",
    "    gpu_id = [0]\n",
    "#torch.cuda.get_device_name(gpu_id[0])\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ = torch.load('PHOCNet_a1.pt')\n",
    "cnn = model_.module#list(model_.named_parameters())\n",
    "if gpu_id is not None:\n",
    "        if len(gpu_id) > 1:\n",
    "            cnn = nn.DataParallel(cnn, device_ids=gpu_id)\n",
    "            cnn.cuda()\n",
    "        else:\n",
    "            cnn.cuda(gpu_id[0])\n",
    "cnn.training = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load before, after images and words, transforms and cleans them\n",
    "# the function also assumes that ground truth words are the same before and after\n",
    "# returns before_images, after_images, words\n",
    "def load_and_transform(map_name):\n",
    "    images_before = np.load('../../../detection_outputs_ready_for_test/detected_regions/'+map_name+'.npy')\n",
    "    words_before = np.load('../../../detection_outputs_ready_for_test/detected_labels/'+map_name+'.npy')\n",
    "    images_before, words_before = clean_word_images(images_before, words_before, 2)\n",
    "    images_before = np.transpose(images_before, (0,3,1,2))\n",
    "    \n",
    "    images_after = np.load('../../../detection_outputs_ready_for_test/new_regions/no_conf_output/'+map_name+'.npy')\n",
    "    words_after = np.load('../../../detection_outputs_ready_for_test/new_labels/no_conf_output/'+map_name+'.npy')\n",
    "    images_after, words_after = clean_word_images(images_after, words_after, 2)\n",
    "    images_after = np.transpose(images_after, (0,3,1,2))\n",
    "    \n",
    "    print 'Images Before Shape ', images_before.shape\n",
    "    print 'Words Before Shape ', words_before.shape\n",
    "    print 'Images After Shape ', images_after.shape\n",
    "    print 'Words After Shape ', words_after.shape\n",
    "    return images_before, images_after, words_after\n",
    "\n",
    "def clean_word_images(images, words, l):\n",
    "    selected_idx = [x for x in range(len(words)) if len(words[x]) > l]\n",
    "    images = images[selected_idx]\n",
    "    words = words[selected_idx]\n",
    "    return images, words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert image tnto embedding using the cnn model\n",
    "def get_image_embeddings(cnn, images):\n",
    "    outputs = []\n",
    "    for i in tqdm(range(len(images))):\n",
    "        word_img = images[i]\n",
    "        word_img = 1 - word_img.astype(np.float32) / 255.0\n",
    "        word_img = word_img.reshape((1,) + word_img.shape)\n",
    "        word_img = torch.from_numpy(word_img).float()\n",
    "        word_img = word_img.cuda(gpu_id[0])\n",
    "        word_img = torch.autograd.Variable(word_img)\n",
    "        output = torch.sigmoid(cnn(word_img))\n",
    "        output = output.data.cpu().numpy().flatten()\n",
    "        outputs.append(output)\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to create word variations\n",
    "# word_var is a dictionary that contains all variations as key and 0,1,-1 as value\n",
    "# 0 denotes the root word, -1 denotes var = root_word[:-1], +1 denotes var = root_word[1:]\n",
    "# root_word_var is a dict that stores original_word => all_variations\n",
    "# enable_conf: boolean flag that controls if the confusion logic should be used.\n",
    "# when enabled if a word is a root word as well as a word variation (happens if root words ar rand and grand)\n",
    "# it marks it as to be extended and also stores it in the confusion list\n",
    "def create_word_variations(words, enable_conf=False):\n",
    "    word_var = {}\n",
    "    root_word_var = {}\n",
    "    # create the root word variation dict and set word_var as -1 or +1\n",
    "    for w in words:\n",
    "        if len(w) <= 2:\n",
    "            continue\n",
    "        root_var_list = [w, w.lower(), w.upper(), w.capitalize()]\n",
    "        var_set = set()\n",
    "        for var in root_var_list:\n",
    "            word_var[var[1:]] = 1\n",
    "            word_var[var[:-1]] = -1\n",
    "            var_set.add(var)\n",
    "            var_set.add(var[1:])\n",
    "            var_set.add(var[:-1])\n",
    "        root_word_var[w] = var_set\n",
    "    # explicitly set all root words to have direction 0\n",
    "    # mark the words that already have a direction set\n",
    "    conf_words = set()\n",
    "    for w in words:\n",
    "        if len(w) <= 2:\n",
    "            continue\n",
    "        root_var_list = [w, w.lower(), w.upper(), w.capitalize()]\n",
    "        for var in root_var_list:\n",
    "            if var in word_var and word_var[var] != 0 and enable_conf:\n",
    "                conf_words.add(var)\n",
    "            else:\n",
    "                word_var[var] = 0\n",
    "    return word_var, root_word_var, conf_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the PHOC representation of the word itself\n",
    "from cnn_ws.string_embeddings.phoc import build_phoc_descriptor\n",
    "def get_word_phoc_representations(word_strings):\n",
    "    unigrams = [chr(i) for i in range(ord('&'), ord('&')+1) + range(ord('A'), ord('Z')+1) + \\\n",
    "                    range(ord('a'), ord('z') + 1) + range(ord('0'), ord('9') + 1)]\n",
    "    bigram_levels = None\n",
    "    bigrams = None\n",
    "    phoc_unigram_levels=(1, 2, 4, 8)\n",
    "    word_var_dir, root_word_var, conf_words = create_word_variations(word_strings, enable_conf=False)\n",
    "    \n",
    "    word_var_strings = word_var_dir.keys()\n",
    "    embedding_var = build_phoc_descriptor(words=word_var_strings,\n",
    "                                  phoc_unigrams=unigrams,\n",
    "                                  bigram_levels=bigram_levels,\n",
    "                                  phoc_bigrams=bigrams,\n",
    "                                  unigram_levels=phoc_unigram_levels)\n",
    "    \n",
    "    print('embedding variations:', embedding_var.shape)\n",
    "    return (embedding_var, word_var_strings, word_var_dir, root_word_var, conf_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import cdist, pdist, squareform\n",
    "\n",
    "# gets the actual distances of all the ground truth word variations\n",
    "def get_all_dist_gt(dist_mat, emb_info, words):\n",
    "    # expand emb_info tuple\n",
    "    embedding_var, word_var_strings, word_var_dir, root_word_var,_ = emb_info\n",
    "    all_dist = []\n",
    "    for i in range(len(words)):\n",
    "        w_dist = []\n",
    "        w_vars = root_word_var[words[i]]\n",
    "        for j in range(len(word_var_strings)):\n",
    "            if word_var_strings[j] in w_vars:\n",
    "                w_dist.append((word_var_strings[j], dist_mat[i][j]))\n",
    "        all_dist.append(w_dist)\n",
    "    return all_dist\n",
    "\n",
    "# the new report matches method that handles variations\n",
    "def report_matches_with_variations(dist_mat, word_strings, emb_info, k):\n",
    "    # expand emb_info tuple\n",
    "    embedding_var, word_var_strings, word_var_dir, root_word_var,_ = emb_info\n",
    "    gt_words_dist = get_all_dist_gt(dist_mat, emb_info, word_strings)\n",
    "    retrieval_indices = np.argsort(dist_mat, axis=1)\n",
    "    q = retrieval_indices[:,:k]\n",
    "    count = 0\n",
    "    matched_words = []\n",
    "    img_dir = []\n",
    "    words_len = []\n",
    "    actual_dist = []\n",
    "    # get all matched words\n",
    "    for i in range(len(q)):\n",
    "        matched = []\n",
    "        for j in q[i]:\n",
    "            actual_dist.append(dist_mat[i][j])\n",
    "            matched.append(word_var_strings[j])\n",
    "            curr_len = len(word_var_strings[j])\n",
    "            curr_dir = word_var_dir[word_var_strings[j]]\n",
    "            words_len.append(curr_len + abs(curr_dir))\n",
    "            img_dir.append(curr_dir)\n",
    "        matched_words.append(matched)\n",
    "    \n",
    "    # calculate accuracies\n",
    "    is_correct = []\n",
    "    for i in range(len(word_strings)):\n",
    "        #print word_strings[i]\n",
    "        is_correct.append(0)\n",
    "        if word_strings[i] in matched_words[i]:\n",
    "            is_correct[i] = 1\n",
    "            count = count+1\n",
    "        else:\n",
    "            for w in matched_words[i]:\n",
    "                if w in root_word_var[word_strings[i]]:\n",
    "                    is_correct[i] = 2\n",
    "                    count = count+1\n",
    "                    break\n",
    "    return (count, matched_words, img_dir, words_len, actual_dist, is_correct, gt_words_dist)\n",
    "\n",
    "# For some images, the original predicted word os both a root word and a word_variation of another word \n",
    "# (common word problem). Due to this one cannot be sure, if these images should be extended or not.\n",
    "# These images are handled by comparing distances before and after image extension and picking the minimum one\n",
    "# the feature can be turned of by setting enable_conf = False\n",
    "def update_dist_matrix(dist_mat_before, dist_mat_after, conf_idx):\n",
    "    print('conf_idx', conf_idx)\n",
    "    for i in conf_idx:\n",
    "        dist = np.minimum(dist_mat_before[i], dist_mat_after[i])\n",
    "        dist_mat_after[i] = dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_confusion_matrix(match_report_before, match_report_after, words):\n",
    "    status = [0,1,2]\n",
    "    conf_matrix = [['before/after','incorrect (0)','correct (1)','almost (2)'],\n",
    "                   ['incorrect (0)',0,0,0],\n",
    "                   ['correct (1)',0,0,0],\n",
    "                   ['almost (2)',0,0,0]]\n",
    "    for i in status:\n",
    "        for j in status:\n",
    "            count = 0\n",
    "            for k in range(len(words)):\n",
    "                if match_report_before[5][k] == i and match_report_after[5][k] == j:\n",
    "                    count += 1\n",
    "            conf_matrix[1+i][1+j] = count\n",
    "    return conf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_before_after_preds(map_name, before_report, after_report, ground_truth):\n",
    "    before_preds = [w[0] for w in before_report[1]]\n",
    "    after_preds = [w[0] for w in after_report[1]]\n",
    "    before_after_pred = np.array([before_preds, after_preds, ground_truth]).T\n",
    "    np.save('../../../before_after_ext_pred/'+map_name+'.npy', before_after_pred)\n",
    "\n",
    "def compare_images_before_after_ext(map_name, cnn, global_stats):\n",
    "    images_before, images_after, words = load_and_transform(map_name)\n",
    "    image_embs_before = get_image_embeddings(cnn, images_before)\n",
    "    image_embs_after = get_image_embeddings(cnn, images_after)\n",
    "    word_emb_info = get_word_phoc_representations(words)\n",
    "    # get the distances between images and words\n",
    "    dist_matrix_before = cdist(XA=image_embs_before, XB=word_emb_info[0], metric='cosine')\n",
    "    dist_matrix_after = cdist(XA=image_embs_after, XB=word_emb_info[0], metric='cosine')\n",
    "    # build the original report\n",
    "    match_report_before = report_matches_with_variations(dist_matrix_before, words, word_emb_info, 1)\n",
    "    # get the low confidence image index\n",
    "    conf_idx = [i for i in range(len(match_report_before[1])) if match_report_before[1][i][0] in word_emb_info[4]]\n",
    "    # update the dist_after matrix based for low confidence images\n",
    "    update_dist_matrix(dist_matrix_before, dist_matrix_after, conf_idx)\n",
    "    # build the report after extension\n",
    "    match_report_after = report_matches_with_variations(dist_matrix_after, words, word_emb_info, 1)\n",
    "    # save_before_after_preds(map_name, match_report_before, match_report_after, words)\n",
    "    global_stats['correct_before'] += match_report_before[0]\n",
    "    global_stats['correct_after'] += match_report_after[0]\n",
    "    global_stats['total'] += len(words)\n",
    "    acc_before = match_report_before[0]/len(words)\n",
    "    acc_after = match_report_after[0]/len(words)\n",
    "    conf_matrix = generate_confusion_matrix(match_report_before, match_report_after, words)\n",
    "    return (acc_before, acc_after, conf_matrix, match_report_before, match_report_after)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the file names\n",
    "f = open('../splits/val_files.txt', 'rb')\n",
    "A = f.readlines()\n",
    "f.close()\n",
    "A = [x.rstrip('\\n') for x in A]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 6/469 [00:00<00:08, 57.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images Before Shape  (469, 3, 135, 487)\n",
      "Words Before Shape  (469,)\n",
      "Images After Shape  (469, 3, 135, 487)\n",
      "Words After Shape  (469,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 469/469 [00:07<00:00, 62.28it/s]\n",
      "100%|██████████| 469/469 [00:07<00:00, 62.72it/s]\n",
      "100%|██████████| 1871/1871 [00:00<00:00, 5302.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('embedding variations:', (1871, 945))\n",
      "('conf_idx', [])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 6/1297 [00:00<00:22, 56.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images Before Shape  (1297, 3, 135, 487)\n",
      "Words Before Shape  (1297,)\n",
      "Images After Shape  (1297, 3, 135, 487)\n",
      "Words After Shape  (1297,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1297/1297 [00:20<00:00, 62.47it/s]\n",
      "100%|██████████| 1297/1297 [00:21<00:00, 61.57it/s]\n",
      "100%|██████████| 4941/4941 [00:00<00:00, 5787.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('embedding variations:', (4941, 945))\n",
      "('conf_idx', [])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 6/1536 [00:00<00:27, 56.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images Before Shape  (1536, 3, 135, 487)\n",
      "Words Before Shape  (1536,)\n",
      "Images After Shape  (1536, 3, 135, 487)\n",
      "Words After Shape  (1536,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1536/1536 [00:25<00:00, 61.26it/s]\n",
      "100%|██████████| 1536/1536 [00:25<00:00, 60.52it/s]\n",
      "100%|██████████| 5585/5585 [00:01<00:00, 5391.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('embedding variations:', (5585, 945))\n",
      "('conf_idx', [])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 6/895 [00:00<00:16, 55.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images Before Shape  (895, 3, 135, 487)\n",
      "Words Before Shape  (895,)\n",
      "Images After Shape  (895, 3, 135, 487)\n",
      "Words After Shape  (895,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 895/895 [00:14<00:00, 60.48it/s]\n",
      "100%|██████████| 895/895 [00:14<00:00, 61.65it/s]\n",
      "100%|██████████| 3865/3865 [00:00<00:00, 5143.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('embedding variations:', (3865, 945))\n",
      "('conf_idx', [])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 6/1141 [00:00<00:19, 58.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images Before Shape  (1141, 3, 135, 487)\n",
      "Words Before Shape  (1141,)\n",
      "Images After Shape  (1141, 3, 135, 487)\n",
      "Words After Shape  (1141,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1141/1141 [00:18<00:00, 61.05it/s]\n",
      "100%|██████████| 1141/1141 [00:18<00:00, 60.43it/s]\n",
      "100%|██████████| 4463/4463 [00:00<00:00, 6403.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('embedding variations:', (4463, 945))\n",
      "('conf_idx', [])\n"
     ]
    }
   ],
   "source": [
    "global_stats = {'correct_before':0, 'correct_after':0, 'total':0}\n",
    "local_stats = []\n",
    "for i in range(len(A)):\n",
    "    stats = compare_images_before_after_ext(A[i], cnn, global_stats)\n",
    "    local_stats.append(stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for image D0090-5242001\n",
      "the accuracy before extension: 0.383795309168\n",
      "the accuracy after extension: 0.424307036247\n",
      "\n",
      "\n",
      "Accuracy for image D0117-5755018\n",
      "the accuracy before extension: 0.50501156515\n",
      "the accuracy after extension: 0.51966075559\n",
      "\n",
      "\n",
      "Accuracy for image D0117-5755024\n",
      "the accuracy before extension: 0.453776041667\n",
      "the accuracy after extension: 0.466796875\n",
      "\n",
      "\n",
      "Accuracy for image D0117-5755025\n",
      "the accuracy before extension: 0.513966480447\n",
      "the accuracy after extension: 0.534078212291\n",
      "\n",
      "\n",
      "Accuracy for image D0117-5755033\n",
      "the accuracy before extension: 0.460122699387\n",
      "the accuracy after extension: 0.474145486415\n",
      "\n",
      "\n",
      "Overall Accuracy Before  0.471524915699\n",
      "Overall Accuracy After 0.488759835144\n"
     ]
    }
   ],
   "source": [
    "# print accuracies\n",
    "for i in range(len(A)):\n",
    "    print('Accuracy for image '+A[i])\n",
    "    print \"the accuracy before extension: \" + str(local_stats[i][0])\n",
    "    print \"the accuracy after extension: \"+str(local_stats[i][1])\n",
    "    print('\\n')\n",
    "    \n",
    "print 'Overall Accuracy Before ', global_stats['correct_before']/global_stats['total']\n",
    "print 'Overall Accuracy After', global_stats['correct_after']/global_stats['total']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix for Image D0090-5242001\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table><tr><td>before/after</td><td>incorrect (0)</td><td>correct (1)</td><td>almost (2)</td></tr><tr><td>incorrect (0)</td><td>262</td><td>5</td><td>22</td></tr><tr><td>correct (1)</td><td>0</td><td>101</td><td>0</td></tr><tr><td>almost (2)</td><td>8</td><td>25</td><td>46</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Confusion Matrix for Image D0117-5755018\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table><tr><td>before/after</td><td>incorrect (0)</td><td>correct (1)</td><td>almost (2)</td></tr><tr><td>incorrect (0)</td><td>615</td><td>17</td><td>10</td></tr><tr><td>correct (1)</td><td>0</td><td>413</td><td>0</td></tr><tr><td>almost (2)</td><td>8</td><td>131</td><td>103</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Confusion Matrix for Image D0117-5755024\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table><tr><td>before/after</td><td>incorrect (0)</td><td>correct (1)</td><td>almost (2)</td></tr><tr><td>incorrect (0)</td><td>806</td><td>14</td><td>19</td></tr><tr><td>correct (1)</td><td>0</td><td>418</td><td>0</td></tr><tr><td>almost (2)</td><td>13</td><td>148</td><td>118</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Confusion Matrix for Image D0117-5755025\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table><tr><td>before/after</td><td>incorrect (0)</td><td>correct (1)</td><td>almost (2)</td></tr><tr><td>incorrect (0)</td><td>409</td><td>5</td><td>21</td></tr><tr><td>correct (1)</td><td>0</td><td>283</td><td>0</td></tr><tr><td>almost (2)</td><td>8</td><td>84</td><td>85</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Confusion Matrix for Image D0117-5755033\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table><tr><td>before/after</td><td>incorrect (0)</td><td>correct (1)</td><td>almost (2)</td></tr><tr><td>incorrect (0)</td><td>592</td><td>12</td><td>12</td></tr><tr><td>correct (1)</td><td>0</td><td>331</td><td>0</td></tr><tr><td>almost (2)</td><td>8</td><td>89</td><td>97</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import HTML, display\n",
    "def print_conf_matrix(conf_matrix):\n",
    "    display(HTML(\n",
    "    '<table><tr>{}</tr></table>'.format(\n",
    "        '</tr><tr>'.join(\n",
    "            '<td>{}</td>'.format('</td><td>'.join(str(_) for _ in row)) for row in conf_matrix)\n",
    "        )\n",
    "    ))\n",
    "\n",
    "# print the confusion matrix\n",
    "for i in range(len(A)):\n",
    "    conf_matrix = local_stats[i][2]\n",
    "    print('Confusion Matrix for Image ' + A[i])\n",
    "    print_conf_matrix(conf_matrix)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print \"Incorrectly classified before and Incorrectly classified after\"\n",
    "import matplotlib.pyplot as plt\n",
    "ground_truth = match_report_before[1]\n",
    "count = 0\n",
    "for i in range(len(words)):\n",
    "    if match_report_before[5][i] == 0 \\\n",
    "    and match_report_after[5][i] == 0:\n",
    "        count += 1\n",
    "#         print \"************************************************************************\"\n",
    "#         print \"************************************************************************\"\n",
    "#         q = np.transpose(images_before[i],(1,2,0))\n",
    "#         q1 = np.transpose(images_after[i],(1,2,0))\n",
    "#         plt.imshow(q)\n",
    "#         plt.show()\n",
    "#         plt.imshow(q1)\n",
    "#         plt.show()\n",
    "#         print \"Matched before: \"+\"$\"+str(match_report_before[1][i][0])+\"$\"\n",
    "#         print \"Matched after:\" + \"$\"+str(match_report_after[1][i][0])+\"$\"\n",
    "#         print \"Ground truth:\" + str(words[i])\n",
    "#         print \"Image Dir before:\" + str(match_report_before[2][i])\n",
    "#         print \"Image Dir after:\" + str(match_report_after[2][i])\n",
    "#         print \"Distance before:\" + str(match_report_before[4][i])\n",
    "#         print \"Distance after:\" + str(match_report_after[4][i])\n",
    "#         print \"------------------------------------------------------------------------\"\n",
    "#         print \"------------------------------------------------------------------------\"\n",
    "        \n",
    "print count\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print \"Incorrectly classified before and Correctly classified after\"\n",
    "import matplotlib.pyplot as plt\n",
    "count = 0\n",
    "for i in range(len(words)):\n",
    "    if match_report_before[5][i] == 0 \\\n",
    "    and match_report_after[5][i] == 1:\n",
    "        count += 1\n",
    "#         print \"************************************************************************\"\n",
    "#         print \"************************************************************************\"\n",
    "#         q = np.transpose(images_before[i],(1,2,0))\n",
    "#         q1 = np.transpose(images_after[i],(1,2,0))\n",
    "#         plt.imshow(q)\n",
    "#         plt.show()\n",
    "#         plt.imshow(q1)\n",
    "#         plt.show()\n",
    "#         print \"Matched before: \"+\"$\"+str(match_report_before[1][i][0])+\"$\"\n",
    "#         print \"Matched after:\" + \"$\"+str(match_report_after[1][i][0])+\"$\"\n",
    "#         print \"Ground truth:\" + str(words[i])\n",
    "#         print \"Image Dir before:\" + str(match_report_before[2][i])\n",
    "#         print \"Image Dir after:\" + str(match_report_after[2][i])\n",
    "#         print \"Distance before:\" + str(match_report_before[4][i])\n",
    "#         print \"Distance after:\" + str(match_report_after[4][i])\n",
    "#         print \"------------------------------------------------------------------------\"\n",
    "#         print \"------------------------------------------------------------------------\"\n",
    "        \n",
    "print count   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print \"Incorrectly classified before and Almost correctly classified after\"\n",
    "import matplotlib.pyplot as plt\n",
    "count = 0\n",
    "for i in range(len(words)):\n",
    "    if match_report_before[5][i] == 0 \\\n",
    "    and match_report_after[5][i] == 2:\n",
    "        count += 1\n",
    "#         print \"************************************************************************\"\n",
    "#         print \"************************************************************************\"\n",
    "#         q = np.transpose(images_before[i],(1,2,0))\n",
    "#         q1 = np.transpose(images_after[i],(1,2,0))\n",
    "#         plt.imshow(q)\n",
    "#         plt.show()\n",
    "#         plt.imshow(q1)\n",
    "#         plt.show()\n",
    "#         print \"Matched before: \"+\"$\"+str(match_report_before[1][i][0])+\"$\"\n",
    "#         print \"Matched after:\" + \"$\"+str(match_report_after[1][i][0])+\"$\"\n",
    "#         print \"Ground truth:\" + str(words[i])\n",
    "#         print \"Image Dir before:\" + str(match_report_before[2][i])\n",
    "#         print \"Image Dir after:\" + str(match_report_after[2][i])\n",
    "#         print \"Distance before:\" + str(match_report_before[4][i])\n",
    "#         print \"Distance after:\" + str(match_report_after[4][i])\n",
    "#         print \"------------------------------------------------------------------------\"\n",
    "#         print \"------------------------------------------------------------------------\"\n",
    "        \n",
    "print count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print \"Correctly classified before and Incorrectly classified after\"\n",
    "import matplotlib.pyplot as plt\n",
    "count = 0\n",
    "for i in range(len(words)):\n",
    "    if match_report_before[5][i] == 1 \\\n",
    "    and match_report_after[5][i] == 0:\n",
    "        count += 1\n",
    "        print \"************************************************************************\"\n",
    "        print \"************************************************************************\"\n",
    "        q = np.transpose(images_before[i],(1,2,0))\n",
    "        q1 = np.transpose(images_after[i],(1,2,0))\n",
    "        plt.imshow(q)\n",
    "        plt.show()\n",
    "        plt.imshow(q1)\n",
    "        plt.show()\n",
    "        print \"Matched before: \"+\"$\"+str(match_report_before[1][i][0])+\"$\"\n",
    "        print \"Matched after:\" + \"$\"+str(match_report_after[1][i][0])+\"$\"\n",
    "        print \"Ground truth:\" + str(words[i])\n",
    "        print \"Image Dir before:\" + str(match_report_before[2][i])\n",
    "        print \"Image Dir after:\" + str(match_report_after[2][i])\n",
    "        print \"Distance before:\" + str(match_report_before[4][i])\n",
    "        print \"Distance after:\" + str(match_report_after[4][i])\n",
    "        print \"------------------------------------------------------------------------\"\n",
    "        print \"------------------------------------------------------------------------\"\n",
    "        \n",
    "print count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print \"Correctly classified before and Correctly classified after\"\n",
    "import matplotlib.pyplot as plt\n",
    "qualified_ids = match_report_before[2]\n",
    "ground_truth = match_report_before[6]\n",
    "count = 0\n",
    "for i in range(len(qualified_ids)):\n",
    "    if match_report_before[5][i] == 1 \\\n",
    "    and match_report_after[5][i] == 1:\n",
    "        count += 1\n",
    "#         print \"************************************************************************\"\n",
    "#         print \"************************************************************************\"\n",
    "#         q = np.transpose(images_before[i],(1,2,0))\n",
    "#         q1 = np.transpose(images_after[i],(1,2,0))\n",
    "#         plt.imshow(q)\n",
    "#         plt.show()\n",
    "#         plt.imshow(q1)\n",
    "#         plt.show()\n",
    "#         print \"Matched before: \"+\"$\"+str(match_report_before[1][i][0])+\"$\"\n",
    "#         print \"Matched after:\" + \"$\"+str(match_report_after[1][i][0])+\"$\"\n",
    "#         print \"Ground truth:\" + str(words[i])\n",
    "#         print \"Image Dir before:\" + str(match_report_before[2][i])\n",
    "#         print \"Image Dir after:\" + str(match_report_after[2][i])\n",
    "#         print \"Distance before:\" + str(match_report_before[4][i])\n",
    "#         print \"Distance after:\" + str(match_report_after[4][i])\n",
    "#         print \"------------------------------------------------------------------------\"\n",
    "#         print \"------------------------------------------------------------------------\"\n",
    "        \n",
    "print count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print \"Correctly classified before and Almost classified after\"\n",
    "import matplotlib.pyplot as plt\n",
    "count = 0\n",
    "for i in range(len(words)):\n",
    "    if match_report_before[5][i] == 1 \\\n",
    "    and match_report_after[5][i] == 2:\n",
    "        count += 1\n",
    "#         print \"************************************************************************\"\n",
    "#         print \"************************************************************************\"\n",
    "#         q = np.transpose(images_before[i],(1,2,0))\n",
    "#         q1 = np.transpose(images_after[i],(1,2,0))\n",
    "#         plt.imshow(q)\n",
    "#         plt.show()\n",
    "#         plt.imshow(q1)\n",
    "#         plt.show()\n",
    "#         print \"Matched before: \"+\"$\"+str(match_report_before[1][i][0])+\"$\"\n",
    "#         print \"Matched after:\" + \"$\"+str(match_report_after[1][i][0])+\"$\"\n",
    "#         print \"Ground truth:\" + str(words[i])\n",
    "#         print \"Image Dir before:\" + str(match_report_before[2][i])\n",
    "#         print \"Image Dir after:\" + str(match_report_after[2][i])\n",
    "#         print \"Distance before:\" + str(match_report_before[4][i])\n",
    "#         print \"Distance after:\" + str(match_report_after[4][i])\n",
    "#         print \"------------------------------------------------------------------------\"\n",
    "#         print \"------------------------------------------------------------------------\"\n",
    "        \n",
    "print count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print \"Almost classified before and In-correctly classified after\"\n",
    "import matplotlib.pyplot as plt\n",
    "count = 0\n",
    "for i in range(len(words)):\n",
    "    if match_report_before[5][i] == 2 \\\n",
    "    and match_report_after[5][i] == 0:\n",
    "        count += 1\n",
    "#         print \"************************************************************************\"\n",
    "#         print \"************************************************************************\"\n",
    "#         q = np.transpose(images_before[i],(1,2,0))\n",
    "#         q1 = np.transpose(images_after[i],(1,2,0))\n",
    "#         plt.imshow(q)\n",
    "#         plt.show()\n",
    "#         plt.imshow(q1)\n",
    "#         plt.show()\n",
    "#         print \"Image Index: \" + str(i)\n",
    "#         print \"Matched before: \"+\"$\"+str(match_report_before[1][i][0])+\"$\"\n",
    "#         print \"Matched after:\" + \"$\"+str(match_report_after[1][i][0])+\"$\"\n",
    "#         print \"Ground truth:\" + str(words[i])\n",
    "#         print \"Image Dir before:\" + str(match_report_before[2][i])\n",
    "#         print \"Image Dir after:\" + str(match_report_after[2][i])\n",
    "#         print \"Distance before:\" + str(match_report_before[4][i])\n",
    "#         print \"Distance after:\" + str(match_report_after[4][i])\n",
    "#         print \"\\nAll Distances Before:\" + str(match_report_before[6][i])\n",
    "#         print \"\\nAll Distances After:\" + str(match_report_after[6][i])\n",
    "#         print \"------------------------------------------------------------------------\"\n",
    "#         print \"------------------------------------------------------------------------\"\n",
    "        \n",
    "print count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print \"Almost classified before and Correctly classified after\"\n",
    "import matplotlib.pyplot as plt\n",
    "qualified_ids = match_report_before[2]\n",
    "ground_truth = match_report_before[6]\n",
    "count = 0\n",
    "for i in range(len(qualified_ids)):\n",
    "    if match_report_before[5][i] == 2 \\\n",
    "    and match_report_after[5][i] == 1:\n",
    "        count += 1\n",
    "#         print \"************************************************************************\"\n",
    "#         print \"************************************************************************\"\n",
    "#         q = np.transpose(images_before[qualified_ids[i]],(1,2,0))\n",
    "#         q1 = np.transpose(images_after[i],(1,2,0))\n",
    "#         plt.imshow(q)\n",
    "#         plt.show()\n",
    "#         plt.imshow(q1)\n",
    "#         plt.show()\n",
    "#         print \"Matched before: \"+\"$\"+str(match_report_before[1][i][0])+\"$\"\n",
    "#         print \"Matched after:\" + \"$\"+str(match_report_after[1][i][0])+\"$\"\n",
    "#         print \"Ground truth:\" + str(ground_truth[i])\n",
    "#         print \"Image Dir before:\" + str(match_report_before[3][i])\n",
    "#         print \"Image Dir after:\" + str(match_report_after[3][i])\n",
    "#         print \"Distance before:\" + str(match_report_before[7][i])\n",
    "#         print \"Distance after:\" + str(match_report_after[7][i])\n",
    "#         print \"------------------------------------------------------------------------\"\n",
    "#         print \"------------------------------------------------------------------------\"\n",
    "        \n",
    "print count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print \"Almost classified before and Almost classified after\"\n",
    "import matplotlib.pyplot as plt\n",
    "qualified_ids = match_report_before[2]\n",
    "ground_truth = match_report_before[6]\n",
    "count = 0\n",
    "for i in range(len(qualified_ids)):\n",
    "    if match_report_before[5][i] == 2 \\\n",
    "    and match_report_after[5][i] == 2:\n",
    "        count += 1\n",
    "#         print \"************************************************************************\"\n",
    "#         print \"************************************************************************\"\n",
    "#         q = np.transpose(images_before[qualified_ids[i]],(1,2,0))\n",
    "#         q1 = np.transpose(images_after[i],(1,2,0))\n",
    "#         plt.imshow(q)\n",
    "#         plt.show()\n",
    "#         plt.imshow(q1)\n",
    "#         plt.show()\n",
    "#         print \"Matched before: \"+\"$\"+str(match_report_before[1][i][0])+\"$\"\n",
    "#         print \"Matched after:\" + \"$\"+str(match_report_after[1][i][0])+\"$\"\n",
    "#         print \"Ground truth:\" + str(ground_truth[i])\n",
    "#         print \"Image Dir before:\" + str(match_report_before[3][i])\n",
    "#         print \"Image Dir after:\" + str(match_report_after[3][i])\n",
    "#         print \"Distance before:\" + str(match_report_before[7][i])\n",
    "#         print \"Distance after:\" + str(match_report_after[7][i])\n",
    "#         print \"------------------------------------------------------------------------\"\n",
    "#         print \"------------------------------------------------------------------------\"\n",
    "        \n",
    "print count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
