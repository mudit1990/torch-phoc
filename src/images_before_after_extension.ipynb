{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import argparse\n",
    "import logging\n",
    "\n",
    "import numpy as np\n",
    "import torch.autograd\n",
    "import torch.cuda\n",
    "import torch.nn as nn\n",
    "import torch.optim\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import random\n",
    "\n",
    "import copy\n",
    "from datasets.maps_alt import MAPSDataset\n",
    "\n",
    "#from cnn_ws.transformations.homography_augmentation import HomographyAugmentation\n",
    "from cnn_ws.losses.cosine_loss import CosineLoss\n",
    "\n",
    "from cnn_ws.models.myphocnet import PHOCNet\n",
    "from cnn_ws.evaluation.retrieval import map_from_feature_matrix, map_from_query_test_feature_matrices\n",
    "from torch.utils.data.dataloader import _DataLoaderIter as DataLoaderIter\n",
    "from torch.utils.data.sampler import WeightedRandomSampler\n",
    "\n",
    "from cnn_ws.utils.save_load import my_torch_save, my_torch_load\n",
    "\n",
    "#import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_filter_len = 1 # only words above this length are considered valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not torch.cuda.is_available():\n",
    "    logger.warning('Could not find CUDA environment, using CPU mode')\n",
    "    gpu_id = None\n",
    "else:\n",
    "    gpu_id = [0]\n",
    "#torch.cuda.get_device_name(gpu_id[0])\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ = torch.load('models/PHOCNet_Nov13.pt')\n",
    "cnn = model_.module#list(model_.named_parameters())\n",
    "if gpu_id is not None:\n",
    "        if len(gpu_id) > 1:\n",
    "            cnn = nn.DataParallel(cnn, device_ids=gpu_id)\n",
    "            cnn.cuda()\n",
    "        else:\n",
    "            cnn.cuda(gpu_id[0])\n",
    "cnn.training = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from strlocale import BasicLocale\n",
    "\n",
    "def clean_words(words):\n",
    "    lc = BasicLocale()\n",
    "    for i, w in enumerate(words):\n",
    "        try:\n",
    "            words[i] = lc.represent(w).encode('ascii',errors='ignore')\n",
    "        except:\n",
    "            words[i] = w\n",
    "    return words\n",
    "\n",
    "# load before, after images and words, transforms and cleans them\n",
    "# the function also assumes that ground truth words are the same before and after\n",
    "# returns before_images, after_images, words\n",
    "def load_and_transform(map_name):\n",
    "    images_before = np.load('../../../detection_outputs_ready_for_test/ray_regions/'+map_name+'.npy')\n",
    "    words_before = np.load('../../../detection_outputs_ready_for_test/ray_labels/'+map_name+'.npy')\n",
    "    words_before = clean_words(words_before)\n",
    "    images_before, words_before = clean_word_images(images_before, words_before)\n",
    "    images_before = np.transpose(images_before, (0,3,1,2))\n",
    "    \n",
    "    images_after = np.load('../../../detection_outputs_ready_for_test/ray_regions_new/'+map_name+'.npy')\n",
    "    words_after = np.load('../../../detection_outputs_ready_for_test/ray_labels_new/'+map_name+'.npy')\n",
    "    words_after = clean_words(words_after)\n",
    "    images_after, words_after = clean_word_images(images_after, words_after)\n",
    "    images_after = np.transpose(images_after, (0,3,1,2))\n",
    "    \n",
    "    print 'Images Before Shape ', images_before.shape\n",
    "    print 'Words Before Shape ', words_before.shape\n",
    "    print 'Images After Shape ', images_after.shape\n",
    "    print 'Words After Shape ', words_after.shape\n",
    "    return images_before, images_after, words_after\n",
    "\n",
    "def clean_word_images(images, words):\n",
    "    selected_idx = [x for x in range(len(words)) if len(words[x]) > word_filter_len]\n",
    "    images = images[selected_idx]\n",
    "    words = words[selected_idx]\n",
    "    return images, words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert image tnto embedding using the cnn model\n",
    "def get_image_embeddings(cnn, images):\n",
    "    outputs = []\n",
    "    for i in tqdm(range(len(images))):\n",
    "        word_img = images[i]\n",
    "        word_img = 1 - word_img.astype(np.float32) / 255.0\n",
    "        word_img = word_img.reshape((1,) + word_img.shape)\n",
    "        word_img = torch.from_numpy(word_img).float()\n",
    "        word_img = word_img.cuda(gpu_id[0])\n",
    "        word_img = torch.autograd.Variable(word_img)\n",
    "        output = torch.sigmoid(cnn(word_img))\n",
    "        output = output.data.cpu().numpy().flatten()\n",
    "        outputs.append(output)\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to create word variations\n",
    "# word_var is a dictionary that contains all variations as key and 0,1,-1 as value\n",
    "# 0 denotes the root word, -1 denotes var = root_word[:-1], +1 denotes var = root_word[1:]\n",
    "# root_word_var is a dict that stores original_word => all_variations\n",
    "# enable_conf: boolean flag that controls if the confusion logic should be used.\n",
    "# when enabled if a word is a root word as well as a word variation (happens if root words ar rand and grand)\n",
    "# it marks it as to be extended and also stores it in the confusion list\n",
    "def create_word_variations(words, enable_conf=False):\n",
    "    word_var = {}\n",
    "    root_word_var = {}\n",
    "    # create the root word variation dict and set word_var as -1 or +1\n",
    "    for w in words:\n",
    "        if len(w) <= word_filter_len:\n",
    "            continue\n",
    "        root_var_list = [w, w.lower(), w.upper(), w.capitalize()]\n",
    "        var_set = set()\n",
    "        for var in root_var_list:\n",
    "            word_var[var[1:]] = 1\n",
    "            word_var[var[:-1]] = -1\n",
    "            var_set.add(var)\n",
    "            var_set.add(var[1:])\n",
    "            var_set.add(var[:-1])\n",
    "        root_word_var[w] = var_set\n",
    "    # explicitly set all root words to have direction 0\n",
    "    # mark the words that already have a direction set\n",
    "    conf_words = set()\n",
    "    for w in words:\n",
    "        if len(w) <= word_filter_len:\n",
    "            continue\n",
    "        root_var_list = [w, w.lower(), w.upper(), w.capitalize()]\n",
    "        for var in root_var_list:\n",
    "            if var in word_var and word_var[var] != 0 and enable_conf:\n",
    "                conf_words.add(var)\n",
    "            else:\n",
    "                word_var[var] = 0\n",
    "    return word_var, root_word_var, conf_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the PHOC representation of the word itself\n",
    "from cnn_ws.string_embeddings.phoc import build_phoc_descriptor\n",
    "def get_word_phoc_representations(word_strings):\n",
    "    unigrams = [chr(i) for i in range(ord('&'), ord('&')+1) + range(ord('A'), ord('Z')+1) + \\\n",
    "                    range(ord('a'), ord('z') + 1) + range(ord('0'), ord('9') + 1)]\n",
    "    bigram_levels = None\n",
    "    bigrams = None\n",
    "    phoc_unigram_levels=(1, 2, 4, 8)\n",
    "    word_var_dir, root_word_var, conf_words = create_word_variations(word_strings, enable_conf=True)\n",
    "    \n",
    "    word_var_strings = word_var_dir.keys()\n",
    "    embedding_var = build_phoc_descriptor(words=word_var_strings,\n",
    "                                  phoc_unigrams=unigrams,\n",
    "                                  bigram_levels=bigram_levels,\n",
    "                                  phoc_bigrams=bigrams,\n",
    "                                  unigram_levels=phoc_unigram_levels)\n",
    "    \n",
    "    print('embedding variations:', embedding_var.shape)\n",
    "    return (embedding_var, word_var_strings, word_var_dir, root_word_var, conf_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import cdist, pdist, squareform\n",
    "\n",
    "# gets the actual distances of all the ground truth word variations\n",
    "def get_all_dist_gt(dist_mat, emb_info, words):\n",
    "    # expand emb_info tuple\n",
    "    embedding_var, word_var_strings, word_var_dir, root_word_var,_ = emb_info\n",
    "    all_dist = []\n",
    "    for i in range(len(words)):\n",
    "        w_dist = []\n",
    "        w_vars = root_word_var[words[i]]\n",
    "        for j in range(len(word_var_strings)):\n",
    "            if word_var_strings[j] in w_vars:\n",
    "                w_dist.append((word_var_strings[j], dist_mat[i][j]))\n",
    "        all_dist.append(w_dist)\n",
    "    return all_dist\n",
    "\n",
    "# the new report matches method that handles variations\n",
    "def report_matches_with_variations(dist_mat, word_strings, emb_info, k):\n",
    "    # expand emb_info tuple\n",
    "    embedding_var, word_var_strings, word_var_dir, root_word_var,_ = emb_info\n",
    "    gt_words_dist = get_all_dist_gt(dist_mat, emb_info, word_strings)\n",
    "    retrieval_indices = np.argsort(dist_mat, axis=1)\n",
    "    q = retrieval_indices[:,:k]\n",
    "    count = 0\n",
    "    matched_words = []\n",
    "    img_dir = []\n",
    "    words_len = []\n",
    "    actual_dist = []\n",
    "    # get all matched words\n",
    "    for i in range(len(q)):\n",
    "        matched = []\n",
    "        for j in q[i]:\n",
    "            actual_dist.append(dist_mat[i][j])\n",
    "            matched.append(word_var_strings[j])\n",
    "            curr_len = len(word_var_strings[j])\n",
    "            curr_dir = word_var_dir[word_var_strings[j]]\n",
    "            words_len.append(curr_len + abs(curr_dir))\n",
    "            img_dir.append(curr_dir)\n",
    "        matched_words.append(matched)\n",
    "    \n",
    "    # calculate accuracies\n",
    "    is_correct = []\n",
    "    for i in range(len(word_strings)):\n",
    "        is_correct.append(0)\n",
    "        if word_strings[i].lower() in [mw.lower() for mw in matched_words[i]]:\n",
    "            is_correct[i] = 1\n",
    "            count = count+1\n",
    "        else:\n",
    "            for w in matched_words[i]:\n",
    "                if w in root_word_var[word_strings[i]]:\n",
    "                    is_correct[i] = 2\n",
    "                    count = count+1\n",
    "                    break\n",
    "    return (count, matched_words, img_dir, words_len, actual_dist, is_correct, gt_words_dist)\n",
    "\n",
    "# For some images, the original predicted word os both a root word and a word_variation of another word \n",
    "# (common word problem). Due to this one cannot be sure, if these images should be extended or not.\n",
    "# These images are handled by comparing distances before and after image extension and picking the minimum one\n",
    "# the feature can be turned of by setting enable_conf = False\n",
    "def update_dist_matrix(dist_mat_before, dist_mat_after, conf_idx):\n",
    "    print('conf_idx', conf_idx)\n",
    "    for i in conf_idx:\n",
    "        dist = np.minimum(dist_mat_before[i], dist_mat_after[i])\n",
    "        dist_mat_after[i] = dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_confusion_matrix(match_report_before, match_report_after, words):\n",
    "    status = [0,1,2]\n",
    "    conf_matrix = [['before/after','incorrect (0)','correct (1)','almost (2)'],\n",
    "                   ['incorrect (0)',0,0,0],\n",
    "                   ['correct (1)',0,0,0],\n",
    "                   ['almost (2)',0,0,0]]\n",
    "    for i in status:\n",
    "        for j in status:\n",
    "            count = 0\n",
    "            for k in range(len(words)):\n",
    "                if match_report_before[5][k] == i and match_report_after[5][k] == j:\n",
    "                    count += 1\n",
    "            conf_matrix[1+i][1+j] = count\n",
    "    return conf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_before_after_preds(map_name, before_report, after_report, ground_truth):\n",
    "    before_preds = [w[0] for w in before_report[1]]\n",
    "    after_preds = [w[0] for w in after_report[1]]\n",
    "    before_after_pred = np.array([before_preds, after_preds, ground_truth]).T\n",
    "    np.save('../../../before_after_ext_pred/ray_detections/'+map_name+'.npy', before_after_pred)\n",
    "\n",
    "def compare_images_before_after_ext(map_name, cnn, global_stats):\n",
    "    images_before, images_after, words = load_and_transform(map_name)\n",
    "    image_embs_before = get_image_embeddings(cnn, images_before)\n",
    "    image_embs_after = get_image_embeddings(cnn, images_after)\n",
    "    word_emb_info = get_word_phoc_representations(words)\n",
    "    # get the distances between images and words\n",
    "    dist_matrix_before = cdist(XA=image_embs_before, XB=word_emb_info[0], metric='cosine')\n",
    "    dist_matrix_after = cdist(XA=image_embs_after, XB=word_emb_info[0], metric='cosine')\n",
    "    # build the original report\n",
    "    match_report_before = report_matches_with_variations(dist_matrix_before, words, word_emb_info, 1)\n",
    "    # get the low confidence image index\n",
    "    conf_idx = [i for i in range(len(match_report_before[1])) if match_report_before[1][i][0] in word_emb_info[4]]\n",
    "    # update the dist_after matrix based for low confidence images\n",
    "    update_dist_matrix(dist_matrix_before, dist_matrix_after, conf_idx)\n",
    "    # build the report after extension\n",
    "    match_report_after = report_matches_with_variations(dist_matrix_after, words, word_emb_info, 1)\n",
    "    save_before_after_preds(map_name, match_report_before, match_report_after, words)\n",
    "    global_stats['correct_before'] += match_report_before[0]\n",
    "    global_stats['correct_after'] += match_report_after[0]\n",
    "    global_stats['total'] += len(words)\n",
    "    acc_before = match_report_before[0]/len(words)\n",
    "    acc_after = match_report_after[0]/len(words)\n",
    "    conf_matrix = generate_confusion_matrix(match_report_before, match_report_after, words)\n",
    "    return (acc_before, acc_after, conf_matrix, match_report_before, match_report_after)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the file names\n",
    "# f = open('../splits/test_files.txt', 'rb')\n",
    "# A = f.readlines()\n",
    "# f.close()\n",
    "# A = [x.rstrip('\\n') for x in A]\n",
    "# # train maps to remove\n",
    "# # A.remove('D0042-1070013')\n",
    "# # test maps to remove\n",
    "# A.remove('D5005-5028102')\n",
    "A = ['D0042-1070001','D0042-1070002','D0042-1070006','D0042-1070007','D0117-5755018','D0117-5755035','D0117-5755036']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8af5a0323fce404789c6482b87ae7df2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description=u'Main Iteration', max=7), HTML(value=u'')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D0042-1070001\n",
      "Images Before Shape  (1078, 3, 135, 487)\n",
      "Words Before Shape  (1078,)\n",
      "Images After Shape  (1078, 3, 135, 487)\n",
      "Words After Shape  (1078,)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7ff89ac8523408d82c094220dc039b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1078), HTML(value=u'')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e82e985f6c30437bade22329988d7bf1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1078), HTML(value=u'')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1813/1813 [00:00<00:00, 4272.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('embedding variations:', (1813, 945))\n",
      "('conf_idx', [61, 87, 95, 134, 169, 175, 178, 187, 194, 199, 200, 219, 229, 230, 246, 247, 248, 260, 267, 281, 314, 315, 411, 417, 440, 472, 492, 503, 505, 508, 534, 602, 634, 645, 668, 688, 730, 746, 770, 777, 876, 890, 898, 953, 959, 978, 980, 982, 1047, 1055])\n",
      "D0042-1070002\n",
      "Images Before Shape  (1139, 3, 135, 487)\n",
      "Words Before Shape  (1139,)\n",
      "Images After Shape  (1139, 3, 135, 487)\n",
      "Words After Shape  (1139,)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16972550ff724e6492a20ab5d2c74c5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1139), HTML(value=u'')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36968919be274b38871c3c325a88be33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1139), HTML(value=u'')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2120/2120 [00:00<00:00, 4699.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('embedding variations:', (2120, 945))\n",
      "('conf_idx', [79, 91, 110, 142, 162, 210, 230, 246, 252, 256, 257, 260, 267, 268, 283, 311, 319, 331, 336, 348, 358, 368, 385, 409, 475, 519, 526, 533, 554, 564, 571, 597, 644, 657, 728, 790, 809, 871, 875, 905, 919, 933, 941, 942, 953, 1022, 1031, 1034, 1036, 1044, 1051, 1062, 1101])\n",
      "D0042-1070006\n",
      "Images Before Shape  (2339, 3, 135, 487)\n",
      "Words Before Shape  (2339,)\n",
      "Images After Shape  (2339, 3, 135, 487)\n",
      "Words After Shape  (2339,)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c85b883a0ff14d0daeef4fc439b110e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=2339), HTML(value=u'')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5668ebb221bb4f5293e3121d155d5e37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=2339), HTML(value=u'')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2828/2828 [00:00<00:00, 5653.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('embedding variations:', (2828, 945))\n",
      "('conf_idx', [2, 3, 5, 47, 49, 68, 108, 116, 124, 149, 152, 155, 158, 161, 162, 163, 171, 173, 178, 180, 184, 188, 191, 195, 196, 207, 208, 212, 213, 214, 217, 218, 221, 224, 225, 236, 242, 279, 282, 288, 290, 292, 294, 297, 298, 299, 308, 313, 317, 323, 325, 327, 330, 331, 335, 343, 347, 349, 351, 352, 359, 361, 362, 365, 366, 367, 370, 374, 383, 384, 388, 393, 394, 398, 400, 426, 433, 436, 441, 444, 445, 450, 453, 473, 476, 484, 486, 491, 492, 494, 500, 510, 521, 531, 535, 540, 542, 558, 567, 571, 574, 581, 582, 594, 598, 621, 622, 638, 659, 678, 682, 684, 686, 689, 692, 696, 697, 724, 734, 735, 748, 752, 760, 791, 808, 809, 815, 818, 820, 822, 841, 847, 861, 890, 891, 892, 972, 992, 1007, 1016, 1027, 1028, 1034, 1035, 1049, 1053, 1062, 1063, 1078, 1079, 1080, 1101, 1114, 1116, 1131, 1152, 1153, 1160, 1163, 1169, 1172, 1174, 1175, 1180, 1181, 1194, 1207, 1208, 1209, 1214, 1219, 1224, 1239, 1242, 1243, 1244, 1245, 1247, 1253, 1255, 1260, 1265, 1270, 1274, 1277, 1281, 1284, 1303, 1309, 1310, 1317, 1320, 1325, 1332, 1336, 1342, 1347, 1354, 1361, 1392, 1420, 1421, 1431, 1477, 1492, 1508, 1527, 1544, 1545, 1555, 1562, 1567, 1571, 1592, 1596, 1608, 1609, 1612, 1614, 1619, 1620, 1622, 1623, 1627, 1628, 1629, 1630, 1639, 1640, 1641, 1642, 1647, 1653, 1654, 1656, 1657, 1658, 1661, 1668, 1669, 1670, 1678, 1679, 1683, 1689, 1693, 1708, 1710, 1711, 1713, 1715, 1717, 1722, 1730, 1733, 1735, 1736, 1742, 1743, 1745, 1748, 1749, 1751, 1752, 1763, 1775, 1779, 1794, 1803, 1804, 1810, 1811, 1830, 1831, 1833, 1837, 1844, 1848, 1854, 1859, 1865, 1868, 1870, 1876, 1881, 1887, 1892, 1898, 1901, 1911, 1921, 1935, 1947, 1972, 1987, 1991, 1997, 2020, 2037, 2058, 2066, 2073, 2079, 2081, 2082, 2083, 2087, 2103, 2106, 2119, 2132, 2136, 2141, 2160, 2180, 2198, 2207, 2208, 2215, 2217, 2226, 2234, 2244, 2258, 2276, 2328, 2336])\n",
      "D0042-1070007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "strlocale.py:137: UnicodeWarning: Unicode equal comparison failed to convert both arguments to Unicode - interpreting them as being unequal\n",
      "  if c in self._diacrit_dict: # Replace simple diacritic\n",
      "strlocale.py:152: UnicodeWarning: Unicode equal comparison failed to convert both arguments to Unicode - interpreting them as being unequal\n",
      "  return [c if (c not in self.__filtered) else u'' for c in chars]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images Before Shape  (1302, 3, 135, 487)\n",
      "Words Before Shape  (1302,)\n",
      "Images After Shape  (1302, 3, 135, 487)\n",
      "Words After Shape  (1302,)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1b24aa584034536b3fc28a4a3a7e90f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1302), HTML(value=u'')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6519cc685b346908c2c6770d6b7bf97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1302), HTML(value=u'')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2037/2037 [00:00<00:00, 5397.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('embedding variations:', (2037, 945))\n",
      "('conf_idx', [38, 54, 82, 84, 100, 140, 161, 185, 219, 224, 230, 258, 265, 274, 277, 306, 310, 345, 354, 371, 410, 450, 557, 672, 695, 763, 834, 850, 859, 875, 880, 884, 897, 915, 937, 939, 940, 947, 967, 989, 1009, 1047, 1079, 1087, 1089, 1118, 1152, 1278])\n",
      "D0117-5755018\n",
      "Images Before Shape  (3501, 3, 135, 487)\n",
      "Words Before Shape  (3501,)\n",
      "Images After Shape  (3501, 3, 135, 487)\n",
      "Words After Shape  (3501,)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05f7c48423c4488cbb1423479f853a68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=3501), HTML(value=u'')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afda7a8e4e1a4cf7953c2e0734f86454",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=3501), HTML(value=u'')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5321/5321 [00:00<00:00, 5541.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('embedding variations:', (5321, 945))\n",
      "('conf_idx', [7, 9, 123, 151, 159, 161, 183, 187, 205, 220, 221, 222, 224, 226, 239, 243, 244, 246, 252, 253, 254, 260, 261, 267, 272, 279, 282, 297, 302, 305, 307, 309, 313, 314, 321, 326, 328, 330, 331, 332, 333, 337, 345, 360, 363, 369, 378, 382, 384, 386, 391, 392, 394, 399, 410, 411, 412, 418, 421, 422, 428, 429, 437, 438, 440, 444, 456, 458, 465, 468, 470, 474, 481, 483, 484, 489, 498, 505, 511, 512, 515, 520, 523, 527, 539, 542, 544, 545, 551, 562, 566, 571, 575, 580, 582, 584, 588, 591, 600, 604, 612, 628, 635, 637, 639, 647, 658, 660, 667, 668, 682, 687, 697, 698, 705, 707, 708, 714, 729, 731, 733, 749, 774, 790, 793, 813, 820, 830, 832, 846, 872, 891, 892, 901, 919, 920, 926, 929, 945, 950, 954, 956, 975, 977, 995, 998, 1005, 1006, 1008, 1013, 1021, 1028, 1041, 1045, 1049, 1069, 1084, 1093, 1100, 1103, 1116, 1126, 1142, 1149, 1167, 1193, 1202, 1208, 1214, 1215, 1219, 1236, 1254, 1265, 1288, 1299, 1323, 1327, 1340, 1349, 1361, 1368, 1369, 1379, 1380, 1389, 1397, 1437, 1494, 1563, 1577, 1612, 1618, 1625, 1633, 1636, 1641, 1646, 1669, 1678, 1682, 1702, 1703, 1715, 1721, 1727, 1759, 1770, 1775, 1776, 1804, 1830, 1838, 1839, 1849, 1876, 1882, 1918, 1921, 1922, 1923, 1924, 1925, 1927, 1933, 1934, 1939, 1943, 1950, 1954, 1955, 1957, 1958, 1959, 1960, 1961, 1964, 1965, 1969, 1971, 1974, 1976, 1977, 1980, 1981, 1982, 1984, 1985, 1987, 1995, 1997, 1999, 2001, 2002, 2004, 2007, 2008, 2009, 2010, 2011, 2020, 2024, 2030, 2033, 2036, 2041, 2043, 2044, 2047, 2057, 2058, 2060, 2061, 2063, 2065, 2069, 2073, 2081, 2087, 2089, 2091, 2097, 2098, 2101, 2103, 2105, 2107, 2111, 2115, 2120, 2121, 2123, 2129, 2132, 2136, 2145, 2148, 2149, 2156, 2157, 2161, 2168, 2169, 2171, 2181, 2223, 2303, 2306, 2318, 2356, 2362, 2363, 2401, 2406, 2408, 2411, 2412, 2418, 2420, 2424, 2426, 2430, 2436, 2437, 2442, 2445, 2446, 2448, 2450, 2453, 2455, 2457, 2460, 2463, 2464, 2466, 2467, 2468, 2473, 2475, 2476, 2477, 2484, 2486, 2487, 2489, 2495, 2499, 2504, 2508, 2509, 2513, 2515, 2521, 2522, 2524, 2526, 2531, 2532, 2534, 2537, 2540, 2541, 2542, 2547, 2552, 2555, 2556, 2561, 2562, 2563, 2564, 2565, 2571, 2576, 2581, 2591, 2592, 2594, 2599, 2603, 2608, 2609, 2610, 2611, 2613, 2614, 2616, 2618, 2622, 2626, 2632, 2635, 2636, 2638, 2648, 2656, 2659, 2662, 2665, 2666, 2672, 2675, 2679, 2682, 2693, 2694, 2696, 2697, 2699, 2700, 2703, 2709, 2713, 2715, 2716, 2727, 2728, 2729, 2736, 2741, 2744, 2746, 2747, 2752, 2760, 2763, 2767, 2784, 2788, 2805, 2808, 2812, 2814, 2822, 2828, 2849, 2850, 2864, 2866, 2873, 2874, 2875, 2878, 2880, 2884, 2889, 2901, 2903, 2906, 2922, 2929, 2935, 2967, 2968, 2975, 2981, 3020, 3033, 3058, 3069, 3081, 3095, 3105, 3108, 3111, 3117, 3129, 3134, 3136, 3148, 3158, 3164, 3183, 3208, 3241, 3244, 3285, 3286, 3309, 3317, 3341, 3342, 3347, 3354, 3355, 3363])\n",
      "D0117-5755035\n",
      "Images Before Shape  (2189, 3, 135, 487)\n",
      "Words Before Shape  (2189,)\n",
      "Images After Shape  (2189, 3, 135, 487)\n",
      "Words After Shape  (2189,)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c7ad6608fbd49668574193c042499e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=2189), HTML(value=u'')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5b4a3524ac34ccd979810bcf96c7f77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=2189), HTML(value=u'')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3616/3616 [00:00<00:00, 5860.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('embedding variations:', (3616, 945))\n",
      "('conf_idx', [33, 51, 73, 78, 89, 100, 106, 111, 123, 127, 134, 143, 149, 154, 161, 163, 165, 169, 176, 178, 183, 188, 190, 215, 218, 220, 235, 267, 270, 275, 303, 309, 318, 319, 320, 322, 323, 333, 351, 354, 356, 366, 368, 374, 388, 389, 393, 404, 418, 432, 439, 440, 445, 450, 452, 470, 472, 474, 476, 494, 497, 506, 527, 533, 556, 567, 613, 625, 629, 631, 633, 635, 648, 667, 686, 697, 725, 728, 758, 769, 782, 805, 838, 843, 852, 862, 868, 884, 941, 948, 954, 994, 1014, 1023, 1030, 1036, 1046, 1061, 1071, 1086, 1103, 1105, 1111, 1118, 1119, 1121, 1126, 1132, 1133, 1142, 1146, 1150, 1152, 1156, 1157, 1162, 1170, 1172, 1173, 1185, 1186, 1199, 1217, 1228, 1236, 1237, 1243, 1244, 1246, 1247, 1249, 1271, 1290, 1322, 1332, 1352, 1360, 1371, 1380, 1393, 1405, 1407, 1409, 1410, 1415, 1419, 1425, 1426, 1429, 1430, 1436, 1441, 1457, 1467, 1476, 1477, 1479, 1480, 1482, 1484, 1485, 1486, 1487, 1501, 1505, 1506, 1507, 1509, 1511, 1522, 1528, 1537, 1564, 1570, 1573, 1585, 1588, 1590, 1592, 1595, 1607, 1618, 1619, 1621, 1625, 1648, 1656, 1657, 1658, 1659, 1664, 1665, 1667, 1680, 1686, 1700, 1708, 1711, 1723, 1728, 1735, 1759, 1767, 1783, 1797, 1800, 1813, 1820, 1829, 1861, 1881, 1882, 1893, 1902, 1906, 1919, 1921, 1925, 1935, 1937, 1941, 1944, 1947, 1978, 1996, 2002, 2022, 2024, 2050, 2079])\n",
      "D0117-5755036\n",
      "Images Before Shape  (2576, 3, 135, 487)\n",
      "Words Before Shape  (2576,)\n",
      "Images After Shape  (2576, 3, 135, 487)\n",
      "Words After Shape  (2576,)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0568d9382184c058625fa89311fac5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=2576), HTML(value=u'')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75343d1bbd084d40a1eac313164543b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=2576), HTML(value=u'')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4247/4247 [00:00<00:00, 5954.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('embedding variations:', (4247, 945))\n",
      "('conf_idx', [92, 110, 129, 130, 133, 135, 146, 149, 161, 166, 168, 176, 179, 195, 204, 211, 221, 240, 262, 273, 284, 286, 306, 311, 313, 314, 316, 325, 331, 351, 354, 357, 374, 401, 405, 420, 421, 422, 434, 446, 448, 449, 451, 455, 468, 495, 506, 521, 523, 534, 536, 538, 542, 545, 553, 574, 579, 586, 603, 613, 619, 625, 631, 642, 646, 658, 664, 670, 677, 697, 702, 706, 719, 721, 734, 759, 798, 807, 840, 862, 867, 872, 879, 894, 899, 905, 907, 911, 916, 919, 921, 936, 942, 943, 957, 994, 999, 1001, 1005, 1022, 1031, 1109, 1134, 1166, 1187, 1191, 1198, 1237, 1239, 1267, 1270, 1274, 1277, 1291, 1292, 1295, 1299, 1300, 1309, 1312, 1314, 1319, 1321, 1323, 1324, 1327, 1328, 1339, 1340, 1344, 1345, 1354, 1356, 1358, 1365, 1368, 1371, 1375, 1385, 1386, 1387, 1388, 1390, 1394, 1398, 1399, 1405, 1409, 1410, 1411, 1419, 1422, 1425, 1436, 1439, 1445, 1446, 1447, 1455, 1456, 1457, 1464, 1527, 1540, 1590, 1593, 1598, 1600, 1630, 1652, 1653, 1655, 1663, 1664, 1667, 1670, 1677, 1678, 1687, 1693, 1707, 1709, 1712, 1713, 1717, 1723, 1724, 1728, 1748, 1752, 1754, 1764, 1768, 1776, 1782, 1791, 1800, 1807, 1809, 1811, 1813, 1815, 1819, 1820, 1829, 1836, 1839, 1841, 1845, 1850, 1852, 1868, 1870, 1878, 1880, 1881, 1884, 1885, 1891, 1895, 1897, 1900, 1902, 1903, 1908, 1911, 1927, 1929, 1957, 1966, 1978, 1988, 1989, 2004, 2010, 2017, 2035, 2037, 2045, 2046, 2047, 2056, 2057, 2071, 2073, 2078, 2089, 2094, 2105, 2111, 2127, 2140, 2143, 2145, 2152, 2195, 2198, 2205, 2212, 2215, 2241, 2259, 2274, 2297, 2300, 2309, 2310, 2313, 2316, 2322, 2326, 2331, 2366, 2370, 2372, 2375, 2422, 2429, 2446, 2456, 2469, 2502, 2540, 2541, 2543, 2545, 2564])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "global_stats = {'correct_before':0, 'correct_after':0, 'total':0}\n",
    "local_stats = []\n",
    "for i in tqdm(range(len(A)), ascii=True, desc='Main Iteration'):\n",
    "    print A[i]\n",
    "    stats = compare_images_before_after_ext(A[i], cnn, global_stats)\n",
    "    local_stats.append(stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for image D0042-1070001\n",
      "the accuracy before extension: 0.49814471243\n",
      "the accuracy after extension: 0.503710575139\n",
      "\n",
      "\n",
      "Accuracy for image D0042-1070002\n",
      "the accuracy before extension: 0.40825285338\n",
      "the accuracy after extension: 0.412642669008\n",
      "\n",
      "\n",
      "Accuracy for image D0042-1070006\n",
      "the accuracy before extension: 0.351004702864\n",
      "the accuracy after extension: 0.354852501069\n",
      "\n",
      "\n",
      "Accuracy for image D0042-1070007\n",
      "the accuracy before extension: 0.357910906298\n",
      "the accuracy after extension: 0.375576036866\n",
      "\n",
      "\n",
      "Accuracy for image D0117-5755018\n",
      "the accuracy before extension: 0.469294487289\n",
      "the accuracy after extension: 0.476435304199\n",
      "\n",
      "\n",
      "Accuracy for image D0117-5755035\n",
      "the accuracy before extension: 0.479671082686\n",
      "the accuracy after extension: 0.480127912289\n",
      "\n",
      "\n",
      "Accuracy for image D0117-5755036\n",
      "the accuracy before extension: 0.503105590062\n",
      "the accuracy after extension: 0.509316770186\n",
      "\n",
      "\n",
      "Overall Accuracy Before  0.444491645426\n",
      "Overall Accuracy After 0.450509770603\n"
     ]
    }
   ],
   "source": [
    "# print accuracies\n",
    "for i in range(len(A)):\n",
    "    print('Accuracy for image '+A[i])\n",
    "    print \"the accuracy before extension: \" + str(local_stats[i][0])\n",
    "    print \"the accuracy after extension: \"+str(local_stats[i][1])\n",
    "    print('\\n')\n",
    "    \n",
    "print 'Overall Accuracy Before ', global_stats['correct_before']/global_stats['total']\n",
    "print 'Overall Accuracy After', global_stats['correct_after']/global_stats['total']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix for Image D0090-5242001\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table><tr><td>before/after</td><td>incorrect (0)</td><td>correct (1)</td><td>almost (2)</td></tr><tr><td>incorrect (0)</td><td>262</td><td>5</td><td>22</td></tr><tr><td>correct (1)</td><td>0</td><td>101</td><td>0</td></tr><tr><td>almost (2)</td><td>8</td><td>25</td><td>46</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Confusion Matrix for Image D0117-5755018\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table><tr><td>before/after</td><td>incorrect (0)</td><td>correct (1)</td><td>almost (2)</td></tr><tr><td>incorrect (0)</td><td>615</td><td>17</td><td>10</td></tr><tr><td>correct (1)</td><td>0</td><td>413</td><td>0</td></tr><tr><td>almost (2)</td><td>8</td><td>131</td><td>103</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Confusion Matrix for Image D0117-5755024\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table><tr><td>before/after</td><td>incorrect (0)</td><td>correct (1)</td><td>almost (2)</td></tr><tr><td>incorrect (0)</td><td>806</td><td>14</td><td>19</td></tr><tr><td>correct (1)</td><td>0</td><td>418</td><td>0</td></tr><tr><td>almost (2)</td><td>13</td><td>148</td><td>118</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Confusion Matrix for Image D0117-5755025\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table><tr><td>before/after</td><td>incorrect (0)</td><td>correct (1)</td><td>almost (2)</td></tr><tr><td>incorrect (0)</td><td>409</td><td>5</td><td>21</td></tr><tr><td>correct (1)</td><td>0</td><td>283</td><td>0</td></tr><tr><td>almost (2)</td><td>8</td><td>84</td><td>85</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Confusion Matrix for Image D0117-5755033\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table><tr><td>before/after</td><td>incorrect (0)</td><td>correct (1)</td><td>almost (2)</td></tr><tr><td>incorrect (0)</td><td>592</td><td>12</td><td>12</td></tr><tr><td>correct (1)</td><td>0</td><td>331</td><td>0</td></tr><tr><td>almost (2)</td><td>8</td><td>89</td><td>97</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import HTML, display\n",
    "def print_conf_matrix(conf_matrix):\n",
    "    display(HTML(\n",
    "    '<table><tr>{}</tr></table>'.format(\n",
    "        '</tr><tr>'.join(\n",
    "            '<td>{}</td>'.format('</td><td>'.join(str(_) for _ in row)) for row in conf_matrix)\n",
    "        )\n",
    "    ))\n",
    "\n",
    "# print the confusion matrix\n",
    "for i in range(len(A)):\n",
    "    conf_matrix = local_stats[i][2]\n",
    "    print('Confusion Matrix for Image ' + A[i])\n",
    "    print_conf_matrix(conf_matrix)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print \"Incorrectly classified before and Incorrectly classified after\"\n",
    "import matplotlib.pyplot as plt\n",
    "ground_truth = match_report_before[1]\n",
    "count = 0\n",
    "for i in range(len(words)):\n",
    "    if match_report_before[5][i] == 0 \\\n",
    "    and match_report_after[5][i] == 0:\n",
    "        count += 1\n",
    "#         print \"************************************************************************\"\n",
    "#         print \"************************************************************************\"\n",
    "#         q = np.transpose(images_before[i],(1,2,0))\n",
    "#         q1 = np.transpose(images_after[i],(1,2,0))\n",
    "#         plt.imshow(q)\n",
    "#         plt.show()\n",
    "#         plt.imshow(q1)\n",
    "#         plt.show()\n",
    "#         print \"Matched before: \"+\"$\"+str(match_report_before[1][i][0])+\"$\"\n",
    "#         print \"Matched after:\" + \"$\"+str(match_report_after[1][i][0])+\"$\"\n",
    "#         print \"Ground truth:\" + str(words[i])\n",
    "#         print \"Image Dir before:\" + str(match_report_before[2][i])\n",
    "#         print \"Image Dir after:\" + str(match_report_after[2][i])\n",
    "#         print \"Distance before:\" + str(match_report_before[4][i])\n",
    "#         print \"Distance after:\" + str(match_report_after[4][i])\n",
    "#         print \"------------------------------------------------------------------------\"\n",
    "#         print \"------------------------------------------------------------------------\"\n",
    "        \n",
    "print count\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print \"Incorrectly classified before and Correctly classified after\"\n",
    "import matplotlib.pyplot as plt\n",
    "count = 0\n",
    "for i in range(len(words)):\n",
    "    if match_report_before[5][i] == 0 \\\n",
    "    and match_report_after[5][i] == 1:\n",
    "        count += 1\n",
    "#         print \"************************************************************************\"\n",
    "#         print \"************************************************************************\"\n",
    "#         q = np.transpose(images_before[i],(1,2,0))\n",
    "#         q1 = np.transpose(images_after[i],(1,2,0))\n",
    "#         plt.imshow(q)\n",
    "#         plt.show()\n",
    "#         plt.imshow(q1)\n",
    "#         plt.show()\n",
    "#         print \"Matched before: \"+\"$\"+str(match_report_before[1][i][0])+\"$\"\n",
    "#         print \"Matched after:\" + \"$\"+str(match_report_after[1][i][0])+\"$\"\n",
    "#         print \"Ground truth:\" + str(words[i])\n",
    "#         print \"Image Dir before:\" + str(match_report_before[2][i])\n",
    "#         print \"Image Dir after:\" + str(match_report_after[2][i])\n",
    "#         print \"Distance before:\" + str(match_report_before[4][i])\n",
    "#         print \"Distance after:\" + str(match_report_after[4][i])\n",
    "#         print \"------------------------------------------------------------------------\"\n",
    "#         print \"------------------------------------------------------------------------\"\n",
    "        \n",
    "print count   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print \"Incorrectly classified before and Almost correctly classified after\"\n",
    "import matplotlib.pyplot as plt\n",
    "count = 0\n",
    "for i in range(len(words)):\n",
    "    if match_report_before[5][i] == 0 \\\n",
    "    and match_report_after[5][i] == 2:\n",
    "        count += 1\n",
    "#         print \"************************************************************************\"\n",
    "#         print \"************************************************************************\"\n",
    "#         q = np.transpose(images_before[i],(1,2,0))\n",
    "#         q1 = np.transpose(images_after[i],(1,2,0))\n",
    "#         plt.imshow(q)\n",
    "#         plt.show()\n",
    "#         plt.imshow(q1)\n",
    "#         plt.show()\n",
    "#         print \"Matched before: \"+\"$\"+str(match_report_before[1][i][0])+\"$\"\n",
    "#         print \"Matched after:\" + \"$\"+str(match_report_after[1][i][0])+\"$\"\n",
    "#         print \"Ground truth:\" + str(words[i])\n",
    "#         print \"Image Dir before:\" + str(match_report_before[2][i])\n",
    "#         print \"Image Dir after:\" + str(match_report_after[2][i])\n",
    "#         print \"Distance before:\" + str(match_report_before[4][i])\n",
    "#         print \"Distance after:\" + str(match_report_after[4][i])\n",
    "#         print \"------------------------------------------------------------------------\"\n",
    "#         print \"------------------------------------------------------------------------\"\n",
    "        \n",
    "print count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print \"Correctly classified before and Incorrectly classified after\"\n",
    "import matplotlib.pyplot as plt\n",
    "count = 0\n",
    "for i in range(len(words)):\n",
    "    if match_report_before[5][i] == 1 \\\n",
    "    and match_report_after[5][i] == 0:\n",
    "        count += 1\n",
    "        print \"************************************************************************\"\n",
    "        print \"************************************************************************\"\n",
    "        q = np.transpose(images_before[i],(1,2,0))\n",
    "        q1 = np.transpose(images_after[i],(1,2,0))\n",
    "        plt.imshow(q)\n",
    "        plt.show()\n",
    "        plt.imshow(q1)\n",
    "        plt.show()\n",
    "        print \"Matched before: \"+\"$\"+str(match_report_before[1][i][0])+\"$\"\n",
    "        print \"Matched after:\" + \"$\"+str(match_report_after[1][i][0])+\"$\"\n",
    "        print \"Ground truth:\" + str(words[i])\n",
    "        print \"Image Dir before:\" + str(match_report_before[2][i])\n",
    "        print \"Image Dir after:\" + str(match_report_after[2][i])\n",
    "        print \"Distance before:\" + str(match_report_before[4][i])\n",
    "        print \"Distance after:\" + str(match_report_after[4][i])\n",
    "        print \"------------------------------------------------------------------------\"\n",
    "        print \"------------------------------------------------------------------------\"\n",
    "        \n",
    "print count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print \"Correctly classified before and Correctly classified after\"\n",
    "import matplotlib.pyplot as plt\n",
    "qualified_ids = match_report_before[2]\n",
    "ground_truth = match_report_before[6]\n",
    "count = 0\n",
    "for i in range(len(qualified_ids)):\n",
    "    if match_report_before[5][i] == 1 \\\n",
    "    and match_report_after[5][i] == 1:\n",
    "        count += 1\n",
    "#         print \"************************************************************************\"\n",
    "#         print \"************************************************************************\"\n",
    "#         q = np.transpose(images_before[i],(1,2,0))\n",
    "#         q1 = np.transpose(images_after[i],(1,2,0))\n",
    "#         plt.imshow(q)\n",
    "#         plt.show()\n",
    "#         plt.imshow(q1)\n",
    "#         plt.show()\n",
    "#         print \"Matched before: \"+\"$\"+str(match_report_before[1][i][0])+\"$\"\n",
    "#         print \"Matched after:\" + \"$\"+str(match_report_after[1][i][0])+\"$\"\n",
    "#         print \"Ground truth:\" + str(words[i])\n",
    "#         print \"Image Dir before:\" + str(match_report_before[2][i])\n",
    "#         print \"Image Dir after:\" + str(match_report_after[2][i])\n",
    "#         print \"Distance before:\" + str(match_report_before[4][i])\n",
    "#         print \"Distance after:\" + str(match_report_after[4][i])\n",
    "#         print \"------------------------------------------------------------------------\"\n",
    "#         print \"------------------------------------------------------------------------\"\n",
    "        \n",
    "print count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print \"Correctly classified before and Almost classified after\"\n",
    "import matplotlib.pyplot as plt\n",
    "count = 0\n",
    "for i in range(len(words)):\n",
    "    if match_report_before[5][i] == 1 \\\n",
    "    and match_report_after[5][i] == 2:\n",
    "        count += 1\n",
    "#         print \"************************************************************************\"\n",
    "#         print \"************************************************************************\"\n",
    "#         q = np.transpose(images_before[i],(1,2,0))\n",
    "#         q1 = np.transpose(images_after[i],(1,2,0))\n",
    "#         plt.imshow(q)\n",
    "#         plt.show()\n",
    "#         plt.imshow(q1)\n",
    "#         plt.show()\n",
    "#         print \"Matched before: \"+\"$\"+str(match_report_before[1][i][0])+\"$\"\n",
    "#         print \"Matched after:\" + \"$\"+str(match_report_after[1][i][0])+\"$\"\n",
    "#         print \"Ground truth:\" + str(words[i])\n",
    "#         print \"Image Dir before:\" + str(match_report_before[2][i])\n",
    "#         print \"Image Dir after:\" + str(match_report_after[2][i])\n",
    "#         print \"Distance before:\" + str(match_report_before[4][i])\n",
    "#         print \"Distance after:\" + str(match_report_after[4][i])\n",
    "#         print \"------------------------------------------------------------------------\"\n",
    "#         print \"------------------------------------------------------------------------\"\n",
    "        \n",
    "print count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print \"Almost classified before and In-correctly classified after\"\n",
    "import matplotlib.pyplot as plt\n",
    "count = 0\n",
    "for i in range(len(words)):\n",
    "    if match_report_before[5][i] == 2 \\\n",
    "    and match_report_after[5][i] == 0:\n",
    "        count += 1\n",
    "#         print \"************************************************************************\"\n",
    "#         print \"************************************************************************\"\n",
    "#         q = np.transpose(images_before[i],(1,2,0))\n",
    "#         q1 = np.transpose(images_after[i],(1,2,0))\n",
    "#         plt.imshow(q)\n",
    "#         plt.show()\n",
    "#         plt.imshow(q1)\n",
    "#         plt.show()\n",
    "#         print \"Image Index: \" + str(i)\n",
    "#         print \"Matched before: \"+\"$\"+str(match_report_before[1][i][0])+\"$\"\n",
    "#         print \"Matched after:\" + \"$\"+str(match_report_after[1][i][0])+\"$\"\n",
    "#         print \"Ground truth:\" + str(words[i])\n",
    "#         print \"Image Dir before:\" + str(match_report_before[2][i])\n",
    "#         print \"Image Dir after:\" + str(match_report_after[2][i])\n",
    "#         print \"Distance before:\" + str(match_report_before[4][i])\n",
    "#         print \"Distance after:\" + str(match_report_after[4][i])\n",
    "#         print \"\\nAll Distances Before:\" + str(match_report_before[6][i])\n",
    "#         print \"\\nAll Distances After:\" + str(match_report_after[6][i])\n",
    "#         print \"------------------------------------------------------------------------\"\n",
    "#         print \"------------------------------------------------------------------------\"\n",
    "        \n",
    "print count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print \"Almost classified before and Correctly classified after\"\n",
    "import matplotlib.pyplot as plt\n",
    "qualified_ids = match_report_before[2]\n",
    "ground_truth = match_report_before[6]\n",
    "count = 0\n",
    "for i in range(len(qualified_ids)):\n",
    "    if match_report_before[5][i] == 2 \\\n",
    "    and match_report_after[5][i] == 1:\n",
    "        count += 1\n",
    "#         print \"************************************************************************\"\n",
    "#         print \"************************************************************************\"\n",
    "#         q = np.transpose(images_before[qualified_ids[i]],(1,2,0))\n",
    "#         q1 = np.transpose(images_after[i],(1,2,0))\n",
    "#         plt.imshow(q)\n",
    "#         plt.show()\n",
    "#         plt.imshow(q1)\n",
    "#         plt.show()\n",
    "#         print \"Matched before: \"+\"$\"+str(match_report_before[1][i][0])+\"$\"\n",
    "#         print \"Matched after:\" + \"$\"+str(match_report_after[1][i][0])+\"$\"\n",
    "#         print \"Ground truth:\" + str(ground_truth[i])\n",
    "#         print \"Image Dir before:\" + str(match_report_before[3][i])\n",
    "#         print \"Image Dir after:\" + str(match_report_after[3][i])\n",
    "#         print \"Distance before:\" + str(match_report_before[7][i])\n",
    "#         print \"Distance after:\" + str(match_report_after[7][i])\n",
    "#         print \"------------------------------------------------------------------------\"\n",
    "#         print \"------------------------------------------------------------------------\"\n",
    "        \n",
    "print count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print \"Almost classified before and Almost classified after\"\n",
    "import matplotlib.pyplot as plt\n",
    "qualified_ids = match_report_before[2]\n",
    "ground_truth = match_report_before[6]\n",
    "count = 0\n",
    "for i in range(len(qualified_ids)):\n",
    "    if match_report_before[5][i] == 2 \\\n",
    "    and match_report_after[5][i] == 2:\n",
    "        count += 1\n",
    "#         print \"************************************************************************\"\n",
    "#         print \"************************************************************************\"\n",
    "#         q = np.transpose(images_before[qualified_ids[i]],(1,2,0))\n",
    "#         q1 = np.transpose(images_after[i],(1,2,0))\n",
    "#         plt.imshow(q)\n",
    "#         plt.show()\n",
    "#         plt.imshow(q1)\n",
    "#         plt.show()\n",
    "#         print \"Matched before: \"+\"$\"+str(match_report_before[1][i][0])+\"$\"\n",
    "#         print \"Matched after:\" + \"$\"+str(match_report_after[1][i][0])+\"$\"\n",
    "#         print \"Ground truth:\" + str(ground_truth[i])\n",
    "#         print \"Image Dir before:\" + str(match_report_before[3][i])\n",
    "#         print \"Image Dir after:\" + str(match_report_after[3][i])\n",
    "#         print \"Distance before:\" + str(match_report_before[7][i])\n",
    "#         print \"Distance after:\" + str(match_report_after[7][i])\n",
    "#         print \"------------------------------------------------------------------------\"\n",
    "#         print \"------------------------------------------------------------------------\"\n",
    "        \n",
    "print count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
