{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import argparse\n",
    "import logging\n",
    "\n",
    "import numpy as np\n",
    "import torch.autograd\n",
    "import torch.cuda\n",
    "import torch.nn as nn\n",
    "import torch.optim\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import random\n",
    "\n",
    "import copy\n",
    "from datasets.maps_alt import MAPSDataset\n",
    "\n",
    "#from cnn_ws.transformations.homography_augmentation import HomographyAugmentation\n",
    "from cnn_ws.losses.cosine_loss import CosineLoss\n",
    "\n",
    "from cnn_ws.models.myphocnet import PHOCNet\n",
    "from cnn_ws.evaluation.retrieval import map_from_feature_matrix, map_from_query_test_feature_matrices\n",
    "from torch.utils.data.dataloader import _DataLoaderIter as DataLoaderIter\n",
    "from torch.utils.data.sampler import WeightedRandomSampler\n",
    "\n",
    "from cnn_ws.utils.save_load import my_torch_save, my_torch_load\n",
    "\n",
    "#import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_filter_len = 1 # only words above this length are considered valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not torch.cuda.is_available():\n",
    "    logger.warning('Could not find CUDA environment, using CPU mode')\n",
    "    gpu_id = None\n",
    "else:\n",
    "    gpu_id = [0]\n",
    "#torch.cuda.get_device_name(gpu_id[0])\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ = torch.load('models/PHOCNet_SDMD.pt')\n",
    "cnn = model_.module#list(model_.named_parameters())\n",
    "if gpu_id is not None:\n",
    "        if len(gpu_id) > 1:\n",
    "            cnn = nn.DataParallel(cnn, device_ids=gpu_id)\n",
    "            cnn.cuda()\n",
    "        else:\n",
    "            cnn.cuda(gpu_id[0])\n",
    "cnn.training = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from strlocale import BasicLocale\n",
    "\n",
    "def clean_words(words):\n",
    "    lc = BasicLocale()\n",
    "    for i, w in enumerate(words):\n",
    "        try:\n",
    "            words[i] = lc.represent(w).encode('ascii',errors='ignore')\n",
    "        except:\n",
    "            words[i] = w\n",
    "    return words\n",
    "\n",
    "# load before, after images and words, transforms and cleans them\n",
    "# the function also assumes that ground truth words are the same before and after\n",
    "# returns before_images, after_images, words\n",
    "def load_and_transform(map_name):\n",
    "    images_before = np.load('../../../detection_outputs_ready_for_test/detected_regions/'+map_name+'.npy')\n",
    "    words_before = np.load('../../../detection_outputs_ready_for_test/detected_labels/'+map_name+'.npy')\n",
    "    words_before = clean_words(words_before)\n",
    "    images_before, words_before = clean_word_images(images_before, words_before)\n",
    "    images_before = np.transpose(images_before, (0,3,1,2))\n",
    "    \n",
    "    images_after = np.load('../../../detection_outputs_ready_for_test/new_regions/gis_output/'+map_name+'.npy')\n",
    "    words_after = np.load('../../../detection_outputs_ready_for_test/new_labels/gis_output/'+map_name+'.npy')\n",
    "    words_after = clean_words(words_after)\n",
    "    images_after, words_after = clean_word_images(images_after, words_after)\n",
    "    images_after = np.transpose(images_after, (0,3,1,2))\n",
    "    \n",
    "    print 'Images Before Shape ', images_before.shape\n",
    "    print 'Words Before Shape ', words_before.shape\n",
    "    print 'Images After Shape ', images_after.shape\n",
    "    print 'Words After Shape ', words_after.shape\n",
    "    return images_before, images_after, words_after\n",
    "\n",
    "def clean_word_images(images, words):\n",
    "    selected_idx = [x for x in range(len(words)) if len(words[x]) > word_filter_len]\n",
    "    images = images[selected_idx]\n",
    "    words = words[selected_idx]\n",
    "    return images, words\n",
    "\n",
    "def load_and_clean_gis_data():\n",
    "    with open('../../../GIS_data/GIS_combined.txt') as f:\n",
    "        gis_data = np.array(f.read().splitlines())\n",
    "    gis_data = clean_words(gis_data)\n",
    "    print 'GIS Data', gis_data.shape\n",
    "    return gis_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # find the file names\n",
    "# f = open('../splits/val_files.txt', 'rb')\n",
    "# A = f.readlines()\n",
    "# f.close()\n",
    "# A = [x.rstrip('\\n') for x in A]\n",
    "\n",
    "# gl_gt_in_gis = 0\n",
    "# gl_total = 0\n",
    "# for i in range(len(A)):\n",
    "#     im_before, im_after, words, gis = load_and_transform(A[i])\n",
    "#     gis = set(gis)\n",
    "#     words = set(words)\n",
    "#     gt_in_gis = 0\n",
    "#     total = 0\n",
    "#     for w in words:\n",
    "#         if w in gis:\n",
    "#             gt_in_gis += 1\n",
    "#         total += 1\n",
    "#     print 'percentage of words in gs_data ' + str(gt_in_gis/total)\n",
    "#     gl_gt_in_gis += gt_in_gis\n",
    "#     gl_total += total\n",
    "# print 'overall percentage of words in gs_data ' + str(gl_gt_in_gis/gl_total)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert image tnto embedding using the cnn model\n",
    "def get_image_embeddings(cnn, images):\n",
    "    outputs = []\n",
    "    for i in tqdm(range(len(images))):\n",
    "        word_img = images[i]\n",
    "        word_img = 1 - word_img.astype(np.float32) / 255.0\n",
    "        word_img = word_img.reshape((1,) + word_img.shape)\n",
    "        word_img = torch.from_numpy(word_img).float()\n",
    "        word_img = word_img.cuda(gpu_id[0])\n",
    "        word_img = torch.autograd.Variable(word_img)\n",
    "        output = torch.sigmoid(cnn(word_img))\n",
    "        output = output.data.cpu().numpy().flatten()\n",
    "        outputs.append(output)\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to create word variations\n",
    "# word_var is a dictionary that contains all variations as key and 0,1,-1 as value\n",
    "# 0 denotes the root word, -1 denotes var = root_word[:-1], +1 denotes var = root_word[1:]\n",
    "# root_word_var is a dict that stores original_word => all_variations\n",
    "# enable_conf: boolean flag that controls if the confusion logic should be used.\n",
    "# when enabled if a word is a root word as well as a word variation (happens if root words ar rand and grand)\n",
    "# it marks it as to be extended and also stores it in the confusion list\n",
    "def create_word_variations(words, enable_conf=False):\n",
    "    word_var = {}\n",
    "    root_word_var = {}\n",
    "    # create the root word variation dict and set word_var as -1 or +1\n",
    "    for w in words:\n",
    "        if len(w) <= word_filter_len:\n",
    "            continue\n",
    "        root_var_list = [w, w.lower(), w.upper(), w.capitalize()]\n",
    "        var_set = set()\n",
    "        for var in root_var_list:\n",
    "            word_var[var[1:]] = 1\n",
    "            word_var[var[:-1]] = -1\n",
    "            var_set.add(var)\n",
    "            var_set.add(var[1:])\n",
    "            var_set.add(var[:-1])\n",
    "        root_word_var[w] = var_set\n",
    "    # explicitly set all root words to have direction 0\n",
    "    # mark the words that already have a direction set\n",
    "    conf_words = set()\n",
    "    for w in words:\n",
    "        if len(w) <= word_filter_len:\n",
    "            continue\n",
    "        root_var_list = [w, w.lower(), w.upper(), w.capitalize()]\n",
    "        for var in root_var_list:\n",
    "            if var in word_var and word_var[var] != 0 and enable_conf:\n",
    "                conf_words.add(var)\n",
    "            else:\n",
    "                word_var[var] = 0\n",
    "    return word_var, root_word_var, conf_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the PHOC representation of the word itself\n",
    "from cnn_ws.string_embeddings.phoc import build_phoc_descriptor\n",
    "def get_word_phoc_representations(word_strings):\n",
    "    unigrams = [chr(i) for i in range(ord('&'), ord('&')+1) + range(ord('A'), ord('Z')+1) + \\\n",
    "                    range(ord('a'), ord('z') + 1) + range(ord('0'), ord('9') + 1)]\n",
    "    bigram_levels = None\n",
    "    bigrams = None\n",
    "    phoc_unigram_levels=(1, 2, 4, 8)\n",
    "    word_var_dir, root_word_var, conf_words = create_word_variations(word_strings, enable_conf=True)\n",
    "    \n",
    "    word_var_strings = word_var_dir.keys()\n",
    "    embedding_var = build_phoc_descriptor(words=word_var_strings,\n",
    "                                  phoc_unigrams=unigrams,\n",
    "                                  bigram_levels=bigram_levels,\n",
    "                                  phoc_bigrams=bigrams,\n",
    "                                  unigram_levels=phoc_unigram_levels)\n",
    "    \n",
    "    print('embedding variations:', embedding_var.shape)\n",
    "    return (embedding_var, word_var_strings, word_var_dir, root_word_var, conf_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import cdist, pdist, squareform\n",
    "\n",
    "# gets the actual distances of all the ground truth word variations\n",
    "def get_all_dist_gt(dist_mat, emb_info, ground_truth):\n",
    "    # expand emb_info tuple\n",
    "    embedding_var, word_var_strings, word_var_dir, root_word_var,_ = emb_info\n",
    "    all_dist = []\n",
    "    for i in range(len(ground_truth)):\n",
    "        w_dist = []\n",
    "        if ground_truth[i] in root_word_var:\n",
    "            w_vars = root_word_var[ground_truth[i]]\n",
    "            for j in range(len(word_var_strings)):\n",
    "                if word_var_strings[j] in w_vars:\n",
    "                    w_dist.append((word_var_strings[j], dist_mat[i][j]))\n",
    "        all_dist.append(w_dist)\n",
    "    return all_dist\n",
    "\n",
    "# the new report matches method that handles variations\n",
    "def report_matches_with_variations(dist_mat, ground_truth, emb_info, k):\n",
    "    # expand emb_info tuple\n",
    "    embedding_var, word_var_strings, word_var_dir, root_word_var,_ = emb_info\n",
    "    gt_words_dist = []\n",
    "    # gt_words_dist = get_all_dist_gt(dist_mat, emb_info, ground_truth)\n",
    "    retrieval_indices = np.argsort(dist_mat, axis=1)\n",
    "    q = retrieval_indices[:,:k]\n",
    "    count = 0\n",
    "    matched_words = []\n",
    "    img_dir = []\n",
    "    words_len = []\n",
    "    actual_dist = []\n",
    "    # get all matched words\n",
    "    for i in range(len(q)):\n",
    "        matched = []\n",
    "        for j in q[i]:\n",
    "            actual_dist.append(dist_mat[i][j])\n",
    "            matched.append(word_var_strings[j])\n",
    "            curr_len = len(word_var_strings[j])\n",
    "            curr_dir = word_var_dir[word_var_strings[j]]\n",
    "            words_len.append(curr_len + abs(curr_dir))\n",
    "            img_dir.append(curr_dir)\n",
    "        matched_words.append(matched)\n",
    "    \n",
    "    # calculate accuracies\n",
    "    is_correct = []\n",
    "    for i in range(len(ground_truth)):\n",
    "        #print word_strings[i]\n",
    "        is_correct.append(0)\n",
    "        if ground_truth[i].lower() in [mw.lower() for mw in matched_words[i]]:\n",
    "            is_correct[i] = 1\n",
    "            count = count+1\n",
    "        else:\n",
    "            for w in matched_words[i]:\n",
    "                if ground_truth[i] in root_word_var and w in root_word_var[ground_truth[i]]:\n",
    "                    is_correct[i] = 2\n",
    "                    count = count+1\n",
    "                    break\n",
    "    return (count, matched_words, img_dir, words_len, actual_dist, is_correct, gt_words_dist)\n",
    "\n",
    "# For some images, the original predicted word os both a root word and a word_variation of another word \n",
    "# (common word problem). Due to this one cannot be sure, if these images should be extended or not.\n",
    "# These images are handled by comparing distances before and after image extension and picking the minimum one\n",
    "# the feature can be turned of by setting enable_conf = False\n",
    "def update_dist_matrix(dist_mat_before, dist_mat_after, conf_idx):\n",
    "    print('conf_idx', conf_idx)\n",
    "    for i in conf_idx:\n",
    "        dist = np.minimum(dist_mat_before[i], dist_mat_after[i])\n",
    "        dist_mat_after[i] = dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_confusion_matrix(match_report_before, match_report_after, words):\n",
    "    status = [0,1,2]\n",
    "    conf_matrix = [['before/after','incorrect (0)','correct (1)','almost (2)'],\n",
    "                   ['incorrect (0)',0,0,0],\n",
    "                   ['correct (1)',0,0,0],\n",
    "                   ['almost (2)',0,0,0]]\n",
    "    for i in status:\n",
    "        for j in status:\n",
    "            count = 0\n",
    "            for k in range(len(words)):\n",
    "                if match_report_before[5][k] == i and match_report_after[5][k] == j:\n",
    "                    count += 1\n",
    "            conf_matrix[1+i][1+j] = count\n",
    "    return conf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_before_after_preds(map_name, before_report, after_report, ground_truth):\n",
    "    before_preds = [w[0] for w in before_report[1]]\n",
    "    after_preds = [w[0] for w in after_report[1]]\n",
    "    before_after_pred = np.array([before_preds, after_preds, ground_truth]).T\n",
    "    np.save('../../../before_after_ext_pred/'+map_name+'.npy', before_after_pred)\n",
    "\n",
    "def compare_images_before_after_ext(map_name, cnn, global_stats, word_emb_info):\n",
    "    images_before, images_after, words = load_and_transform(map_name)\n",
    "    image_embs_before = get_image_embeddings(cnn, images_before)\n",
    "    image_embs_after = get_image_embeddings(cnn, images_after)\n",
    "    # get the distances between images and words\n",
    "    dist_matrix_before = cdist(XA=image_embs_before, XB=word_emb_info[0], metric='cosine')\n",
    "    print 'before distance calculation done'\n",
    "    dist_matrix_after = cdist(XA=image_embs_after, XB=word_emb_info[0], metric='cosine')\n",
    "    print 'after distance calculation done'\n",
    "    # build the original report\n",
    "    match_report_before = report_matches_with_variations(dist_matrix_before, words, word_emb_info, 1)\n",
    "    # get the low confidence image index\n",
    "    conf_idx = [i for i in range(len(match_report_before[1])) if match_report_before[1][i][0] in word_emb_info[4]]\n",
    "    # update the dist_after matrix based for low confidence images\n",
    "    update_dist_matrix(dist_matrix_before, dist_matrix_after, conf_idx)\n",
    "    # build the report after extension\n",
    "    match_report_after = report_matches_with_variations(dist_matrix_after, words, word_emb_info, 1)\n",
    "    # save_before_after_preds(map_name, match_report_before, match_report_after, words)\n",
    "    global_stats['correct_before'] += match_report_before[0]\n",
    "    global_stats['correct_after'] += match_report_after[0]\n",
    "    global_stats['total'] += len(words)\n",
    "    acc_before = match_report_before[0]/len(words)\n",
    "    acc_after = match_report_after[0]/len(words)\n",
    "    conf_matrix = generate_confusion_matrix(match_report_before, match_report_after, words)\n",
    "    return (acc_before, acc_after, conf_matrix, match_report_before, match_report_after)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the file names\n",
    "f = open('../splits/val_files.txt', 'rb')\n",
    "A = f.readlines()\n",
    "f.close()\n",
    "A = [x.rstrip('\\n') for x in A]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GIS Data (477196,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1290899/1290899 [06:18<00:00, 3413.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('embedding variations:', (1290899, 945))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "gis_data = load_and_clean_gis_data()\n",
    "text_phoc_info = get_word_phoc_representations(gis_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac755028761a48ef912920ddc78f6054",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description=u'Main Iteration', max=1), HTML(value=u'')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images Before Shape  (2713, 3, 135, 487)\n",
      "Words Before Shape  (2713,)\n",
      "Images After Shape  (2713, 3, 135, 487)\n",
      "Words After Shape  (2713,)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82abeb68c97d457faf7ee1d7dfbd5e68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=2713), HTML(value=u'')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "786abb155138410b97cce93c83280afe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=2713), HTML(value=u'')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "global_stats = {'correct_before':0, 'correct_after':0, 'total':0}\n",
    "local_stats = []\n",
    "for i in tqdm(range(len(A)), ascii=True, desc='Main Iteration'):\n",
    "    stats = compare_images_before_after_ext(A[i], cnn, global_stats, text_phoc_info)\n",
    "    local_stats.append(stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for image D0090-5242001\n",
      "the accuracy before extension: 0.213219616205\n",
      "the accuracy after extension: 0.226012793177\n",
      "\n",
      "\n",
      "Accuracy for image D0117-5755018\n",
      "the accuracy before extension: 0.392444101773\n",
      "the accuracy after extension: 0.40400925212\n",
      "\n",
      "\n",
      "Accuracy for image D0117-5755024\n",
      "the accuracy before extension: 0.333333333333\n",
      "the accuracy after extension: 0.333333333333\n",
      "\n",
      "\n",
      "Accuracy for image D0117-5755025\n",
      "the accuracy before extension: 0.341899441341\n",
      "the accuracy after extension: 0.356424581006\n",
      "\n",
      "\n",
      "Accuracy for image D0117-5755033\n",
      "the accuracy before extension: 0.30411919369\n",
      "the accuracy after extension: 0.306748466258\n",
      "\n",
      "\n",
      "Overall Accuracy Before  0.332334207568\n",
      "Overall Accuracy After 0.339265642563\n"
     ]
    }
   ],
   "source": [
    "# print accuracies\n",
    "for i in range(len(A)):\n",
    "    print('Accuracy for image '+A[i])\n",
    "    print \"the accuracy before extension: \" + str(local_stats[i][0])\n",
    "    print \"the accuracy after extension: \"+str(local_stats[i][1])\n",
    "    print('\\n')\n",
    "    \n",
    "print 'Overall Accuracy Before ', global_stats['correct_before']/global_stats['total']\n",
    "print 'Overall Accuracy After', global_stats['correct_after']/global_stats['total']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML, display\n",
    "def print_conf_matrix(conf_matrix):\n",
    "    display(HTML(\n",
    "    '<table><tr>{}</tr></table>'.format(\n",
    "        '</tr><tr>'.join(\n",
    "            '<td>{}</td>'.format('</td><td>'.join(str(_) for _ in row)) for row in conf_matrix)\n",
    "        )\n",
    "    ))\n",
    "\n",
    "# print the confusion matrix\n",
    "for i in range(len(A)):\n",
    "    conf_matrix = local_stats[i][2]\n",
    "    print('Confusion Matrix for Image ' + A[i])\n",
    "    print_conf_matrix(conf_matrix)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print \"Incorrectly classified before and Incorrectly classified after\"\n",
    "import matplotlib.pyplot as plt\n",
    "ground_truth = match_report_before[1]\n",
    "count = 0\n",
    "for i in range(len(words)):\n",
    "    if match_report_before[5][i] == 0 \\\n",
    "    and match_report_after[5][i] == 0:\n",
    "        count += 1\n",
    "#         print \"************************************************************************\"\n",
    "#         print \"************************************************************************\"\n",
    "#         q = np.transpose(images_before[i],(1,2,0))\n",
    "#         q1 = np.transpose(images_after[i],(1,2,0))\n",
    "#         plt.imshow(q)\n",
    "#         plt.show()\n",
    "#         plt.imshow(q1)\n",
    "#         plt.show()\n",
    "#         print \"Matched before: \"+\"$\"+str(match_report_before[1][i][0])+\"$\"\n",
    "#         print \"Matched after:\" + \"$\"+str(match_report_after[1][i][0])+\"$\"\n",
    "#         print \"Ground truth:\" + str(words[i])\n",
    "#         print \"Image Dir before:\" + str(match_report_before[2][i])\n",
    "#         print \"Image Dir after:\" + str(match_report_after[2][i])\n",
    "#         print \"Distance before:\" + str(match_report_before[4][i])\n",
    "#         print \"Distance after:\" + str(match_report_after[4][i])\n",
    "#         print \"------------------------------------------------------------------------\"\n",
    "#         print \"------------------------------------------------------------------------\"\n",
    "        \n",
    "print count\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print \"Incorrectly classified before and Correctly classified after\"\n",
    "import matplotlib.pyplot as plt\n",
    "count = 0\n",
    "for i in range(len(words)):\n",
    "    if match_report_before[5][i] == 0 \\\n",
    "    and match_report_after[5][i] == 1:\n",
    "        count += 1\n",
    "#         print \"************************************************************************\"\n",
    "#         print \"************************************************************************\"\n",
    "#         q = np.transpose(images_before[i],(1,2,0))\n",
    "#         q1 = np.transpose(images_after[i],(1,2,0))\n",
    "#         plt.imshow(q)\n",
    "#         plt.show()\n",
    "#         plt.imshow(q1)\n",
    "#         plt.show()\n",
    "#         print \"Matched before: \"+\"$\"+str(match_report_before[1][i][0])+\"$\"\n",
    "#         print \"Matched after:\" + \"$\"+str(match_report_after[1][i][0])+\"$\"\n",
    "#         print \"Ground truth:\" + str(words[i])\n",
    "#         print \"Image Dir before:\" + str(match_report_before[2][i])\n",
    "#         print \"Image Dir after:\" + str(match_report_after[2][i])\n",
    "#         print \"Distance before:\" + str(match_report_before[4][i])\n",
    "#         print \"Distance after:\" + str(match_report_after[4][i])\n",
    "#         print \"------------------------------------------------------------------------\"\n",
    "#         print \"------------------------------------------------------------------------\"\n",
    "        \n",
    "print count   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print \"Incorrectly classified before and Almost correctly classified after\"\n",
    "import matplotlib.pyplot as plt\n",
    "count = 0\n",
    "for i in range(len(words)):\n",
    "    if match_report_before[5][i] == 0 \\\n",
    "    and match_report_after[5][i] == 2:\n",
    "        count += 1\n",
    "#         print \"************************************************************************\"\n",
    "#         print \"************************************************************************\"\n",
    "#         q = np.transpose(images_before[i],(1,2,0))\n",
    "#         q1 = np.transpose(images_after[i],(1,2,0))\n",
    "#         plt.imshow(q)\n",
    "#         plt.show()\n",
    "#         plt.imshow(q1)\n",
    "#         plt.show()\n",
    "#         print \"Matched before: \"+\"$\"+str(match_report_before[1][i][0])+\"$\"\n",
    "#         print \"Matched after:\" + \"$\"+str(match_report_after[1][i][0])+\"$\"\n",
    "#         print \"Ground truth:\" + str(words[i])\n",
    "#         print \"Image Dir before:\" + str(match_report_before[2][i])\n",
    "#         print \"Image Dir after:\" + str(match_report_after[2][i])\n",
    "#         print \"Distance before:\" + str(match_report_before[4][i])\n",
    "#         print \"Distance after:\" + str(match_report_after[4][i])\n",
    "#         print \"------------------------------------------------------------------------\"\n",
    "#         print \"------------------------------------------------------------------------\"\n",
    "        \n",
    "print count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print \"Correctly classified before and Incorrectly classified after\"\n",
    "import matplotlib.pyplot as plt\n",
    "count = 0\n",
    "for i in range(len(words)):\n",
    "    if match_report_before[5][i] == 1 \\\n",
    "    and match_report_after[5][i] == 0:\n",
    "        count += 1\n",
    "        print \"************************************************************************\"\n",
    "        print \"************************************************************************\"\n",
    "        q = np.transpose(images_before[i],(1,2,0))\n",
    "        q1 = np.transpose(images_after[i],(1,2,0))\n",
    "        plt.imshow(q)\n",
    "        plt.show()\n",
    "        plt.imshow(q1)\n",
    "        plt.show()\n",
    "        print \"Matched before: \"+\"$\"+str(match_report_before[1][i][0])+\"$\"\n",
    "        print \"Matched after:\" + \"$\"+str(match_report_after[1][i][0])+\"$\"\n",
    "        print \"Ground truth:\" + str(words[i])\n",
    "        print \"Image Dir before:\" + str(match_report_before[2][i])\n",
    "        print \"Image Dir after:\" + str(match_report_after[2][i])\n",
    "        print \"Distance before:\" + str(match_report_before[4][i])\n",
    "        print \"Distance after:\" + str(match_report_after[4][i])\n",
    "        print \"------------------------------------------------------------------------\"\n",
    "        print \"------------------------------------------------------------------------\"\n",
    "        \n",
    "print count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print \"Correctly classified before and Correctly classified after\"\n",
    "import matplotlib.pyplot as plt\n",
    "qualified_ids = match_report_before[2]\n",
    "ground_truth = match_report_before[6]\n",
    "count = 0\n",
    "for i in range(len(qualified_ids)):\n",
    "    if match_report_before[5][i] == 1 \\\n",
    "    and match_report_after[5][i] == 1:\n",
    "        count += 1\n",
    "#         print \"************************************************************************\"\n",
    "#         print \"************************************************************************\"\n",
    "#         q = np.transpose(images_before[i],(1,2,0))\n",
    "#         q1 = np.transpose(images_after[i],(1,2,0))\n",
    "#         plt.imshow(q)\n",
    "#         plt.show()\n",
    "#         plt.imshow(q1)\n",
    "#         plt.show()\n",
    "#         print \"Matched before: \"+\"$\"+str(match_report_before[1][i][0])+\"$\"\n",
    "#         print \"Matched after:\" + \"$\"+str(match_report_after[1][i][0])+\"$\"\n",
    "#         print \"Ground truth:\" + str(words[i])\n",
    "#         print \"Image Dir before:\" + str(match_report_before[2][i])\n",
    "#         print \"Image Dir after:\" + str(match_report_after[2][i])\n",
    "#         print \"Distance before:\" + str(match_report_before[4][i])\n",
    "#         print \"Distance after:\" + str(match_report_after[4][i])\n",
    "#         print \"------------------------------------------------------------------------\"\n",
    "#         print \"------------------------------------------------------------------------\"\n",
    "        \n",
    "print count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print \"Correctly classified before and Almost classified after\"\n",
    "import matplotlib.pyplot as plt\n",
    "count = 0\n",
    "for i in range(len(words)):\n",
    "    if match_report_before[5][i] == 1 \\\n",
    "    and match_report_after[5][i] == 2:\n",
    "        count += 1\n",
    "#         print \"************************************************************************\"\n",
    "#         print \"************************************************************************\"\n",
    "#         q = np.transpose(images_before[i],(1,2,0))\n",
    "#         q1 = np.transpose(images_after[i],(1,2,0))\n",
    "#         plt.imshow(q)\n",
    "#         plt.show()\n",
    "#         plt.imshow(q1)\n",
    "#         plt.show()\n",
    "#         print \"Matched before: \"+\"$\"+str(match_report_before[1][i][0])+\"$\"\n",
    "#         print \"Matched after:\" + \"$\"+str(match_report_after[1][i][0])+\"$\"\n",
    "#         print \"Ground truth:\" + str(words[i])\n",
    "#         print \"Image Dir before:\" + str(match_report_before[2][i])\n",
    "#         print \"Image Dir after:\" + str(match_report_after[2][i])\n",
    "#         print \"Distance before:\" + str(match_report_before[4][i])\n",
    "#         print \"Distance after:\" + str(match_report_after[4][i])\n",
    "#         print \"------------------------------------------------------------------------\"\n",
    "#         print \"------------------------------------------------------------------------\"\n",
    "        \n",
    "print count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print \"Almost classified before and In-correctly classified after\"\n",
    "import matplotlib.pyplot as plt\n",
    "count = 0\n",
    "for i in range(len(words)):\n",
    "    if match_report_before[5][i] == 2 \\\n",
    "    and match_report_after[5][i] == 0:\n",
    "        count += 1\n",
    "#         print \"************************************************************************\"\n",
    "#         print \"************************************************************************\"\n",
    "#         q = np.transpose(images_before[i],(1,2,0))\n",
    "#         q1 = np.transpose(images_after[i],(1,2,0))\n",
    "#         plt.imshow(q)\n",
    "#         plt.show()\n",
    "#         plt.imshow(q1)\n",
    "#         plt.show()\n",
    "#         print \"Image Index: \" + str(i)\n",
    "#         print \"Matched before: \"+\"$\"+str(match_report_before[1][i][0])+\"$\"\n",
    "#         print \"Matched after:\" + \"$\"+str(match_report_after[1][i][0])+\"$\"\n",
    "#         print \"Ground truth:\" + str(words[i])\n",
    "#         print \"Image Dir before:\" + str(match_report_before[2][i])\n",
    "#         print \"Image Dir after:\" + str(match_report_after[2][i])\n",
    "#         print \"Distance before:\" + str(match_report_before[4][i])\n",
    "#         print \"Distance after:\" + str(match_report_after[4][i])\n",
    "#         print \"\\nAll Distances Before:\" + str(match_report_before[6][i])\n",
    "#         print \"\\nAll Distances After:\" + str(match_report_after[6][i])\n",
    "#         print \"------------------------------------------------------------------------\"\n",
    "#         print \"------------------------------------------------------------------------\"\n",
    "        \n",
    "print count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print \"Almost classified before and Correctly classified after\"\n",
    "import matplotlib.pyplot as plt\n",
    "qualified_ids = match_report_before[2]\n",
    "ground_truth = match_report_before[6]\n",
    "count = 0\n",
    "for i in range(len(qualified_ids)):\n",
    "    if match_report_before[5][i] == 2 \\\n",
    "    and match_report_after[5][i] == 1:\n",
    "        count += 1\n",
    "#         print \"************************************************************************\"\n",
    "#         print \"************************************************************************\"\n",
    "#         q = np.transpose(images_before[qualified_ids[i]],(1,2,0))\n",
    "#         q1 = np.transpose(images_after[i],(1,2,0))\n",
    "#         plt.imshow(q)\n",
    "#         plt.show()\n",
    "#         plt.imshow(q1)\n",
    "#         plt.show()\n",
    "#         print \"Matched before: \"+\"$\"+str(match_report_before[1][i][0])+\"$\"\n",
    "#         print \"Matched after:\" + \"$\"+str(match_report_after[1][i][0])+\"$\"\n",
    "#         print \"Ground truth:\" + str(ground_truth[i])\n",
    "#         print \"Image Dir before:\" + str(match_report_before[3][i])\n",
    "#         print \"Image Dir after:\" + str(match_report_after[3][i])\n",
    "#         print \"Distance before:\" + str(match_report_before[7][i])\n",
    "#         print \"Distance after:\" + str(match_report_after[7][i])\n",
    "#         print \"------------------------------------------------------------------------\"\n",
    "#         print \"------------------------------------------------------------------------\"\n",
    "        \n",
    "print count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print \"Almost classified before and Almost classified after\"\n",
    "import matplotlib.pyplot as plt\n",
    "qualified_ids = match_report_before[2]\n",
    "ground_truth = match_report_before[6]\n",
    "count = 0\n",
    "for i in range(len(qualified_ids)):\n",
    "    if match_report_before[5][i] == 2 \\\n",
    "    and match_report_after[5][i] == 2:\n",
    "        count += 1\n",
    "#         print \"************************************************************************\"\n",
    "#         print \"************************************************************************\"\n",
    "#         q = np.transpose(images_before[qualified_ids[i]],(1,2,0))\n",
    "#         q1 = np.transpose(images_after[i],(1,2,0))\n",
    "#         plt.imshow(q)\n",
    "#         plt.show()\n",
    "#         plt.imshow(q1)\n",
    "#         plt.show()\n",
    "#         print \"Matched before: \"+\"$\"+str(match_report_before[1][i][0])+\"$\"\n",
    "#         print \"Matched after:\" + \"$\"+str(match_report_after[1][i][0])+\"$\"\n",
    "#         print \"Ground truth:\" + str(ground_truth[i])\n",
    "#         print \"Image Dir before:\" + str(match_report_before[3][i])\n",
    "#         print \"Image Dir after:\" + str(match_report_after[3][i])\n",
    "#         print \"Distance before:\" + str(match_report_before[7][i])\n",
    "#         print \"Distance after:\" + str(match_report_after[7][i])\n",
    "#         print \"------------------------------------------------------------------------\"\n",
    "#         print \"------------------------------------------------------------------------\"\n",
    "        \n",
    "print count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
