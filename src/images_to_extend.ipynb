{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import logging\n",
    "\n",
    "import numpy as np\n",
    "import torch.autograd\n",
    "import torch.cuda\n",
    "import torch.nn as nn\n",
    "import torch.optim\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "\n",
    "import copy\n",
    "from datasets.maps_alt import MAPSDataset\n",
    "\n",
    "#from cnn_ws.transformations.homography_augmentation import HomographyAugmentation\n",
    "from cnn_ws.losses.cosine_loss import CosineLoss\n",
    "\n",
    "from cnn_ws.models.myphocnet import PHOCNet\n",
    "from cnn_ws.evaluation.retrieval import map_from_feature_matrix, map_from_query_test_feature_matrices\n",
    "from torch.utils.data.dataloader import _DataLoaderIter as DataLoaderIter\n",
    "from torch.utils.data.sampler import WeightedRandomSampler\n",
    "\n",
    "from cnn_ws.utils.save_load import my_torch_save, my_torch_load\n",
    "\n",
    "#import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not torch.cuda.is_available():\n",
    "    logger.warning('Could not find CUDA environment, using CPU mode')\n",
    "    gpu_id = None\n",
    "else:\n",
    "    gpu_id = [0]\n",
    "#torch.cuda.get_device_name(gpu_id[0])\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ = torch.load('PHOCNet_a1.pt')\n",
    "cnn = model_.module#list(model_.named_parameters())\n",
    "if gpu_id is not None:\n",
    "        if len(gpu_id) > 1:\n",
    "            cnn = nn.DataParallel(cnn, device_ids=gpu_id)\n",
    "            cnn.cuda()\n",
    "        else:\n",
    "            cnn.cuda(gpu_id[0])\n",
    "cnn.training = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the file names\n",
    "f = open('../splits/val_files.txt', 'rb')\n",
    "A = f.readlines()\n",
    "f.close()\n",
    "A = [x.rstrip('\\n') for x in A]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_transform(map_name):\n",
    "    images = np.load('../../../detection_outputs_ready_for_test/detected_regions/'+map_name+'.npy')\n",
    "    words = np.load('../../../detection_outputs_ready_for_test/detected_labels/'+map_name+'.npy')\n",
    "    images = np.transpose(images, (0,3,1,2))\n",
    "    print 'Images Shape ', images.shape\n",
    "    print 'Words Shape ', words.shape\n",
    "    return images, words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_img_phoc_embs(cnn, images):\n",
    "    outputs = []\n",
    "    for i in tqdm(range(len(images)), ascii=True, desc='Converting Images to Embeddings'):\n",
    "        word_img = images[i]\n",
    "        word_img = 1 - word_img.astype(np.float32) / 255.0\n",
    "        word_img = word_img.reshape((1,) + word_img.shape)\n",
    "        word_img = torch.from_numpy(word_img).float()\n",
    "        word_img = word_img.cuda(gpu_id[0])\n",
    "        word_img = torch.autograd.Variable(word_img)\n",
    "        output = torch.sigmoid(cnn(word_img))\n",
    "        output = output.data.cpu().numpy().flatten()\n",
    "        outputs.append(output)\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cnn_ws.string_embeddings.phoc import build_phoc_descriptor\n",
    "\n",
    "# function to create word variations\n",
    "# word_var is a dictionary that contains all variations as key and 0,1,-1 as value\n",
    "# 0 denotes the root word, -1 denotes var = root_word[:-1], +1 denotes var = root_word[1:]\n",
    "# root_word_var is a dict that stores original_word => all_variations\n",
    "# enable_conf: boolean flag that controls if the confusion logic should be used.\n",
    "# when enabled if a word is a root word as well as a word variation (happens if root words ar rand and grand)\n",
    "# it marks it as to be extended and also stores it in the confusion list\n",
    "def create_word_variations(words, enable_conf=False):\n",
    "    word_var = {}\n",
    "    root_word_var = {}\n",
    "    # create the root word variation dict and set word_var as -1 or +1\n",
    "    for w in words:\n",
    "        if len(w) <= 2:\n",
    "            continue\n",
    "        root_var_list = [w, w.lower(), w.upper(), w.capitalize()]\n",
    "        var_set = set()\n",
    "        for var in root_var_list:\n",
    "            word_var[var[1:]] = 1\n",
    "            word_var[var[:-1]] = -1\n",
    "            var_set.add(var)\n",
    "            var_set.add(var[1:])\n",
    "            var_set.add(var[:-1])\n",
    "        root_word_var[w] = var_set\n",
    "    # explicitly set all root words to have direction 0\n",
    "    # mark the words that already have a direction set\n",
    "    conf_words = set()\n",
    "    for w in words:\n",
    "        if len(w) <= 2:\n",
    "            continue\n",
    "        root_var_list = [w, w.lower(), w.upper(), w.capitalize()]\n",
    "        for var in root_var_list:\n",
    "            if var in word_var and word_var[var] != 0 and enable_conf:\n",
    "                conf_words.add(var)\n",
    "            else:\n",
    "                word_var[var] = 0\n",
    "    return word_var, root_word_var, conf_words\n",
    "\n",
    "def gen_text_phoc_embs(words):\n",
    "    word_strings = words\n",
    "    unigrams = [chr(i) for i in range(ord('&'), ord('&')+1) + range(ord('A'), ord('Z')+1) + \\\n",
    "                    range(ord('a'), ord('z') + 1) + range(ord('0'), ord('9') + 1)]\n",
    "    bigram_levels = None\n",
    "    bigrams = None\n",
    "    phoc_unigram_levels=(1, 2, 4, 8)\n",
    "    \n",
    "    word_var_dir, root_word_var, conf_words = create_word_variations(word_strings, enable_conf=True)\n",
    "    \n",
    "    embedding = build_phoc_descriptor(words=word_strings,\n",
    "                                  phoc_unigrams=unigrams,\n",
    "                                  bigram_levels=bigram_levels,\n",
    "                                  phoc_bigrams=bigrams,\n",
    "                                  unigram_levels=phoc_unigram_levels)\n",
    "\n",
    "    word_var_strings = word_var_dir.keys()\n",
    "    embedding_var = build_phoc_descriptor(words=word_var_strings,\n",
    "                                  phoc_unigrams=unigrams,\n",
    "                                  bigram_levels=bigram_levels,\n",
    "                                  phoc_bigrams=bigrams,\n",
    "                                  unigram_levels=phoc_unigram_levels)\n",
    "    \n",
    "    return embedding, embedding_var, word_var_strings, word_var_dir, root_word_var, conf_words\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the new report matches method that handles variations\n",
    "from scipy.spatial.distance import cdist, pdist, squareform\n",
    "def report_matches_with_variations(outputs, embedding_var, matching, word_strings, \n",
    "                                   word_var_strings, word_var_dir, root_word_var, k, length):\n",
    "    # length sorting stuff\n",
    "    qualified_ids = [x for x in range(len(word_strings)) if len(word_strings[x]) > length]\n",
    "    outputs = np.array(outputs)\n",
    "    word_strings = np.array(word_strings)\n",
    "    outputs = list(outputs[qualified_ids])\n",
    "    word_strings = list(word_strings[qualified_ids])\n",
    "    \n",
    "    # same stuff for variations\n",
    "    qualified_ids_vars = [x for x in range(len(word_var_strings)) if len(word_var_strings[x]) > (length-1)]\n",
    "    embedding_var = np.array(embedding_var)\n",
    "    word_var_strings = np.array(word_var_strings)\n",
    "    embedding_var = list(embedding_var[qualified_ids_vars])\n",
    "    word_var_strings = list(word_var_strings[qualified_ids_vars])\n",
    "    \n",
    "    # the real computation\n",
    "    dist_mat = cdist(XA=outputs, XB=embedding_var, metric=matching)\n",
    "    retrieval_indices = np.argsort(dist_mat, axis=1)\n",
    "    q = retrieval_indices[:,:k]\n",
    "    count = 0\n",
    "    matched_words = []\n",
    "    img_dir = []\n",
    "    words_len = []\n",
    "    # get all matched words\n",
    "    for i in range(len(q)):\n",
    "        matched = []\n",
    "        for j in q[i]:\n",
    "            matched.append(word_var_strings[j])\n",
    "            curr_len = len(word_var_strings[j])\n",
    "            curr_dir = word_var_dir[word_var_strings[j]]\n",
    "            words_len.append(curr_len + abs(curr_dir))\n",
    "            img_dir.append(curr_dir)\n",
    "        matched_words.append(matched)\n",
    "    \n",
    "    # calculate accuracies\n",
    "    for i in range(len(word_strings)):\n",
    "        #print word_strings[i]\n",
    "        if word_strings[i] in matched_words[i]:\n",
    "            count = count+1\n",
    "        else:\n",
    "            for w in matched_words[i]:\n",
    "                if w in root_word_var[word_strings[i]]:\n",
    "                    count = count+1\n",
    "                    break\n",
    "\n",
    "    return (count, matched_words, qualified_ids, img_dir, words_len, outputs, word_strings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the old original report matches method\n",
    "from scipy.spatial.distance import cdist, pdist, squareform\n",
    "def report_matches(outputs, embedding, matching, word_strings, k, length):\n",
    "    # length sorting stuff\n",
    "    qualified_ids = [x for x in range(len(word_strings)) if len(word_strings[x]) > length]\n",
    "    outputs = np.array(outputs)\n",
    "    embedding = np.array(embedding)\n",
    "    word_strings = np.array(word_strings)\n",
    "    outputs = list(outputs[qualified_ids])\n",
    "    embedding = list(embedding[qualified_ids])\n",
    "    word_strings = list(word_strings[qualified_ids])\n",
    "    # the real computation\n",
    "    dist_mat = cdist(XA=outputs, XB=embedding, metric=matching)\n",
    "    retrieval_indices = np.argsort(dist_mat, axis=1)\n",
    "    q = retrieval_indices[:,:k]\n",
    "    count = 0\n",
    "    matched_words = []\n",
    "    # get all matched words\n",
    "    for i in range(len(q)):\n",
    "        matched = []\n",
    "        for j in q[i]:\n",
    "            matched.append(word_strings[j])\n",
    "        matched_words.append(matched)\n",
    "    \n",
    "    for i in range(len(word_strings)):\n",
    "        if word_strings[i] in matched_words[i]:\n",
    "            count = count+1\n",
    "\n",
    "    return (count, matched_words, outputs, embedding, word_strings, qualified_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# given the image name, this driver function computes the following\n",
    "# 1. loads the words and images and transforms them based on image name\n",
    "# 2. generates embeddings for images using the cnn model\n",
    "# 3. gets the original and variation embeddings\n",
    "# 4. generate report with word variations (prints accuracy)\n",
    "# 5. generate report original (prints accuracy)\n",
    "# 6. returns the image_dir_info that needs to be saved as numpy files\n",
    "def image_ext_with_word_var(map_name, cnn, global_stats):\n",
    "    images, words = load_and_transform(map_name)\n",
    "    img_phoc_embs = gen_img_phoc_embs(cnn, images)\n",
    "    embedding, embedding_var, word_var_strings, word_var_dir, root_word_var, conf_set = gen_text_phoc_embs(words)\n",
    "    print set([s.lower() for s in conf_set])\n",
    "    original_report = report_matches(img_phoc_embs, embedding, 'cosine', words, 1, 2)\n",
    "    global_stats['correct_original'] += original_report[0]\n",
    "    print 'Original Accuracy ', str(original_report[0]/float(len(original_report[4])))\n",
    "    word_var_report = report_matches_with_variations(img_phoc_embs, embedding_var,'cosine', words, \\\n",
    "                                                     word_var_strings, word_var_dir, root_word_var, 1, 2)\n",
    "    global_stats['correct_word_var'] += word_var_report[0]\n",
    "    print 'Accuracy With Word Variations ', str(word_var_report[0]/float(len(word_var_report[4])))\n",
    "    global_stats['total'] += len(word_var_report[4])\n",
    "    img_dir_info = np.array([word_var_report[2], word_var_report[3], word_var_report[4]])\n",
    "    return img_dir_info, word_var_report[6], conf_set\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Converting Images to Embeddings:   0%|          | 0/536 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D0090-5242001\n",
      "Images Shape  (536, 3, 135, 487)\n",
      "Words Shape  (536,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting Images to Embeddings: 100%|##########| 536/536 [00:09<00:00, 58.41it/s]\n",
      "100%|██████████| 536/536 [00:00<00:00, 3677.02it/s]\n",
      "100%|██████████| 1871/1871 [00:00<00:00, 5952.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set(['and', 'wayne'])\n",
      "Original Accuracy  0.373134328358\n",
      "Accuracy With Word Variations  0.383795309168\n",
      "D0117-5755018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting Images to Embeddings:   0%|          | 7/3131 [00:00<00:48, 64.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images Shape  (3131, 3, 135, 487)\n",
      "Words Shape  (3131,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting Images to Embeddings: 100%|##########| 3131/3131 [00:52<00:00, 59.41it/s]\n",
      "100%|██████████| 3131/3131 [00:00<00:00, 6938.73it/s]\n",
      "100%|██████████| 4941/4941 [00:01<00:00, 4621.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set(['rand', 'for', 'linton', 'trail', 'state', 'indian', 'green', 'road', 'highway'])\n",
      "Original Accuracy  0.496530454896\n",
      "Accuracy With Word Variations  0.50501156515\n",
      "D0117-5755024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting Images to Embeddings:   0%|          | 6/3309 [00:00<00:57, 57.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images Shape  (3309, 3, 135, 487)\n",
      "Words Shape  (3309,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting Images to Embeddings: 100%|##########| 3309/3309 [00:58<00:00, 56.49it/s]\n",
      "100%|██████████| 3309/3309 [00:00<00:00, 8627.59it/s]\n",
      "100%|██████████| 5585/5585 [00:01<00:00, 5063.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set(['rand', 'for', 'route', 'lake', 'trail', 'state', 'road', 'orth', 'highway'])\n",
      "Original Accuracy  0.453776041667\n",
      "Accuracy With Word Variations  0.453776041667\n",
      "D0117-5755025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting Images to Embeddings:   0%|          | 6/2197 [00:00<00:39, 55.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images Shape  (2197, 3, 135, 487)\n",
      "Words Shape  (2197,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting Images to Embeddings: 100%|##########| 2197/2197 [00:38<00:00, 56.73it/s]\n",
      "100%|██████████| 2197/2197 [00:00<00:00, 6444.65it/s]\n",
      "100%|██████████| 3865/3865 [00:00<00:00, 5164.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set(['rand', 'lincoln', 'alton', 'state', 'road', 'bluff', 'mill', 'highway'])\n",
      "Original Accuracy  0.51061452514\n",
      "Accuracy With Word Variations  0.513966480447\n",
      "D0117-5755033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting Images to Embeddings:   0%|          | 5/2276 [00:00<00:47, 48.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images Shape  (2276, 3, 135, 487)\n",
      "Words Shape  (2276,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting Images to Embeddings: 100%|##########| 2276/2276 [00:40<00:00, 55.83it/s]\n",
      "100%|██████████| 2276/2276 [00:00<00:00, 6559.70it/s]\n",
      "100%|██████████| 4463/4463 [00:00<00:00, 5626.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set(['rand', 'rush', 'for', 'camp', 'lake', 'trail', 'state', 'road', 'rock', 'ind', 'ear', 'highway', 'victor'])\n",
      "Original Accuracy  0.451358457493\n",
      "Accuracy With Word Variations  0.460122699387\n",
      "Accuracy Original 0.466092169352\n",
      "Accuracy With Word Variations 0.471524915699\n"
     ]
    }
   ],
   "source": [
    "global_stats = {'correct_original':0, 'correct_word_var':0, 'total':0}\n",
    "for i in range(len(A)):\n",
    "    print A[i]\n",
    "    img_dir_info, words, conf_words = image_ext_with_word_var(A[i], cnn, global_stats)\n",
    "    np.save('../../../images_to_extend/image_dir_'+A[i]+'.npy', img_dir_info)\n",
    "    np.save('../../../images_to_extend/image_labels_'+A[i]+'.npy', words)\n",
    "    np.save('../../../images_to_extend/word_confusions_'+A[i]+'.npy', conf_words)\n",
    "print 'Accuracy Original', global_stats['correct_original']/float(global_stats['total'])\n",
    "print 'Accuracy With Word Variations', global_stats['correct_word_var']/float(global_stats['total'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # image plot using the variations\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# count, matched_words, qualified_ids, img_dirs, words_len, new_outputs, new_word_strings, \\\n",
    "# = report_matches_with_variations(outputs, embedding_var,'cosine', word_strings,word_var_strings,1, 2)\n",
    "\n",
    "# img_dir_info = np.array([qualified_ids, img_dirs, words_len, new_word_strings])\n",
    "\n",
    "# print \"the accuracy is: \"+str(count/float(len(new_word_strings)))\n",
    "\n",
    "# _len = min(100, len(matched_words))\n",
    "# new_images = images[qualified_ids]\n",
    "# for i in range(_len):\n",
    "#     print \"************************************************************************\"\n",
    "#     print \"************************************************************************\"\n",
    "#     print \"Original image:\"\n",
    "#     q = np.transpose(new_images[i],(1,2,0))\n",
    "#     plt.imshow(q)\n",
    "#     plt.show()\n",
    "#     print \"the matched words are (inorder): \"+str(matched_words[i])\n",
    "#     print \"the gound truth is:\" + str(new_word_strings[i])\n",
    "#     print \"------------------------------------------------------------------------\"\n",
    "#     print \"------------------------------------------------------------------------\"\n",
    "# pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # image plots using original without variation method for comparisons\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# count, matched_words, new_outputs, new_embedding, new_word_strings, \\\n",
    "#     qualified_ids = report_matches(outputs, embedding, 'cosine', word_strings, 1, 2)\n",
    "\n",
    "# print \"the accuracy is: \"+str(count/float(len(new_word_strings)))\n",
    "\n",
    "# _len = min(100, len(matched_words))\n",
    "# new_images = images[qualified_ids]\n",
    "# for i in range(_len):\n",
    "#     print \"************************************************************************\"\n",
    "#     print \"************************************************************************\"\n",
    "#     print \"Original image:\"\n",
    "#     q = np.transpose(new_images[i],(1,2,0))\n",
    "#     plt.imshow(q)\n",
    "#     plt.show()\n",
    "#     print \"the matched words are (inorder): \"+str(matched_words[i])\n",
    "#     print \"the gound truth is:\" + str(new_word_strings[i])\n",
    "#     print \"------------------------------------------------------------------------\"\n",
    "#     print \"------------------------------------------------------------------------\"\n",
    "# pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
